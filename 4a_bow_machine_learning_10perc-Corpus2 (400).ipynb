{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carrega o arquivo com as sentenças, features e classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_frame = pd.read_csv('dataset_sentencas_processadas_400.csv')\n",
    "\n",
    "# sentenca_original = sentenças obtidas do trabalho de Gabriela\n",
    "# sentenca_processada1 = remoção das anotações feitas por Gabriela\n",
    "# sentenca_processada2 = sem pontuações\n",
    "# sentenca_processada3_1 = sem acentos\n",
    "# sentenca_processada3_2 = sem stopwords\n",
    "# sentenca_processada3_3 = letras minúsculas\n",
    "# sentenca_processada3_4 = apenas as raizes das palavras (stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificacao</th>\n",
       "      <th>sentenca</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "      <th>sentenca_processada3_1</th>\n",
       "      <th>sentenca_processada3_2</th>\n",
       "      <th>sentenca_processada3_3</th>\n",
       "      <th>sentenca_processada3_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "      <td>Parece estar no Reino da Dinamarca</td>\n",
       "      <td>Parece estar no Reino da Dinamarca</td>\n",
       "      <td>Parece estar Reino Dinamarca</td>\n",
       "      <td>parece estar reino dinamarca</td>\n",
       "      <td>parec est rein dinamarc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classificacao                             sentenca  \\\n",
       "0            1.0  Parece estar no Reino da Dinamarca.   \n",
       "\n",
       "                  sentenca_processada1                sentenca_processada2  \\\n",
       "0  Parece estar no Reino da Dinamarca.  Parece estar no Reino da Dinamarca   \n",
       "\n",
       "               sentenca_processada3_1        sentenca_processada3_2  \\\n",
       "0  Parece estar no Reino da Dinamarca  Parece estar Reino Dinamarca   \n",
       "\n",
       "         sentenca_processada3_3   sentenca_processada3_4  \n",
       "0  parece estar reino dinamarca  parec est rein dinamarc  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    200\n",
      "1.0    200\n",
      "Name: classificacao, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_frame['classificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BOW (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vetorizar = CountVectorizer(lowercase = False) #, max_features=10000);\n",
    "\n",
    "bag_of_words = vetorizar.fit_transform(data_frame['sentenca_processada3_4'].values.astype('U'))\n",
    "\n",
    "vocabulario = vetorizar.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1389)\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Utiliza conjunto de treino/teste (90/10%) para cálculo Precisão, Acurácia, F1-Score e Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.5 \t 0.29 \t 0.7 \t 0.41\n",
      "1 \t 0.57 \t 0.42 \t 0.57 \t 0.48\n",
      "2 \t 0.45 \t 0.23 \t 0.5 \t 0.31\n",
      "3 \t 0.5 \t 0.5 \t 0.55 \t 0.52\n",
      "4 \t 0.45 \t 0.29 \t 0.58 \t 0.39\n",
      "5 \t 0.52 \t 0.22 \t 0.44 \t 0.3\n",
      "6 \t 0.42 \t 0.3 \t 0.5 \t 0.38\n",
      "7 \t 0.5 \t 0.26 \t 0.45 \t 0.33\n",
      "8 \t 0.55 \t 0.32 \t 0.55 \t 0.4\n",
      "9 \t 0.42 \t 0.27 \t 0.46 \t 0.34\n",
      "10 \t 0.48 \t 0.33 \t 0.5 \t 0.4\n",
      "11 \t 0.62 \t 0.38 \t 0.55 \t 0.44\n",
      "12 \t 0.48 \t 0.25 \t 0.31 \t 0.28\n",
      "13 \t 0.52 \t 0.4 \t 0.53 \t 0.46\n",
      "14 \t 0.52 \t 0.35 \t 0.67 \t 0.46\n",
      "15 \t 0.5 \t 0.47 \t 0.42 \t 0.44\n",
      "16 \t 0.55 \t 0.42 \t 0.53 \t 0.47\n",
      "17 \t 0.52 \t 0.29 \t 0.6 \t 0.39\n",
      "18 \t 0.55 \t 0.4 \t 0.57 \t 0.47\n",
      "19 \t 0.52 \t 0.4 \t 0.53 \t 0.46\n",
      "20 \t 0.38 \t 0.38 \t 0.47 \t 0.42\n",
      "21 \t 0.5 \t 0.32 \t 0.73 \t 0.44\n",
      "22 \t 0.38 \t 0.12 \t 0.17 \t 0.14\n",
      "23 \t 0.62 \t 0.45 \t 0.69 \t 0.55\n",
      "24 \t 0.48 \t 0.32 \t 0.67 \t 0.43\n",
      "25 \t 0.72 \t 0.67 \t 0.62 \t 0.65\n",
      "26 \t 0.5 \t 0.42 \t 0.47 \t 0.44\n",
      "27 \t 0.6 \t 0.48 \t 0.67 \t 0.56\n",
      "28 \t 0.45 \t 0.21 \t 0.36 \t 0.27\n",
      "29 \t 0.62 \t 0.37 \t 0.7 \t 0.48\n",
      "30 \t 0.38 \t 0.29 \t 0.47 \t 0.36\n",
      "31 \t 0.62 \t 0.56 \t 0.53 \t 0.55\n",
      "32 \t 0.57 \t 0.58 \t 0.55 \t 0.56\n",
      "33 \t 0.62 \t 0.56 \t 0.53 \t 0.55\n",
      "34 \t 0.55 \t 0.37 \t 0.54 \t 0.44\n",
      "35 \t 0.32 \t 0.24 \t 0.43 \t 0.31\n",
      "36 \t 0.57 \t 0.48 \t 0.81 \t 0.6\n",
      "37 \t 0.52 \t 0.47 \t 0.5 \t 0.49\n",
      "38 \t 0.48 \t 0.38 \t 0.5 \t 0.43\n",
      "39 \t 0.42 \t 0.25 \t 0.38 \t 0.3\n",
      "40 \t 0.5 \t 0.27 \t 0.6 \t 0.37\n",
      "41 \t 0.48 \t 0.42 \t 0.44 \t 0.43\n",
      "42 \t 0.45 \t 0.24 \t 0.45 \t 0.31\n",
      "43 \t 0.48 \t 0.28 \t 0.38 \t 0.32\n",
      "44 \t 0.52 \t 0.29 \t 0.42 \t 0.34\n",
      "45 \t 0.42 \t 0.26 \t 0.36 \t 0.3\n",
      "46 \t 0.68 \t 0.45 \t 0.82 \t 0.58\n",
      "47 \t 0.45 \t 0.4 \t 0.44 \t 0.42\n",
      "48 \t 0.55 \t 0.5 \t 0.56 \t 0.53\n",
      "49 \t 0.55 \t 0.4 \t 0.57 \t 0.47\n",
      "50 \t 0.55 \t 0.44 \t 0.73 \t 0.55\n",
      "51 \t 0.48 \t 0.26 \t 0.42 \t 0.32\n",
      "52 \t 0.5 \t 0.32 \t 0.58 \t 0.41\n",
      "53 \t 0.52 \t 0.37 \t 0.5 \t 0.42\n",
      "54 \t 0.57 \t 0.45 \t 0.6 \t 0.51\n",
      "55 \t 0.48 \t 0.28 \t 0.7 \t 0.4\n",
      "56 \t 0.4 \t 0.33 \t 0.6 \t 0.43\n",
      "57 \t 0.5 \t 0.45 \t 0.5 \t 0.47\n",
      "58 \t 0.45 \t 0.38 \t 0.47 \t 0.42\n",
      "59 \t 0.5 \t 0.26 \t 0.67 \t 0.38\n",
      "60 \t 0.45 \t 0.33 \t 0.47 \t 0.39\n",
      "61 \t 0.4 \t 0.1 \t 0.25 \t 0.14\n",
      "62 \t 0.57 \t 0.43 \t 0.64 \t 0.51\n",
      "63 \t 0.45 \t 0.35 \t 0.44 \t 0.39\n",
      "64 \t 0.52 \t 0.47 \t 0.44 \t 0.46\n",
      "65 \t 0.45 \t 0.28 \t 0.36 \t 0.31\n",
      "66 \t 0.42 \t 0.28 \t 0.33 \t 0.3\n",
      "67 \t 0.65 \t 0.31 \t 0.44 \t 0.36\n",
      "68 \t 0.57 \t 0.28 \t 0.56 \t 0.37\n",
      "69 \t 0.32 \t 0.22 \t 0.24 \t 0.23\n",
      "70 \t 0.52 \t 0.41 \t 0.44 \t 0.42\n",
      "71 \t 0.57 \t 0.5 \t 0.35 \t 0.41\n",
      "72 \t 0.62 \t 0.47 \t 0.64 \t 0.55\n",
      "73 \t 0.52 \t 0.26 \t 0.5 \t 0.34\n",
      "74 \t 0.48 \t 0.48 \t 0.5 \t 0.49\n",
      "75 \t 0.48 \t 0.32 \t 0.67 \t 0.43\n",
      "76 \t 0.48 \t 0.21 \t 0.71 \t 0.32\n",
      "77 \t 0.48 \t 0.43 \t 0.5 \t 0.46\n",
      "78 \t 0.5 \t 0.41 \t 0.41 \t 0.41\n",
      "79 \t 0.57 \t 0.45 \t 0.6 \t 0.51\n",
      "80 \t 0.68 \t 0.48 \t 0.83 \t 0.61\n",
      "81 \t 0.57 \t 0.41 \t 0.5 \t 0.45\n",
      "82 \t 0.5 \t 0.29 \t 0.55 \t 0.37\n",
      "83 \t 0.5 \t 0.32 \t 0.58 \t 0.41\n",
      "84 \t 0.52 \t 0.24 \t 0.62 \t 0.34\n",
      "85 \t 0.45 \t 0.29 \t 0.46 \t 0.35\n",
      "86 \t 0.5 \t 0.38 \t 0.38 \t 0.38\n",
      "87 \t 0.5 \t 0.29 \t 0.7 \t 0.41\n",
      "88 \t 0.48 \t 0.39 \t 0.56 \t 0.46\n",
      "89 \t 0.45 \t 0.6 \t 0.36 \t 0.45\n",
      "90 \t 0.4 \t 0.17 \t 0.25 \t 0.2\n",
      "91 \t 0.38 \t 0.17 \t 0.4 \t 0.24\n",
      "92 \t 0.55 \t 0.33 \t 0.64 \t 0.44\n",
      "93 \t 0.4 \t 0.28 \t 0.54 \t 0.37\n",
      "94 \t 0.42 \t 0.36 \t 0.47 \t 0.41\n",
      "95 \t 0.42 \t 0.16 \t 0.3 \t 0.21\n",
      "96 \t 0.55 \t 0.41 \t 0.64 \t 0.5\n",
      "97 \t 0.48 \t 0.42 \t 0.44 \t 0.43\n",
      "98 \t 0.52 \t 0.33 \t 0.36 \t 0.34\n",
      "99 \t 0.52 \t 0.35 \t 0.54 \t 0.42\n",
      "80 0.83 25 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = tree.DecisionTreeClassifier()\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.6 \t 0.58 \t 0.7 \t 0.64\n",
      "1 \t 0.52 \t 0.32 \t 0.5 \t 0.39\n",
      "2 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 0.57 \t 0.5 \t 0.65 \t 0.56\n",
      "4 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "5 \t 0.45 \t 0.33 \t 0.38 \t 0.35\n",
      "6 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "7 \t 0.55 \t 0.42 \t 0.53 \t 0.47\n",
      "8 \t 0.55 \t 0.42 \t 0.53 \t 0.47\n",
      "9 \t 0.65 \t 0.73 \t 0.67 \t 0.7\n",
      "10 \t 0.5 \t 0.43 \t 0.53 \t 0.47\n",
      "11 \t 0.6 \t 0.56 \t 0.5 \t 0.53\n",
      "12 \t 0.5 \t 0.56 \t 0.41 \t 0.47\n",
      "13 \t 0.5 \t 0.5 \t 0.5 \t 0.5\n",
      "14 \t 0.65 \t 0.52 \t 0.8 \t 0.63\n",
      "15 \t 0.52 \t 0.71 \t 0.46 \t 0.56\n",
      "16 \t 0.57 \t 0.68 \t 0.54 \t 0.6\n",
      "17 \t 0.62 \t 0.57 \t 0.67 \t 0.62\n",
      "18 \t 0.68 \t 0.55 \t 0.73 \t 0.63\n",
      "19 \t 0.7 \t 0.6 \t 0.75 \t 0.67\n",
      "20 \t 0.57 \t 0.58 \t 0.67 \t 0.62\n",
      "21 \t 0.5 \t 0.44 \t 0.65 \t 0.52\n",
      "22 \t 0.45 \t 0.35 \t 0.35 \t 0.35\n",
      "23 \t 0.5 \t 0.45 \t 0.5 \t 0.47\n",
      "24 \t 0.62 \t 0.64 \t 0.73 \t 0.68\n",
      "25 \t 0.57 \t 0.73 \t 0.46 \t 0.56\n",
      "26 \t 0.52 \t 0.47 \t 0.5 \t 0.49\n",
      "27 \t 0.62 \t 0.57 \t 0.67 \t 0.62\n",
      "28 \t 0.45 \t 0.42 \t 0.42 \t 0.42\n",
      "29 \t 0.5 \t 0.42 \t 0.47 \t 0.44\n",
      "30 \t 0.52 \t 0.54 \t 0.62 \t 0.58\n",
      "31 \t 0.7 \t 0.88 \t 0.58 \t 0.7\n",
      "32 \t 0.6 \t 0.63 \t 0.57 \t 0.6\n",
      "33 \t 0.57 \t 0.44 \t 0.47 \t 0.45\n",
      "34 \t 0.68 \t 0.68 \t 0.65 \t 0.67\n",
      "35 \t 0.42 \t 0.36 \t 0.56 \t 0.44\n",
      "36 \t 0.52 \t 0.33 \t 0.9 \t 0.49\n",
      "37 \t 0.6 \t 0.63 \t 0.57 \t 0.6\n",
      "38 \t 0.52 \t 0.62 \t 0.54 \t 0.58\n",
      "39 \t 0.57 \t 0.55 \t 0.58 \t 0.56\n",
      "40 \t 0.65 \t 0.41 \t 0.9 \t 0.56\n",
      "41 \t 0.48 \t 0.63 \t 0.46 \t 0.53\n",
      "42 \t 0.52 \t 0.48 \t 0.56 \t 0.51\n",
      "43 \t 0.45 \t 0.39 \t 0.39 \t 0.39\n",
      "44 \t 0.5 \t 0.53 \t 0.43 \t 0.47\n",
      "45 \t 0.5 \t 0.47 \t 0.47 \t 0.47\n",
      "46 \t 0.55 \t 0.45 \t 0.56 \t 0.5\n",
      "47 \t 0.52 \t 0.35 \t 0.54 \t 0.42\n",
      "48 \t 0.62 \t 0.65 \t 0.62 \t 0.63\n",
      "49 \t 0.5 \t 0.5 \t 0.5 \t 0.5\n",
      "50 \t 0.45 \t 0.4 \t 0.59 \t 0.48\n",
      "51 \t 0.62 \t 0.58 \t 0.61 \t 0.59\n",
      "52 \t 0.55 \t 0.32 \t 0.7 \t 0.44\n",
      "53 \t 0.5 \t 0.53 \t 0.48 \t 0.5\n",
      "54 \t 0.65 \t 0.7 \t 0.64 \t 0.67\n",
      "55 \t 0.55 \t 0.44 \t 0.73 \t 0.55\n",
      "56 \t 0.5 \t 0.44 \t 0.71 \t 0.55\n",
      "57 \t 0.55 \t 0.65 \t 0.54 \t 0.59\n",
      "58 \t 0.5 \t 0.38 \t 0.53 \t 0.44\n",
      "59 \t 0.52 \t 0.35 \t 0.67 \t 0.46\n",
      "60 \t 0.55 \t 0.48 \t 0.59 \t 0.53\n",
      "61 \t 0.4 \t 0.3 \t 0.38 \t 0.33\n",
      "62 \t 0.48 \t 0.57 \t 0.5 \t 0.53\n",
      "63 \t 0.57 \t 0.6 \t 0.57 \t 0.59\n",
      "64 \t 0.62 \t 0.53 \t 0.56 \t 0.55\n",
      "65 \t 0.6 \t 0.56 \t 0.56 \t 0.56\n",
      "66 \t 0.55 \t 0.56 \t 0.5 \t 0.53\n",
      "67 \t 0.65 \t 0.69 \t 0.47 \t 0.56\n",
      "68 \t 0.45 \t 0.44 \t 0.4 \t 0.42\n",
      "69 \t 0.52 \t 0.44 \t 0.47 \t 0.46\n",
      "70 \t 0.68 \t 0.82 \t 0.58 \t 0.68\n",
      "71 \t 0.65 \t 0.75 \t 0.45 \t 0.56\n",
      "72 \t 0.57 \t 0.63 \t 0.55 \t 0.59\n",
      "73 \t 0.57 \t 0.47 \t 0.56 \t 0.51\n",
      "74 \t 0.52 \t 0.57 \t 0.55 \t 0.56\n",
      "75 \t 0.48 \t 0.32 \t 0.67 \t 0.43\n",
      "76 \t 0.42 \t 0.29 \t 0.54 \t 0.38\n",
      "77 \t 0.52 \t 0.48 \t 0.56 \t 0.51\n",
      "78 \t 0.6 \t 0.65 \t 0.52 \t 0.58\n",
      "79 \t 0.52 \t 0.5 \t 0.53 \t 0.51\n",
      "80 \t 0.62 \t 0.67 \t 0.64 \t 0.65\n",
      "81 \t 0.42 \t 0.65 \t 0.39 \t 0.49\n",
      "82 \t 0.5 \t 0.38 \t 0.53 \t 0.44\n",
      "83 \t 0.5 \t 0.41 \t 0.56 \t 0.47\n",
      "84 \t 0.52 \t 0.43 \t 0.56 \t 0.49\n",
      "85 \t 0.52 \t 0.38 \t 0.57 \t 0.46\n",
      "86 \t 0.62 \t 0.75 \t 0.52 \t 0.62\n",
      "87 \t 0.57 \t 0.42 \t 0.77 \t 0.54\n",
      "88 \t 0.62 \t 0.57 \t 0.72 \t 0.63\n",
      "89 \t 0.52 \t 0.67 \t 0.42 \t 0.51\n",
      "90 \t 0.42 \t 0.44 \t 0.38 \t 0.41\n",
      "91 \t 0.52 \t 0.39 \t 0.64 \t 0.49\n",
      "92 \t 0.62 \t 0.52 \t 0.69 \t 0.59\n",
      "93 \t 0.45 \t 0.44 \t 0.58 \t 0.5\n",
      "94 \t 0.55 \t 0.55 \t 0.6 \t 0.57\n",
      "95 \t 0.55 \t 0.37 \t 0.54 \t 0.44\n",
      "96 \t 0.6 \t 0.55 \t 0.67 \t 0.6\n",
      "97 \t 0.52 \t 0.53 \t 0.5 \t 0.51\n",
      "98 \t 0.57 \t 0.53 \t 0.44 \t 0.48\n",
      "99 \t 0.52 \t 0.35 \t 0.54 \t 0.42\n",
      "36 0.9 31 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = LogisticRegression()\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.57 \t 0.33 \t 0.89 \t 0.48\n",
      "1 \t 0.45 \t 0.84 \t 0.46 \t 0.59\n",
      "2 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "4 \t 0.38 \t 0.38 \t 0.47 \t 0.42\n",
      "5 \t 0.42 \t 0.44 \t 0.38 \t 0.41\n",
      "6 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "7 \t 0.57 \t 0.58 \t 0.55 \t 0.56\n",
      "8 \t 0.52 \t 0.63 \t 0.5 \t 0.56\n",
      "9 \t 0.52 \t 0.55 \t 0.57 \t 0.56\n",
      "10 \t 0.52 \t 0.67 \t 0.54 \t 0.6\n",
      "11 \t 0.48 \t 0.75 \t 0.41 \t 0.53\n",
      "12 \t 0.35 \t 0.5 \t 0.31 \t 0.38\n",
      "13 \t 0.4 \t 0.5 \t 0.42 \t 0.45\n",
      "14 \t 0.55 \t 0.43 \t 0.67 \t 0.53\n",
      "15 \t 0.55 \t 0.88 \t 0.48 \t 0.62\n",
      "16 \t 0.5 \t 0.68 \t 0.48 \t 0.57\n",
      "17 \t 0.55 \t 0.62 \t 0.57 \t 0.59\n",
      "18 \t 0.48 \t 0.65 \t 0.48 \t 0.55\n",
      "19 \t 0.4 \t 0.65 \t 0.43 \t 0.52\n",
      "20 \t 0.55 \t 0.54 \t 0.65 \t 0.59\n",
      "21 \t 0.52 \t 0.44 \t 0.69 \t 0.54\n",
      "22 \t 0.4 \t 0.65 \t 0.38 \t 0.48\n",
      "23 \t 0.45 \t 0.45 \t 0.45 \t 0.45\n",
      "24 \t 0.5 \t 0.44 \t 0.65 \t 0.52\n",
      "25 \t 0.55 \t 1.0 \t 0.45 \t 0.62\n",
      "26 \t 0.62 \t 0.74 \t 0.58 \t 0.65\n",
      "27 \t 0.55 \t 0.52 \t 0.58 \t 0.55\n",
      "28 \t 0.35 \t 0.37 \t 0.33 \t 0.35\n",
      "29 \t 0.48 \t 0.53 \t 0.45 \t 0.49\n",
      "30 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "31 \t 0.5 \t 1.0 \t 0.44 \t 0.62\n",
      "32 \t 0.55 \t 0.74 \t 0.52 \t 0.61\n",
      "33 \t 0.48 \t 0.56 \t 0.39 \t 0.46\n",
      "34 \t 0.52 \t 1.0 \t 0.5 \t 0.67\n",
      "35 \t 0.45 \t 0.4 \t 0.59 \t 0.48\n",
      "36 \t 0.48 \t 0.26 \t 0.88 \t 0.4\n",
      "37 \t 0.6 \t 0.84 \t 0.55 \t 0.67\n",
      "38 \t 0.48 \t 0.57 \t 0.5 \t 0.53\n",
      "39 \t 0.5 \t 0.55 \t 0.5 \t 0.52\n",
      "40 \t 0.32 \t 0.36 \t 0.38 \t 0.37\n",
      "41 \t 0.48 \t 0.63 \t 0.46 \t 0.53\n",
      "42 \t 0.55 \t 0.67 \t 0.56 \t 0.61\n",
      "43 \t 0.45 \t 0.44 \t 0.4 \t 0.42\n",
      "44 \t 0.48 \t 0.65 \t 0.42 \t 0.51\n",
      "45 \t 0.5 \t 0.53 \t 0.48 \t 0.5\n",
      "46 \t 0.62 \t 0.65 \t 0.62 \t 0.63\n",
      "47 \t 0.55 \t 0.6 \t 0.55 \t 0.57\n",
      "48 \t 0.65 \t 0.7 \t 0.64 \t 0.67\n",
      "49 \t 0.48 \t 0.65 \t 0.48 \t 0.55\n",
      "50 \t 0.4 \t 0.36 \t 0.53 \t 0.43\n",
      "51 \t 0.57 \t 0.58 \t 0.55 \t 0.56\n",
      "52 \t 0.5 \t 0.27 \t 0.6 \t 0.37\n",
      "53 \t 0.52 \t 0.74 \t 0.5 \t 0.6\n",
      "54 \t 0.42 \t 0.4 \t 0.42 \t 0.41\n",
      "55 \t 0.5 \t 0.36 \t 0.69 \t 0.47\n",
      "56 \t 0.3 \t 0.04 \t 0.33 \t 0.07\n",
      "57 \t 0.55 \t 0.8 \t 0.53 \t 0.64\n",
      "58 \t 0.3 \t 0.24 \t 0.29 \t 0.26\n",
      "59 \t 0.45 \t 0.35 \t 0.53 \t 0.42\n",
      "60 \t 0.55 \t 0.76 \t 0.55 \t 0.64\n",
      "61 \t 0.35 \t 0.3 \t 0.33 \t 0.32\n",
      "62 \t 0.38 \t 0.48 \t 0.42 \t 0.44\n",
      "63 \t 0.52 \t 0.65 \t 0.52 \t 0.58\n",
      "64 \t 0.6 \t 0.82 \t 0.52 \t 0.64\n",
      "65 \t 0.5 \t 1.0 \t 0.47 \t 0.64\n",
      "66 \t 0.45 \t 0.61 \t 0.42 \t 0.5\n",
      "67 \t 0.32 \t 1.0 \t 0.32 \t 0.49\n",
      "68 \t 0.5 \t 0.67 \t 0.46 \t 0.55\n",
      "69 \t 0.48 \t 0.61 \t 0.44 \t 0.51\n",
      "70 \t 0.48 \t 0.82 \t 0.44 \t 0.57\n",
      "71 \t 0.42 \t 0.75 \t 0.31 \t 0.44\n",
      "72 \t 0.55 \t 0.74 \t 0.52 \t 0.61\n",
      "73 \t 0.55 \t 0.53 \t 0.53 \t 0.53\n",
      "74 \t 0.52 \t 0.62 \t 0.54 \t 0.58\n",
      "75 \t 0.4 \t 0.24 \t 0.55 \t 0.33\n",
      "76 \t 0.57 \t 0.42 \t 0.77 \t 0.54\n",
      "77 \t 0.55 \t 0.57 \t 0.57 \t 0.57\n",
      "78 \t 0.42 \t 1.0 \t 0.42 \t 0.6\n",
      "79 \t 0.55 \t 0.75 \t 0.54 \t 0.63\n",
      "80 \t 0.5 \t 0.76 \t 0.52 \t 0.62\n",
      "81 \t 0.42 \t 0.71 \t 0.4 \t 0.51\n",
      "82 \t 0.52 \t 0.52 \t 0.55 \t 0.54\n",
      "83 \t 0.48 \t 0.5 \t 0.52 \t 0.51\n",
      "84 \t 0.55 \t 0.52 \t 0.58 \t 0.55\n",
      "85 \t 0.5 \t 0.38 \t 0.53 \t 0.44\n",
      "86 \t 0.45 \t 0.94 \t 0.42 \t 0.58\n",
      "87 \t 0.5 \t 0.25 \t 0.75 \t 0.38\n",
      "88 \t 0.48 \t 0.39 \t 0.56 \t 0.46\n",
      "89 \t 0.5 \t 1.0 \t 0.43 \t 0.6\n",
      "90 \t 0.5 \t 0.67 \t 0.46 \t 0.55\n",
      "91 \t 0.5 \t 0.3 \t 0.64 \t 0.41\n",
      "92 \t 0.57 \t 0.52 \t 0.61 \t 0.56\n",
      "93 \t 0.45 \t 0.4 \t 0.59 \t 0.48\n",
      "94 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "95 \t 0.55 \t 0.68 \t 0.52 \t 0.59\n",
      "96 \t 0.57 \t 0.55 \t 0.63 \t 0.59\n",
      "97 \t 0.55 \t 0.84 \t 0.52 \t 0.64\n",
      "98 \t 0.4 \t 1.0 \t 0.38 \t 0.56\n",
      "99 \t 0.4 \t 0.4 \t 0.4 \t 0.4\n",
      "0 0.89 34 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = svm.SVC(gamma='auto', C=1.0, kernel='linear', probability=True)\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "0 \t 1 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 2 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 3 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 4 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 5 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 6 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 7 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 8 \t 0.52 \t 0.54 \t 0.62 \t 0.58\n",
      "0 \t 9 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 10 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 11 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 12 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 13 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 14 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 15 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "0 \t 16 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 17 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 18 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 19 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 20 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 21 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 22 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 23 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 24 \t 0.5 \t 0.46 \t 0.61 \t 0.52\n",
      "0 \t 25 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 26 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 27 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 28 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 29 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 30 \t 0.5 \t 0.46 \t 0.61 \t 0.52\n",
      "0 \t 31 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 32 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "0 \t 33 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "0 \t 34 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 35 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 36 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 37 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "0 \t 38 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 39 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 40 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 41 \t 0.48 \t 0.46 \t 0.58 \t 0.51\n",
      "0 \t 42 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 43 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "0 \t 44 \t 0.52 \t 0.54 \t 0.62 \t 0.58\n",
      "0 \t 45 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 46 \t 0.5 \t 0.46 \t 0.61 \t 0.52\n",
      "0 \t 47 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 48 \t 0.5 \t 0.5 \t 0.6 \t 0.55\n",
      "0 \t 49 \t 0.52 \t 0.5 \t 0.63 \t 0.56\n",
      "4 0.63 8 0.58\n",
      "1 \t 0 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 1 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 2 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 3 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 4 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 5 \t 0.62 \t 0.47 \t 0.64 \t 0.55\n",
      "1 \t 6 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 7 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 8 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 9 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 10 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 11 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 12 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 13 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 14 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 15 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 16 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 17 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 18 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 19 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 20 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 21 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 22 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 23 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 24 \t 0.62 \t 0.47 \t 0.64 \t 0.55\n",
      "1 \t 25 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 26 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 27 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 28 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 29 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 30 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 31 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 32 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 33 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 34 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 35 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 36 \t 0.62 \t 0.47 \t 0.64 \t 0.55\n",
      "1 \t 37 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 38 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 39 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 40 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 41 \t 0.62 \t 0.47 \t 0.64 \t 0.55\n",
      "1 \t 42 \t 0.62 \t 0.47 \t 0.64 \t 0.55\n",
      "1 \t 43 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 44 \t 0.62 \t 0.47 \t 0.64 \t 0.55\n",
      "1 \t 45 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 46 \t 0.57 \t 0.37 \t 0.58 \t 0.45\n",
      "1 \t 47 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 48 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "1 \t 49 \t 0.6 \t 0.42 \t 0.62 \t 0.5\n",
      "5 0.64 5 0.55\n",
      "2 \t 0 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 1 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 2 \t 0.6 \t 0.41 \t 0.75 \t 0.53\n",
      "2 \t 3 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 4 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 5 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 6 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 7 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 8 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 9 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 10 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 11 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 12 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 13 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 14 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 15 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 16 \t 0.6 \t 0.45 \t 0.71 \t 0.56\n",
      "2 \t 17 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 18 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 19 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 20 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 21 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 22 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 23 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 24 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 25 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 26 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 27 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 28 \t 0.6 \t 0.41 \t 0.75 \t 0.53\n",
      "2 \t 29 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 30 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 31 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 32 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 33 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 34 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 35 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 36 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 37 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 38 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 39 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 40 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 41 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 42 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 43 \t 0.6 \t 0.45 \t 0.71 \t 0.56\n",
      "2 \t 44 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 45 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 46 \t 0.55 \t 0.36 \t 0.67 \t 0.47\n",
      "2 \t 47 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 48 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 \t 49 \t 0.57 \t 0.41 \t 0.69 \t 0.51\n",
      "2 0.75 16 0.56\n",
      "3 \t 0 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 1 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 2 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 3 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 4 \t 0.62 \t 0.45 \t 0.77 \t 0.57\n",
      "3 \t 5 \t 0.62 \t 0.45 \t 0.77 \t 0.57\n",
      "3 \t 6 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 7 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 8 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 9 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 10 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 11 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 12 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 13 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 14 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 15 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t 16 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 17 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 18 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 19 \t 0.62 \t 0.45 \t 0.77 \t 0.57\n",
      "3 \t 20 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 21 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 22 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 23 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 24 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 25 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 26 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 27 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 28 \t 0.6 \t 0.45 \t 0.71 \t 0.56\n",
      "3 \t 29 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 30 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 31 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 32 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 33 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 34 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 35 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 36 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 37 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 38 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 39 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 40 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 41 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 42 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 43 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 44 \t 0.6 \t 0.5 \t 0.69 \t 0.58\n",
      "3 \t 45 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 46 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "3 \t 47 \t 0.65 \t 0.5 \t 0.79 \t 0.61\n",
      "3 \t 48 \t 0.62 \t 0.45 \t 0.77 \t 0.57\n",
      "3 \t 49 \t 0.62 \t 0.5 \t 0.73 \t 0.59\n",
      "0 0.79 0 0.61\n",
      "4 \t 0 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 1 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 2 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 3 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 4 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 5 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 6 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 7 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 8 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 9 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 10 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 11 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 12 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 13 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 14 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 15 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 16 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 17 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 18 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 19 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 20 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 21 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 22 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 23 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 24 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 25 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 26 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 27 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 28 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 29 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 30 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 31 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 32 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 33 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 34 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 35 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 36 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 37 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 38 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 39 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 40 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 41 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 42 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 43 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 44 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 45 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 46 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 47 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 48 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "4 \t 49 \t 0.45 \t 0.38 \t 0.56 \t 0.45\n",
      "0 0.56 0 0.45\n",
      "5 \t 0 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 1 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 2 \t 0.52 \t 0.22 \t 0.44 \t 0.3\n",
      "5 \t 3 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 4 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 5 \t 0.5 \t 0.22 \t 0.4 \t 0.29\n",
      "5 \t 6 \t 0.5 \t 0.22 \t 0.4 \t 0.29\n",
      "5 \t 7 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 8 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 9 \t 0.5 \t 0.22 \t 0.4 \t 0.29\n",
      "5 \t 10 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 11 \t 0.5 \t 0.22 \t 0.4 \t 0.29\n",
      "5 \t 12 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 13 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 14 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 15 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 16 \t 0.52 \t 0.22 \t 0.44 \t 0.3\n",
      "5 \t 17 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 18 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 19 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 20 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 21 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 22 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 23 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 24 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 25 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 26 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 27 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 28 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 29 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 30 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 31 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 32 \t 0.5 \t 0.22 \t 0.4 \t 0.29\n",
      "5 \t 33 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 34 \t 0.5 \t 0.22 \t 0.4 \t 0.29\n",
      "5 \t 35 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 36 \t 0.5 \t 0.22 \t 0.4 \t 0.29\n",
      "5 \t 37 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 38 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 39 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 40 \t 0.55 \t 0.22 \t 0.5 \t 0.31\n",
      "5 \t 41 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 42 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 43 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 44 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 45 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 46 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 47 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "5 \t 48 \t 0.5 \t 0.17 \t 0.38 \t 0.23\n",
      "5 \t 49 \t 0.48 \t 0.17 \t 0.33 \t 0.22\n",
      "40 0.5 40 0.31\n",
      "6 \t 0 \t 0.45 \t 0.48 \t 0.52 \t 0.5\n",
      "6 \t 1 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 2 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 3 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 4 \t 0.48 \t 0.52 \t 0.55 \t 0.53\n",
      "6 \t 5 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 6 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 7 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 8 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 9 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 10 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 11 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 12 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 13 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 14 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 15 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 16 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 17 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 18 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 19 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 20 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 21 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 22 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 23 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 24 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 25 \t 0.48 \t 0.52 \t 0.55 \t 0.53\n",
      "6 \t 26 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 27 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 28 \t 0.48 \t 0.52 \t 0.55 \t 0.53\n",
      "6 \t 29 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 30 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 31 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 32 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 33 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 34 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 35 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 36 \t 0.48 \t 0.52 \t 0.55 \t 0.53\n",
      "6 \t 37 \t 0.42 \t 0.48 \t 0.5 \t 0.49\n",
      "6 \t 38 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 39 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 40 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 41 \t 0.45 \t 0.48 \t 0.52 \t 0.5\n",
      "6 \t 42 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 43 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 44 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 45 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 46 \t 0.5 \t 0.57 \t 0.57 \t 0.57\n",
      "6 \t 47 \t 0.45 \t 0.52 \t 0.52 \t 0.52\n",
      "6 \t 48 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "6 \t 49 \t 0.48 \t 0.57 \t 0.54 \t 0.55\n",
      "9 0.57 9 0.57\n",
      "7 \t 0 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 1 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 2 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 3 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 4 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 5 \t 0.52 \t 0.42 \t 0.5 \t 0.46\n",
      "7 \t 6 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 7 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 8 \t 0.52 \t 0.42 \t 0.5 \t 0.46\n",
      "7 \t 9 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 10 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 11 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 12 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 13 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 14 \t 0.48 \t 0.37 \t 0.44 \t 0.4\n",
      "7 \t 15 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 16 \t 0.52 \t 0.42 \t 0.5 \t 0.46\n",
      "7 \t 17 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 18 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 19 \t 0.45 \t 0.32 \t 0.4 \t 0.35\n",
      "7 \t 20 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 21 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 22 \t 0.48 \t 0.37 \t 0.44 \t 0.4\n",
      "7 \t 23 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 24 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 25 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 26 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 27 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 28 \t 0.48 \t 0.37 \t 0.44 \t 0.4\n",
      "7 \t 29 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 30 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 31 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 32 \t 0.45 \t 0.32 \t 0.4 \t 0.35\n",
      "7 \t 33 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 34 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 35 \t 0.5 \t 0.42 \t 0.47 \t 0.44\n",
      "7 \t 36 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 37 \t 0.48 \t 0.37 \t 0.44 \t 0.4\n",
      "7 \t 38 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 39 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 40 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 41 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 42 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 43 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 44 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 45 \t 0.45 \t 0.32 \t 0.4 \t 0.35\n",
      "7 \t 46 \t 0.48 \t 0.32 \t 0.43 \t 0.36\n",
      "7 \t 47 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 48 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "7 \t 49 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "5 0.5 5 0.46\n",
      "8 \t 0 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 1 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 2 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \t 3 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 4 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 5 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 6 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 7 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 8 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 9 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 10 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 11 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 12 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 13 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 14 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 15 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 16 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 17 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 18 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 19 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 20 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 21 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 22 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 23 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 24 \t 0.52 \t 0.42 \t 0.5 \t 0.46\n",
      "8 \t 25 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 26 \t 0.48 \t 0.37 \t 0.44 \t 0.4\n",
      "8 \t 27 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 28 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 29 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 30 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 31 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 32 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 33 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 34 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 35 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 36 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 37 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 38 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 39 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 40 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 41 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 42 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 43 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 44 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 45 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 46 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 47 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 48 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "8 \t 49 \t 0.5 \t 0.37 \t 0.47 \t 0.41\n",
      "24 0.5 24 0.46\n",
      "9 \t 0 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "9 \t 1 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 2 \t 0.6 \t 0.68 \t 0.62 \t 0.65\n",
      "9 \t 3 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 4 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 5 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "9 \t 6 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 7 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "9 \t 8 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 9 \t 0.62 \t 0.68 \t 0.65 \t 0.67\n",
      "9 \t 10 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 11 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 12 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 13 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 14 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 15 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 16 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 17 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 18 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 19 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 20 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 21 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 22 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 23 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 24 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 25 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "9 \t 26 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 27 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "9 \t 28 \t 0.55 \t 0.59 \t 0.59 \t 0.59\n",
      "9 \t 29 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 30 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 31 \t 0.55 \t 0.59 \t 0.59 \t 0.59\n",
      "9 \t 32 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 33 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 34 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 35 \t 0.62 \t 0.68 \t 0.65 \t 0.67\n",
      "9 \t 36 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 37 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 38 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 39 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 40 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 41 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 42 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "9 \t 43 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 44 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 45 \t 0.6 \t 0.68 \t 0.62 \t 0.65\n",
      "9 \t 46 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 47 \t 0.6 \t 0.64 \t 0.64 \t 0.64\n",
      "9 \t 48 \t 0.57 \t 0.59 \t 0.62 \t 0.6\n",
      "9 \t 49 \t 0.57 \t 0.64 \t 0.61 \t 0.62\n",
      "9 0.65 9 0.67\n",
      "10 \t 0 \t 0.55 \t 0.43 \t 0.6 \t 0.5\n",
      "10 \t 1 \t 0.55 \t 0.43 \t 0.6 \t 0.5\n",
      "10 \t 2 \t 0.55 \t 0.43 \t 0.6 \t 0.5\n",
      "10 \t 3 \t 0.55 \t 0.43 \t 0.6 \t 0.5\n",
      "10 \t 4 \t 0.52 \t 0.38 \t 0.57 \t 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    max_f1_j = 0\n",
    "    max_precision_j = 0\n",
    "    max_j_f1 = 0\n",
    "    max_j_precision = 0\n",
    "\n",
    "    for j in range(50):\n",
    "        # Treina o modelo usando o conjunto de dados de treino:\n",
    "        classificador = MLPClassifier(activation='relu', solver='adam', max_iter=200, alpha=0.001, random_state=j)\n",
    "        classificador.fit(treino, classe_treino)\n",
    "\n",
    "        # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "        previsao = classificador.predict_proba(teste)\n",
    "\n",
    "        # transforma as saídas classificadas de acordo com um limiar:\n",
    "        previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "        # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "        previsao_int = previsao_bool.astype(np.int)\n",
    "\n",
    "        f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "        accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "        precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "        recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "\n",
    "        if(max_f1_j < f1_score): \n",
    "            max_f1_j = f1_score\n",
    "            max_j_f1 = j\n",
    "\n",
    "        if(max_precision_j < precision): \n",
    "            max_precision_j = precision\n",
    "            max_j_precision = j\n",
    "\n",
    "        # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "        print(i, '\\t', j, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "\n",
    "    print(max_j_precision, round(max_precision_j, 2), max_j_f1, round(max_f1_j, 2))\n",
    "    \n",
    "    if(max_f1 < max_f1_j): \n",
    "        max_f1 = max_f1_j\n",
    "        max_i_f1 = i\n",
    "\n",
    "    if(max_precision < max_precision_j): \n",
    "        max_precision = max_precision_j\n",
    "        max_i_precision = i\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
