{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carrega o arquivo com as sentenças (Córpus da Gabriela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenca_original</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Traidor e ajudante...</td>\n",
       "      <td>Traidor e ajudante...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Um  maluco corrupto  se unindo a um  traíra .</td>\n",
       "      <td>Um  maluco corrupto  se unindo a um  traíra .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Isso não vai dar certo.</td>\n",
       "      <td>Isso não vai dar certo.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT e PMDB destruiram a economia do brasil, lev...</td>\n",
       "      <td>PT e PMDB destruiram a economia do brasil, lev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O Cunha foi escalado para vilão.</td>\n",
       "      <td>O Cunha foi escalado para vilão.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentenca_original  \\\n",
       "0                              Traidor e ajudante...   \n",
       "1      Um  maluco corrupto  se unindo a um  traíra .   \n",
       "2                            Isso não vai dar certo.   \n",
       "3  PT e PMDB destruiram a economia do brasil, lev...   \n",
       "4                   O Cunha foi escalado para vilão.   \n",
       "\n",
       "                                sentenca_processada1  classificacao  \n",
       "0                              Traidor e ajudante...              0  \n",
       "1      Um  maluco corrupto  se unindo a um  traíra .              0  \n",
       "2                            Isso não vai dar certo.              0  \n",
       "3  PT e PMDB destruiram a economia do brasil, lev...              0  \n",
       "4                   O Cunha foi escalado para vilão.              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    10417\n",
      " 1     2192\n",
      "-1     1992\n",
      "Name: classificacao, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['classificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Atualiza o DataFrame com apenas as classificações irônicas e não irônicas (2.000 para cada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ironicas = list()\n",
    "naoironicas = list()\n",
    "\n",
    "ironicas = df.query('classificacao == 1')\n",
    "naoironicas = df.query('classificacao == 0')\n",
    "\n",
    "dados = ironicas[0:2000]\n",
    "dados = dados.append(naoironicas[0:2000])\n",
    "\n",
    "df = dados\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2000\n",
      "0    2000\n",
      "Name: classificacao, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['classificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Realiza um pre-processamento no dataset para remoção de caracteres especiais, vírgulas, pontos etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sents = list()\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    sents.append(re.sub(r'[^\\w\\s]','',sentenca))\n",
    "    \n",
    "df['sentenca_processada2'] = sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Realiza a obtenção das Features (utiliza sentenca_processada 1 e 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Folha, sempre tão solícita, só fez juntar os...</td>\n",
       "      <td>A Folha sempre tão solícita só fez juntar os d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o mensalão não termina no petrolão...</td>\n",
       "      <td>o mensalão não termina no petrolão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Para a tristeza da extrema-direita e da extrem...</td>\n",
       "      <td>Para a tristeza da extremadireita e da extrema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enquanto Temer tenta se safar, Cunha dará anda...</td>\n",
       "      <td>Enquanto Temer tenta se safar Cunha dará andam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Que dupla...</td>\n",
       "      <td>Que dupla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentenca_processada1  \\\n",
       "0  A Folha, sempre tão solícita, só fez juntar os...   \n",
       "1              o mensalão não termina no petrolão...   \n",
       "2  Para a tristeza da extrema-direita e da extrem...   \n",
       "3  Enquanto Temer tenta se safar, Cunha dará anda...   \n",
       "4                                       Que dupla...   \n",
       "\n",
       "                                sentenca_processada2  \n",
       "0  A Folha sempre tão solícita só fez juntar os d...  \n",
       "1                 o mensalão não termina no petrolão  \n",
       "2  Para a tristeza da extremadireita e da extrema...  \n",
       "3  Enquanto Temer tenta se safar Cunha dará andam...  \n",
       "4                                          Que dupla  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sentenca_processada1', 'sentenca_processada2']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Entidade Nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n",
      "627\n"
     ]
    }
   ],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "\n",
    "entidades_nomeadas = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    text = Text(sentenca, hint_language_code='pt',)\n",
    "    if len(text.entities) > 0:\n",
    "        if df['classificacao'][count] == 1:\n",
    "            ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0:\n",
    "            naoironicas = naoironicas + 1       \n",
    "        entidades_nomeadas.append(1)\n",
    "    else:\n",
    "        entidades_nomeadas.append(0)\n",
    "        \n",
    "    count = count + 1\n",
    "        \n",
    "            \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['entidades_nomeadas'] = entidades_nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2684\n",
       "1    1316\n",
       "Name: entidades_nomeadas, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entidades_nomeadas'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Adjetivos com polaridade positiva (no domínio político)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import nlpnet\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "stemmer = nltk.RSLPStemmer()\n",
    "\n",
    "# Define o etiquetador morfosintático do NLPNet:\n",
    "tagger_nplnet = nlpnet.POSTagger(data_dir='../pos-pt/', language='pt')\n",
    "\n",
    "# Lista de adjetivos de polaridade positiva bem marcados (Trabalho de Gabriela):\n",
    "lista_adjetivos_positivos = ['belo', 'bom', 'bem', 'excelente', 'extraordinário', 'fantástico', 'feliz', 'glorioso', 'heróico', 'hilário', \n",
    " 'honesto', 'ilustre', 'incrível', 'legal', 'limpo', 'lindo', 'majestoso', 'maravilhoso', 'nobre', 'ótimo', 'santo', 'satisfeito', \n",
    " 'solícito']\n",
    "\n",
    "# recupera as raizes das palavras:\n",
    "_lista_adjetivos_positivos = [stemmer.stem(palavra) for palavra in lista_adjetivos_positivos]\n",
    "\n",
    "__lista_adjetivos_positivos = [unidecode.unidecode(palavra) for palavra in _lista_adjetivos_positivos]\n",
    "  \n",
    "def contem_adjetivo_positivo_politico(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    for item in lista:\n",
    "        for (token, tag) in item:\n",
    "            if tag == 'ADJ' and any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_adjetivos_positivos):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "adjetivos = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_adjetivo_positivo_politico(sentenca):\n",
    "        adjetivos.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        adjetivos.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['adjetivos'] = adjetivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3857\n",
       "1     143\n",
       "Name: adjetivos, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['adjetivos'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773\n",
      "1835\n"
     ]
    }
   ],
   "source": [
    "# Lista de disparadores (Trabalho de Gabriela):\n",
    "lista_disparadores = ['aceitar', 'acreditar', 'adorar', 'alíquota', 'alma', 'amá-la', 'anjos', 'boa sorte', 'boa viagem', 'boa noite',\n",
    "  'bocadas', 'bondade', 'campanha', 'canonizá-lo', 'canonização', 'coincidência', 'coisa', 'comprar', 'contribuintes', 'contrição', \n",
    "  'corrupção', 'corruptos', 'cortar gastos', 'crescimento', 'crise', 'culpa', 'demitir', 'democracia', 'desemprego', 'desenvolvimento', \n",
    "  'desgoverno', 'desgraça', 'destruído', 'desvalorização', 'detalhe', 'deuses', 'dinheirama', 'dinheiro', 'ditador', 'dó', 'eleitoreiras', \n",
    "  'embuste', 'estrago', 'ética', 'expertise', 'financiar', 'fome', 'funcionar', 'ganhar', 'gastar', 'gostar', 'gostaria', 'grato', 'honestidade', \n",
    "  'ignorância', 'impeachment', 'inflação', 'investimento', 'lambuzou', 'liderança', 'louvor', 'megaempreiteiro', 'mensalão', 'mentiras', 'mídia',\n",
    "  'milagre', 'miséria', 'moral', 'moralidade', 'necessidade', 'obrigado', 'oposição', 'país', 'parabéns', 'parceria', 'partido', 'pedaladas', 'pena',\n",
    "  'política', 'político', 'prisão', 'quadrilha', 'quebrou', 'reeileição', 'refúgio', 'rombo', 'salve', 'santo', 'saudade', 'sindicalismo',\n",
    "  'solidariedade', 'subordinados', 'sugestivo', 'sugestões', 'surpresa', 'tomara', 'tucanas', 'verde-amarelo', 'vermelhos', 'vida']\n",
    "\n",
    "# recupera as raizes das palavras:\n",
    "_lista_disparadores = [stemmer.stem(palavra) for palavra in lista_disparadores]\n",
    "\n",
    "__lista_disparadores = [unidecode.unidecode(palavra) for palavra in _lista_disparadores]\n",
    "  \n",
    "def has_trigger(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca)\n",
    "    for token in tokens:\n",
    "        if any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_disparadores):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "triggers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if has_trigger(sentenca):\n",
    "        triggers.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        triggers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['triggers'] = triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3608\n",
       "0     392\n",
       "Name: triggers, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['triggers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Intensificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "import nlpnet\n",
    "\n",
    "# Define o etiquetador morfosintático do NLPNet:\n",
    "tagger_nplnet = nlpnet.POSTagger(data_dir='../pos-pt/', language='pt')\n",
    "\n",
    "# Intensificadores\n",
    "def contem_intensificadores(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    ADV = False\n",
    "    for item in lista:\n",
    "         for (_, tag) in item:\n",
    "            if tag == 'ADV':   \n",
    "                ADV = True\n",
    "            elif tag == 'ADJ':\n",
    "                if(ADV == True):           \n",
    "                    return True\n",
    "            else:\n",
    "                ADV = False\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "intensifiers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_intensificadores(sentenca):\n",
    "        intensifiers.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        intensifiers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['intensifiers'] = intensifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3847\n",
       "1     153\n",
       "Name: intensifiers, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intensifiers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Modificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1736\n",
      "1814\n"
     ]
    }
   ],
   "source": [
    "lista_modificadores = ['absolutamente', 'afinal', 'agora', 'apesar', 'até', 'aumento', 'como sempre', 'demais', 'do brasil', 'em paz', 'em solidariedade',\n",
    " 'extremamente', 'ficar longe', 'imagine', 'incondicionalmente', 'lindamente', 'logo agora', 'mais', 'manutenção', 'mas', 'menos',\n",
    "  'não é verdade', 'obrigatoriamente', 'ou melhor', 'pelo menos', 'pensando bem', 'porque', 'quanta', 'quão', 'sempre tão', 'simplesmente', 'só', 'todos']\n",
    "\n",
    "_lista_modificadores = [stemmer.stem(palavra) for palavra in lista_modificadores]\n",
    "\n",
    "__lista_modificadores = [unidecode.unidecode(palavra) for palavra in _lista_modificadores]\n",
    "\n",
    "def contem_modificadores(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca)\n",
    "    for token in tokens:\n",
    "        if any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_modificadores):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "modifiers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_modificadores(sentenca):\n",
    "        modifiers.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        modifiers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['modifiers'] = modifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3550\n",
       "0     450\n",
       "Name: modifiers, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modifiers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Quotation Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "def contem_palavras_com_aspas(sentenca):\n",
    "    result = re.findall(r'[\\'\\\"][\\w!?\\s]+[\\'\\\"]*', sentenca)    \n",
    "    if len(result) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "quotation_marks = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if contem_palavras_com_aspas(sentenca):\n",
    "        quotation_marks.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        quotation_marks.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['quotation_marks'] = quotation_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3727\n",
       "1     273\n",
       "Name: quotation_marks, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quotation_marks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. Pontuação Repetida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "def has_repeated_punctuation(sentenca):\n",
    "    result = re.findall(r'[!?.]+', sentenca)\n",
    "    for group in result:\n",
    "        if len(group) >= 2:\n",
    "            return True        \n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "repeated_punctuation = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_repeated_punctuation(sentenca):\n",
    "        repeated_punctuation.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        repeated_punctuation.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['repeated_punctuation'] = repeated_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3309\n",
       "1     691\n",
       "Name: repeated_punctuation, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['repeated_punctuation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8. Letras Repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "def has_letters_repetition(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    for item in lista:\n",
    "         for (token, tag) in item:\n",
    "            if(tag == 'N'):\n",
    "                result = re.findall(r'(\\w)\\1+', token.lower())\n",
    "                for group in result:\n",
    "                    if len(group) >= 1:\n",
    "                        return True        \n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "letters_repetition = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_letters_repetition(sentenca):\n",
    "        letters_repetition.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        letters_repetition.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['letters_repetition'] = letters_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3477\n",
       "1     523\n",
       "Name: letters_repetition, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letters_repetition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9. Palavras Repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def has_word_repetition(sentenca):\n",
    "    \n",
    "    _tokens = nltk.word_tokenize(sentenca.lower())\n",
    "    \n",
    "    _raizes = [stemmer.stem(palavra) for palavra in _tokens]\n",
    "\n",
    "    _sem_acentos = [unidecode.unidecode(palavra) for palavra in _raizes]\n",
    "\n",
    "    \n",
    "    if(max([len(list(group)) for key, group in groupby(_sem_acentos)])) > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "word_repetition = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_word_repetition(sentenca):\n",
    "        word_repetition.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        word_repetition.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['word_repetition'] = word_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3717\n",
       "1     283\n",
       "Name: word_repetition, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_repetition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10. Rethorical Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESENVOLVER!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11. LIWC (Executar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### LIWC ######\n",
    "import csv\n",
    "liwc_words = []\n",
    "\n",
    "with open('liwc2.txt','r') as f:\n",
    "    next(f) # skip headings\n",
    "    reader=csv.reader(f,delimiter='\\t')\n",
    "    for line in reader:\n",
    "        liwc_words.append(line)\n",
    "\n",
    "def get_polaridade_palavra(word):\n",
    "    for line in liwc_words:\n",
    "        if stemmer.stem(word) in line:\n",
    "            if '126' in line:\n",
    "                return 'positivo'\n",
    "            elif '127' in line:\n",
    "                return 'negativo'\n",
    "            else:\n",
    "                return 'undefined'\n",
    "\n",
    "    return 'not_found'\n",
    "\n",
    "def get_polaridade_sentenca(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca.lower())\n",
    "    positivo = 0\n",
    "    negativo = 0\n",
    "    for token in tokens:\n",
    "        if get_polaridade_palavra(token) == 'positivo':\n",
    "            positivo = positivo + 1\n",
    "        elif get_polaridade_palavra(token) == 'negativo':\n",
    "            negativo = negativo + 1\n",
    "            \n",
    "\n",
    "    if (positivo > negativo):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "liwc = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if get_polaridade_sentenca(sentenca) == 1:\n",
    "        liwc.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        liwc.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['liwc'] = liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liwc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALVA DATAFRAME EM CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataframe completo (sentenças + classificação + features)\n",
    "df.to_csv('dataset_full.csv', index=False)\n",
    "\n",
    "# remove as colunas das sentenças, permanecendo apenas a classificação e features:\n",
    "df1 = df.drop(columns=[\"index\", \"sentenca_original\", \"sentenca_processada1\", \"sentenca_processada2\"])\n",
    "\n",
    "# Salva o dataframe features (classificação + features)\n",
    "df1.to_csv('dataset_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentenca_original</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "      <th>entidades_nomeadas</th>\n",
       "      <th>adjetivos</th>\n",
       "      <th>triggers</th>\n",
       "      <th>intensifiers</th>\n",
       "      <th>modifiers</th>\n",
       "      <th>quotation_marks</th>\n",
       "      <th>repeated_punctuation</th>\n",
       "      <th>letters_repetition</th>\n",
       "      <th>word_repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>A Folha, sempre [tão solícita]P6, só fez junta...</td>\n",
       "      <td>A Folha, sempre tão solícita, só fez juntar os...</td>\n",
       "      <td>1</td>\n",
       "      <td>A Folha sempre tão solícita só fez juntar os d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>o mensalão não termina no petrolão...</td>\n",
       "      <td>o mensalão não termina no petrolão...</td>\n",
       "      <td>1</td>\n",
       "      <td>o mensalão não termina no petrolão</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Para a tristeza da extrema-direita e da extrem...</td>\n",
       "      <td>Para a tristeza da extrema-direita e da extrem...</td>\n",
       "      <td>1</td>\n",
       "      <td>Para a tristeza da extremadireita e da extrema...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Enquanto Temer tenta se safar, Cunha dará anda...</td>\n",
       "      <td>Enquanto Temer tenta se safar, Cunha dará anda...</td>\n",
       "      <td>1</td>\n",
       "      <td>Enquanto Temer tenta se safar Cunha dará andam...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Que dupla...</td>\n",
       "      <td>Que dupla...</td>\n",
       "      <td>1</td>\n",
       "      <td>Que dupla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                  sentenca_original  \\\n",
       "0      7  A Folha, sempre [tão solícita]P6, só fez junta...   \n",
       "1     17              o mensalão não termina no petrolão...   \n",
       "2     22  Para a tristeza da extrema-direita e da extrem...   \n",
       "3     23  Enquanto Temer tenta se safar, Cunha dará anda...   \n",
       "4     36                                       Que dupla...   \n",
       "\n",
       "                                sentenca_processada1  classificacao  \\\n",
       "0  A Folha, sempre tão solícita, só fez juntar os...              1   \n",
       "1              o mensalão não termina no petrolão...              1   \n",
       "2  Para a tristeza da extrema-direita e da extrem...              1   \n",
       "3  Enquanto Temer tenta se safar, Cunha dará anda...              1   \n",
       "4                                       Que dupla...              1   \n",
       "\n",
       "                                sentenca_processada2  entidades_nomeadas  \\\n",
       "0  A Folha sempre tão solícita só fez juntar os d...                   0   \n",
       "1                 o mensalão não termina no petrolão                   0   \n",
       "2  Para a tristeza da extremadireita e da extrema...                   0   \n",
       "3  Enquanto Temer tenta se safar Cunha dará andam...                   1   \n",
       "4                                          Que dupla                   0   \n",
       "\n",
       "   adjetivos  triggers  intensifiers  modifiers  quotation_marks  \\\n",
       "0          1         1             1          1                0   \n",
       "1          0         1             0          1                0   \n",
       "2          0         1             0          1                0   \n",
       "3          0         1             0          1                1   \n",
       "4          0         1             0          0                0   \n",
       "\n",
       "   repeated_punctuation  letters_repetition  word_repetition  \n",
       "0                     0                   0                0  \n",
       "1                     1                   0                0  \n",
       "2                     0                   1                0  \n",
       "3                     1                   0                0  \n",
       "4                     1                   0                0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificacao</th>\n",
       "      <th>entidades_nomeadas</th>\n",
       "      <th>adjetivos</th>\n",
       "      <th>triggers</th>\n",
       "      <th>intensifiers</th>\n",
       "      <th>modifiers</th>\n",
       "      <th>quotation_marks</th>\n",
       "      <th>repeated_punctuation</th>\n",
       "      <th>letters_repetition</th>\n",
       "      <th>word_repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classificacao  entidades_nomeadas  adjetivos  triggers  intensifiers  \\\n",
       "0              1                   0          1         1             1   \n",
       "1              1                   0          0         1             0   \n",
       "2              1                   0          0         1             0   \n",
       "3              1                   1          0         1             0   \n",
       "4              1                   0          0         1             0   \n",
       "\n",
       "   modifiers  quotation_marks  repeated_punctuation  letters_repetition  \\\n",
       "0          1                0                     0                   0   \n",
       "1          1                0                     1                   0   \n",
       "2          1                0                     0                   1   \n",
       "3          1                1                     1                   0   \n",
       "4          0                0                     1                   0   \n",
       "\n",
       "   word_repetition  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = df1.iloc[:,1:10].values\n",
    "outputs = df1['classificacao']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELEÇÃO DAS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n",
      "[0.05798318 0.09833265 0.04484432 0.06661862 0.07870014 0.07961864\n",
      " 0.36655478 0.09197765 0.11537002]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(inputs, outputs)\n",
    "classificador = tree.DecisionTreeClassifier()\n",
    "classificador.fit(inputs, outputs)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(classificador.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n",
      "[False False False False False False  True False False]\n",
      "[7 2 8 6 4 3 1 5 9]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "classificador = LogisticRegression()\n",
    "# classificador.fit(treino, classe_treino)\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(classificador, 1)\n",
    "rfe = rfe.fit(inputs, outputs)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n",
      "[False False False False False False  True False False]\n",
      "[9 2 5 7 3 4 1 8 6]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "classificador = svm.SVC(gamma='auto', C=1.0, kernel='linear', probability=False)\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(classificador, 1)\n",
    "rfe = rfe.fit(inputs, outputs)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5e3ba0bdf6d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# display the relative importance of each attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(inputs, outputs)\n",
    "classificador = MLPClassifier(activation='relu', solver='adam', max_iter=10000, alpha=1e-10, hidden_layer_sizes=(18,2))\n",
    "classificador.fit(inputs, outputs)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(classificador.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # http://minerandodados.com.br/index.php/2018/05/21/feature-selection-bala-de-prata/\n",
    "# from sklearn import feature_selection\n",
    "# fs = feature_selection.SelectPercentile(feature_selection.f_classif, percentile=100)\n",
    "# # model = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k=9)\n",
    "# X_treino_fs = fs.fit_transform(inputs, outputs)\n",
    "\n",
    "# # results = model.fit(df[columns], df['qsec'])\n",
    "\n",
    "# print(fs.scores_)\n",
    "# print(fs.pvalues_)\n",
    "\n",
    "# # x = pd.DataFrame(X_treino_fs)\n",
    "# # x\n",
    "\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
