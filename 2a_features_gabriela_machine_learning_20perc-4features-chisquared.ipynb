{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carrega o arquivo com as features e classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_frame = pd.read_csv('dataset_features.csv') ## tamanho_2000.csv (old_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificacao</th>\n",
       "      <th>entidades_nomeadas</th>\n",
       "      <th>adjetivos</th>\n",
       "      <th>triggers</th>\n",
       "      <th>intensifiers</th>\n",
       "      <th>modifiers</th>\n",
       "      <th>quotation_marks</th>\n",
       "      <th>repeated_punctuation</th>\n",
       "      <th>letters_repetition</th>\n",
       "      <th>word_repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classificacao  entidades_nomeadas  adjetivos  triggers  intensifiers  \\\n",
       "0              1                   0          1         1             1   \n",
       "1              1                   0          0         1             0   \n",
       "2              1                   0          0         1             0   \n",
       "3              1                   1          0         1             0   \n",
       "4              1                   0          0         1             0   \n",
       "\n",
       "   modifiers  quotation_marks  repeated_punctuation  letters_repetition  \\\n",
       "0          1                0                     0                   0   \n",
       "1          1                0                     1                   0   \n",
       "2          1                0                     0                   1   \n",
       "3          1                1                     1                   0   \n",
       "4          0                0                     1                   0   \n",
       "\n",
       "   word_repetition  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aplica os algoritmos de Machine Learning (SVM, Árvore Decisão, Regressão Logística e RNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 4), (4000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = data_frame.iloc[:,[7, 9, 6, 2]].values # chi-squared\n",
    "# inputs = data_frame.iloc[:,[1, 2, 3, 4, 7]].values # gabriela\n",
    "outputs = data_frame['classificacao']\n",
    "\n",
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Utiliza conjunto de treino/teste (80/20% e 90/10%) para cálculo Precisão, Acurácia, F1-Score e Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "# treino, teste, classe_treino, classe_teste = train_test_split(inputs, outputs, random_state = 1, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.57 \t 0.34 \t 0.65 \t 0.44\n",
      "1 \t 0.57 \t 0.34 \t 0.68 \t 0.45\n",
      "2 \t 0.57 \t 0.32 \t 0.68 \t 0.44\n",
      "3 \t 0.58 \t 0.35 \t 0.63 \t 0.45\n",
      "4 \t 0.56 \t 0.32 \t 0.62 \t 0.42\n",
      "5 \t 0.58 \t 0.32 \t 0.64 \t 0.43\n",
      "6 \t 0.56 \t 0.3 \t 0.6 \t 0.4\n",
      "7 \t 0.57 \t 0.34 \t 0.64 \t 0.45\n",
      "8 \t 0.54 \t 0.29 \t 0.62 \t 0.4\n",
      "9 \t 0.55 \t 0.31 \t 0.68 \t 0.42\n",
      "10 \t 0.56 \t 0.34 \t 0.65 \t 0.45\n",
      "11 \t 0.59 \t 0.35 \t 0.67 \t 0.45\n",
      "12 \t 0.57 \t 0.32 \t 0.64 \t 0.43\n",
      "13 \t 0.54 \t 0.31 \t 0.63 \t 0.42\n",
      "14 \t 0.56 \t 0.3 \t 0.62 \t 0.41\n",
      "15 \t 0.54 \t 0.29 \t 0.62 \t 0.4\n",
      "16 \t 0.58 \t 0.34 \t 0.7 \t 0.45\n",
      "17 \t 0.59 \t 0.34 \t 0.65 \t 0.44\n",
      "18 \t 0.57 \t 0.32 \t 0.64 \t 0.43\n",
      "19 \t 0.58 \t 0.32 \t 0.69 \t 0.44\n",
      "20 \t 0.56 \t 0.32 \t 0.62 \t 0.42\n",
      "21 \t 0.55 \t 0.31 \t 0.64 \t 0.42\n",
      "22 \t 0.58 \t 0.31 \t 0.65 \t 0.42\n",
      "23 \t 0.56 \t 0.3 \t 0.62 \t 0.4\n",
      "24 \t 0.56 \t 0.3 \t 0.62 \t 0.4\n",
      "25 \t 0.58 \t 0.32 \t 0.64 \t 0.43\n",
      "26 \t 0.58 \t 0.3 \t 0.67 \t 0.42\n",
      "27 \t 0.56 \t 0.34 \t 0.61 \t 0.44\n",
      "28 \t 0.58 \t 0.33 \t 0.67 \t 0.44\n",
      "29 \t 0.56 \t 0.33 \t 0.63 \t 0.44\n",
      "30 \t 0.6 \t 0.35 \t 0.65 \t 0.45\n",
      "31 \t 0.55 \t 0.32 \t 0.62 \t 0.42\n",
      "32 \t 0.6 \t 0.37 \t 0.68 \t 0.48\n",
      "33 \t 0.6 \t 0.35 \t 0.64 \t 0.45\n",
      "34 \t 0.57 \t 0.33 \t 0.61 \t 0.43\n",
      "35 \t 0.57 \t 0.32 \t 0.66 \t 0.43\n",
      "36 \t 0.57 \t 0.33 \t 0.62 \t 0.43\n",
      "37 \t 0.56 \t 0.32 \t 0.6 \t 0.42\n",
      "38 \t 0.56 \t 0.34 \t 0.63 \t 0.44\n",
      "39 \t 0.56 \t 0.32 \t 0.66 \t 0.43\n",
      "40 \t 0.6 \t 0.32 \t 0.64 \t 0.43\n",
      "41 \t 0.56 \t 0.32 \t 0.64 \t 0.43\n",
      "42 \t 0.54 \t 0.35 \t 0.62 \t 0.45\n",
      "43 \t 0.56 \t 0.29 \t 0.64 \t 0.4\n",
      "44 \t 0.59 \t 0.36 \t 0.66 \t 0.46\n",
      "45 \t 0.56 \t 0.31 \t 0.62 \t 0.41\n",
      "46 \t 0.57 \t 0.33 \t 0.63 \t 0.43\n",
      "47 \t 0.57 \t 0.32 \t 0.66 \t 0.43\n",
      "48 \t 0.57 \t 0.33 \t 0.68 \t 0.44\n",
      "49 \t 0.57 \t 0.32 \t 0.63 \t 0.43\n",
      "50 \t 0.56 \t 0.31 \t 0.62 \t 0.41\n",
      "51 \t 0.59 \t 0.32 \t 0.63 \t 0.42\n",
      "52 \t 0.58 \t 0.34 \t 0.71 \t 0.46\n",
      "53 \t 0.59 \t 0.35 \t 0.65 \t 0.45\n",
      "54 \t 0.56 \t 0.3 \t 0.58 \t 0.39\n",
      "55 \t 0.58 \t 0.35 \t 0.67 \t 0.46\n",
      "56 \t 0.57 \t 0.31 \t 0.69 \t 0.43\n",
      "57 \t 0.58 \t 0.34 \t 0.67 \t 0.45\n",
      "58 \t 0.54 \t 0.29 \t 0.59 \t 0.39\n",
      "59 \t 0.61 \t 0.39 \t 0.74 \t 0.51\n",
      "60 \t 0.57 \t 0.31 \t 0.59 \t 0.41\n",
      "61 \t 0.57 \t 0.32 \t 0.64 \t 0.43\n",
      "62 \t 0.54 \t 0.31 \t 0.67 \t 0.42\n",
      "63 \t 0.57 \t 0.32 \t 0.62 \t 0.42\n",
      "64 \t 0.58 \t 0.35 \t 0.69 \t 0.47\n",
      "65 \t 0.56 \t 0.33 \t 0.62 \t 0.43\n",
      "66 \t 0.57 \t 0.3 \t 0.59 \t 0.4\n",
      "67 \t 0.58 \t 0.33 \t 0.62 \t 0.43\n",
      "68 \t 0.57 \t 0.31 \t 0.6 \t 0.41\n",
      "69 \t 0.56 \t 0.31 \t 0.61 \t 0.41\n",
      "70 \t 0.56 \t 0.29 \t 0.63 \t 0.4\n",
      "71 \t 0.58 \t 0.31 \t 0.64 \t 0.42\n",
      "72 \t 0.55 \t 0.31 \t 0.66 \t 0.42\n",
      "73 \t 0.58 \t 0.33 \t 0.67 \t 0.45\n",
      "74 \t 0.54 \t 0.3 \t 0.59 \t 0.4\n",
      "75 \t 0.56 \t 0.31 \t 0.62 \t 0.42\n",
      "76 \t 0.6 \t 0.34 \t 0.63 \t 0.45\n",
      "77 \t 0.55 \t 0.31 \t 0.66 \t 0.42\n",
      "78 \t 0.56 \t 0.32 \t 0.65 \t 0.42\n",
      "79 \t 0.56 \t 0.32 \t 0.61 \t 0.42\n",
      "80 \t 0.56 \t 0.32 \t 0.62 \t 0.42\n",
      "81 \t 0.59 \t 0.35 \t 0.67 \t 0.46\n",
      "82 \t 0.54 \t 0.31 \t 0.6 \t 0.41\n",
      "83 \t 0.57 \t 0.31 \t 0.65 \t 0.42\n",
      "84 \t 0.58 \t 0.31 \t 0.64 \t 0.42\n",
      "85 \t 0.57 \t 0.34 \t 0.64 \t 0.45\n",
      "86 \t 0.57 \t 0.32 \t 0.62 \t 0.43\n",
      "87 \t 0.6 \t 0.35 \t 0.7 \t 0.47\n",
      "88 \t 0.56 \t 0.3 \t 0.62 \t 0.41\n",
      "89 \t 0.57 \t 0.32 \t 0.64 \t 0.43\n",
      "90 \t 0.55 \t 0.28 \t 0.61 \t 0.38\n",
      "91 \t 0.57 \t 0.33 \t 0.59 \t 0.42\n",
      "92 \t 0.59 \t 0.34 \t 0.68 \t 0.46\n",
      "93 \t 0.56 \t 0.32 \t 0.6 \t 0.42\n",
      "94 \t 0.56 \t 0.3 \t 0.61 \t 0.4\n",
      "95 \t 0.53 \t 0.3 \t 0.58 \t 0.39\n",
      "96 \t 0.56 \t 0.31 \t 0.65 \t 0.42\n",
      "97 \t 0.59 \t 0.31 \t 0.68 \t 0.43\n",
      "98 \t 0.56 \t 0.33 \t 0.59 \t 0.43\n",
      "99 \t 0.57 \t 0.33 \t 0.66 \t 0.44\n",
      "59 0.74 59 0.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(inputs, outputs, random_state = i, test_size = 0.2)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = tree.DecisionTreeClassifier()\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.57 \t 0.33 \t 0.65 \t 0.43\n",
      "1 \t 0.57 \t 0.33 \t 0.68 \t 0.44\n",
      "2 \t 0.57 \t 0.32 \t 0.68 \t 0.44\n",
      "3 \t 0.58 \t 0.34 \t 0.63 \t 0.44\n",
      "4 \t 0.55 \t 0.3 \t 0.62 \t 0.41\n",
      "5 \t 0.58 \t 0.32 \t 0.64 \t 0.43\n",
      "6 \t 0.56 \t 0.3 \t 0.6 \t 0.4\n",
      "7 \t 0.57 \t 0.33 \t 0.64 \t 0.43\n",
      "8 \t 0.53 \t 0.28 \t 0.62 \t 0.39\n",
      "9 \t 0.55 \t 0.3 \t 0.68 \t 0.41\n",
      "10 \t 0.56 \t 0.32 \t 0.65 \t 0.43\n",
      "11 \t 0.59 \t 0.34 \t 0.66 \t 0.45\n",
      "12 \t 0.57 \t 0.31 \t 0.65 \t 0.42\n",
      "13 \t 0.53 \t 0.3 \t 0.62 \t 0.41\n",
      "14 \t 0.55 \t 0.29 \t 0.61 \t 0.39\n",
      "15 \t 0.54 \t 0.29 \t 0.62 \t 0.4\n",
      "16 \t 0.58 \t 0.33 \t 0.71 \t 0.45\n",
      "17 \t 0.58 \t 0.33 \t 0.64 \t 0.44\n",
      "18 \t 0.57 \t 0.32 \t 0.64 \t 0.43\n",
      "19 \t 0.58 \t 0.3 \t 0.69 \t 0.42\n",
      "20 \t 0.56 \t 0.31 \t 0.63 \t 0.41\n",
      "21 \t 0.55 \t 0.31 \t 0.63 \t 0.42\n",
      "22 \t 0.58 \t 0.31 \t 0.64 \t 0.42\n",
      "23 \t 0.56 \t 0.3 \t 0.62 \t 0.4\n",
      "24 \t 0.56 \t 0.29 \t 0.63 \t 0.4\n",
      "25 \t 0.58 \t 0.32 \t 0.63 \t 0.43\n",
      "26 \t 0.57 \t 0.29 \t 0.68 \t 0.41\n",
      "27 \t 0.56 \t 0.33 \t 0.61 \t 0.43\n",
      "28 \t 0.57 \t 0.32 \t 0.68 \t 0.43\n",
      "29 \t 0.56 \t 0.33 \t 0.63 \t 0.44\n",
      "30 \t 0.6 \t 0.33 \t 0.64 \t 0.44\n",
      "31 \t 0.55 \t 0.31 \t 0.62 \t 0.41\n",
      "32 \t 0.6 \t 0.36 \t 0.68 \t 0.47\n",
      "33 \t 0.6 \t 0.34 \t 0.64 \t 0.44\n",
      "34 \t 0.57 \t 0.32 \t 0.6 \t 0.42\n",
      "35 \t 0.57 \t 0.32 \t 0.65 \t 0.43\n",
      "36 \t 0.57 \t 0.33 \t 0.61 \t 0.43\n",
      "37 \t 0.56 \t 0.31 \t 0.6 \t 0.41\n",
      "38 \t 0.57 \t 0.34 \t 0.64 \t 0.44\n",
      "39 \t 0.56 \t 0.31 \t 0.66 \t 0.42\n",
      "40 \t 0.6 \t 0.33 \t 0.64 \t 0.43\n",
      "41 \t 0.56 \t 0.31 \t 0.64 \t 0.42\n",
      "42 \t 0.55 \t 0.34 \t 0.62 \t 0.44\n",
      "43 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "44 \t 0.58 \t 0.34 \t 0.66 \t 0.45\n",
      "45 \t 0.55 \t 0.3 \t 0.62 \t 0.41\n",
      "46 \t 0.58 \t 0.33 \t 0.65 \t 0.44\n",
      "47 \t 0.56 \t 0.31 \t 0.65 \t 0.42\n",
      "48 \t 0.57 \t 0.32 \t 0.68 \t 0.43\n",
      "49 \t 0.58 \t 0.31 \t 0.63 \t 0.42\n",
      "50 \t 0.56 \t 0.3 \t 0.62 \t 0.41\n",
      "51 \t 0.58 \t 0.31 \t 0.63 \t 0.41\n",
      "52 \t 0.57 \t 0.33 \t 0.7 \t 0.45\n",
      "53 \t 0.59 \t 0.35 \t 0.64 \t 0.45\n",
      "54 \t 0.56 \t 0.29 \t 0.58 \t 0.39\n",
      "55 \t 0.58 \t 0.34 \t 0.67 \t 0.45\n",
      "56 \t 0.57 \t 0.31 \t 0.69 \t 0.43\n",
      "57 \t 0.58 \t 0.34 \t 0.67 \t 0.45\n",
      "58 \t 0.55 \t 0.28 \t 0.59 \t 0.38\n",
      "59 \t 0.6 \t 0.37 \t 0.73 \t 0.5\n",
      "60 \t 0.57 \t 0.31 \t 0.59 \t 0.4\n",
      "61 \t 0.57 \t 0.32 \t 0.64 \t 0.43\n",
      "62 \t 0.55 \t 0.31 \t 0.68 \t 0.42\n",
      "63 \t 0.56 \t 0.31 \t 0.62 \t 0.41\n",
      "64 \t 0.58 \t 0.34 \t 0.7 \t 0.46\n",
      "65 \t 0.57 \t 0.31 \t 0.64 \t 0.42\n",
      "66 \t 0.57 \t 0.3 \t 0.59 \t 0.4\n",
      "67 \t 0.58 \t 0.31 \t 0.62 \t 0.41\n",
      "68 \t 0.57 \t 0.31 \t 0.6 \t 0.41\n",
      "69 \t 0.56 \t 0.31 \t 0.61 \t 0.41\n",
      "70 \t 0.56 \t 0.3 \t 0.62 \t 0.4\n",
      "71 \t 0.58 \t 0.31 \t 0.64 \t 0.42\n",
      "72 \t 0.55 \t 0.31 \t 0.66 \t 0.42\n",
      "73 \t 0.58 \t 0.32 \t 0.67 \t 0.43\n",
      "74 \t 0.54 \t 0.3 \t 0.59 \t 0.39\n",
      "75 \t 0.56 \t 0.3 \t 0.62 \t 0.4\n",
      "76 \t 0.6 \t 0.33 \t 0.64 \t 0.44\n",
      "77 \t 0.55 \t 0.3 \t 0.65 \t 0.41\n",
      "78 \t 0.56 \t 0.3 \t 0.65 \t 0.41\n",
      "79 \t 0.56 \t 0.32 \t 0.61 \t 0.42\n",
      "80 \t 0.56 \t 0.31 \t 0.62 \t 0.42\n",
      "81 \t 0.59 \t 0.34 \t 0.67 \t 0.45\n",
      "82 \t 0.54 \t 0.31 \t 0.6 \t 0.41\n",
      "83 \t 0.57 \t 0.31 \t 0.66 \t 0.42\n",
      "84 \t 0.58 \t 0.31 \t 0.63 \t 0.42\n",
      "85 \t 0.57 \t 0.34 \t 0.65 \t 0.44\n",
      "86 \t 0.56 \t 0.3 \t 0.62 \t 0.41\n",
      "87 \t 0.6 \t 0.34 \t 0.69 \t 0.45\n",
      "88 \t 0.56 \t 0.3 \t 0.63 \t 0.4\n",
      "89 \t 0.57 \t 0.31 \t 0.65 \t 0.42\n",
      "90 \t 0.55 \t 0.28 \t 0.61 \t 0.38\n",
      "91 \t 0.56 \t 0.31 \t 0.58 \t 0.4\n",
      "92 \t 0.59 \t 0.34 \t 0.68 \t 0.45\n",
      "93 \t 0.56 \t 0.31 \t 0.61 \t 0.41\n",
      "94 \t 0.56 \t 0.29 \t 0.6 \t 0.39\n",
      "95 \t 0.53 \t 0.3 \t 0.58 \t 0.39\n",
      "96 \t 0.55 \t 0.3 \t 0.66 \t 0.41\n",
      "97 \t 0.59 \t 0.31 \t 0.68 \t 0.42\n",
      "98 \t 0.55 \t 0.32 \t 0.59 \t 0.42\n",
      "99 \t 0.57 \t 0.31 \t 0.67 \t 0.43\n",
      "59 0.73 59 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(inputs, outputs, random_state = i, test_size = 0.2)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = LogisticRegression()\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.56 \t 0.28 \t 0.65 \t 0.39\n",
      "1 \t 0.57 \t 0.33 \t 0.68 \t 0.44\n",
      "2 \t 0.56 \t 0.27 \t 0.7 \t 0.38\n",
      "3 \t 0.57 \t 0.27 \t 0.64 \t 0.38\n",
      "4 \t 0.55 \t 0.3 \t 0.62 \t 0.41\n",
      "5 \t 0.57 \t 0.25 \t 0.65 \t 0.37\n",
      "6 \t 0.56 \t 0.3 \t 0.6 \t 0.4\n",
      "7 \t 0.57 \t 0.33 \t 0.64 \t 0.43\n",
      "8 \t 0.53 \t 0.28 \t 0.62 \t 0.39\n",
      "9 \t 0.55 \t 0.3 \t 0.68 \t 0.41\n",
      "10 \t 0.55 \t 0.27 \t 0.66 \t 0.38\n",
      "11 \t 0.59 \t 0.34 \t 0.66 \t 0.45\n",
      "12 \t 0.56 \t 0.27 \t 0.64 \t 0.38\n",
      "13 \t 0.53 \t 0.3 \t 0.62 \t 0.41\n",
      "14 \t 0.55 \t 0.29 \t 0.61 \t 0.39\n",
      "15 \t 0.53 \t 0.23 \t 0.61 \t 0.34\n",
      "16 \t 0.57 \t 0.27 \t 0.72 \t 0.4\n",
      "17 \t 0.58 \t 0.33 \t 0.64 \t 0.44\n",
      "18 \t 0.57 \t 0.31 \t 0.65 \t 0.42\n",
      "19 \t 0.58 \t 0.3 \t 0.69 \t 0.42\n",
      "20 \t 0.55 \t 0.25 \t 0.62 \t 0.36\n",
      "21 \t 0.54 \t 0.26 \t 0.65 \t 0.37\n",
      "22 \t 0.58 \t 0.26 \t 0.67 \t 0.37\n",
      "23 \t 0.55 \t 0.23 \t 0.62 \t 0.33\n",
      "24 \t 0.56 \t 0.29 \t 0.63 \t 0.4\n",
      "25 \t 0.57 \t 0.26 \t 0.63 \t 0.37\n",
      "26 \t 0.56 \t 0.23 \t 0.67 \t 0.34\n",
      "27 \t 0.56 \t 0.33 \t 0.61 \t 0.43\n",
      "28 \t 0.56 \t 0.25 \t 0.68 \t 0.36\n",
      "29 \t 0.56 \t 0.27 \t 0.66 \t 0.38\n",
      "30 \t 0.58 \t 0.28 \t 0.63 \t 0.39\n",
      "31 \t 0.55 \t 0.31 \t 0.62 \t 0.41\n",
      "32 \t 0.59 \t 0.29 \t 0.69 \t 0.41\n",
      "33 \t 0.58 \t 0.26 \t 0.65 \t 0.37\n",
      "34 \t 0.57 \t 0.32 \t 0.6 \t 0.42\n",
      "35 \t 0.57 \t 0.3 \t 0.66 \t 0.41\n",
      "36 \t 0.57 \t 0.32 \t 0.63 \t 0.43\n",
      "37 \t 0.56 \t 0.31 \t 0.6 \t 0.41\n",
      "38 \t 0.57 \t 0.34 \t 0.64 \t 0.44\n",
      "39 \t 0.55 \t 0.25 \t 0.68 \t 0.36\n",
      "40 \t 0.6 \t 0.32 \t 0.63 \t 0.42\n",
      "41 \t 0.56 \t 0.31 \t 0.64 \t 0.42\n",
      "42 \t 0.55 \t 0.34 \t 0.62 \t 0.44\n",
      "43 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "44 \t 0.56 \t 0.27 \t 0.66 \t 0.38\n",
      "45 \t 0.55 \t 0.3 \t 0.62 \t 0.41\n",
      "46 \t 0.58 \t 0.33 \t 0.65 \t 0.44\n",
      "47 \t 0.56 \t 0.31 \t 0.65 \t 0.42\n",
      "48 \t 0.57 \t 0.32 \t 0.68 \t 0.43\n",
      "49 \t 0.58 \t 0.31 \t 0.63 \t 0.42\n",
      "50 \t 0.56 \t 0.26 \t 0.64 \t 0.37\n",
      "51 \t 0.57 \t 0.25 \t 0.63 \t 0.36\n",
      "52 \t 0.57 \t 0.33 \t 0.7 \t 0.45\n",
      "53 \t 0.59 \t 0.34 \t 0.65 \t 0.44\n",
      "54 \t 0.56 \t 0.29 \t 0.58 \t 0.39\n",
      "55 \t 0.57 \t 0.29 \t 0.69 \t 0.4\n",
      "56 \t 0.55 \t 0.25 \t 0.69 \t 0.37\n",
      "57 \t 0.57 \t 0.3 \t 0.66 \t 0.41\n",
      "58 \t 0.55 \t 0.28 \t 0.59 \t 0.38\n",
      "59 \t 0.59 \t 0.32 \t 0.76 \t 0.45\n",
      "60 \t 0.57 \t 0.31 \t 0.59 \t 0.4\n",
      "61 \t 0.57 \t 0.32 \t 0.64 \t 0.43\n",
      "62 \t 0.55 \t 0.31 \t 0.68 \t 0.42\n",
      "63 \t 0.56 \t 0.31 \t 0.62 \t 0.41\n",
      "64 \t 0.57 \t 0.27 \t 0.74 \t 0.4\n",
      "65 \t 0.55 \t 0.25 \t 0.63 \t 0.36\n",
      "66 \t 0.57 \t 0.29 \t 0.59 \t 0.39\n",
      "67 \t 0.57 \t 0.24 \t 0.63 \t 0.35\n",
      "68 \t 0.56 \t 0.3 \t 0.6 \t 0.4\n",
      "69 \t 0.56 \t 0.3 \t 0.62 \t 0.4\n",
      "70 \t 0.55 \t 0.24 \t 0.63 \t 0.35\n",
      "71 \t 0.57 \t 0.3 \t 0.63 \t 0.41\n",
      "72 \t 0.55 \t 0.31 \t 0.66 \t 0.42\n",
      "73 \t 0.58 \t 0.32 \t 0.67 \t 0.43\n",
      "74 \t 0.54 \t 0.29 \t 0.6 \t 0.39\n",
      "75 \t 0.56 \t 0.24 \t 0.64 \t 0.35\n",
      "76 \t 0.58 \t 0.27 \t 0.64 \t 0.38\n",
      "77 \t 0.54 \t 0.25 \t 0.66 \t 0.36\n",
      "78 \t 0.56 \t 0.3 \t 0.65 \t 0.41\n",
      "79 \t 0.54 \t 0.24 \t 0.61 \t 0.34\n",
      "80 \t 0.55 \t 0.25 \t 0.63 \t 0.36\n",
      "81 \t 0.58 \t 0.29 \t 0.69 \t 0.41\n",
      "82 \t 0.54 \t 0.3 \t 0.6 \t 0.4\n",
      "83 \t 0.56 \t 0.24 \t 0.66 \t 0.35\n",
      "84 \t 0.57 \t 0.27 \t 0.64 \t 0.38\n",
      "85 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "86 \t 0.56 \t 0.3 \t 0.62 \t 0.41\n",
      "87 \t 0.6 \t 0.34 \t 0.69 \t 0.45\n",
      "88 \t 0.55 \t 0.23 \t 0.63 \t 0.33\n",
      "89 \t 0.55 \t 0.24 \t 0.65 \t 0.35\n",
      "90 \t 0.55 \t 0.27 \t 0.61 \t 0.38\n",
      "91 \t 0.56 \t 0.31 \t 0.58 \t 0.4\n",
      "92 \t 0.58 \t 0.29 \t 0.7 \t 0.41\n",
      "93 \t 0.56 \t 0.31 \t 0.61 \t 0.41\n",
      "94 \t 0.56 \t 0.29 \t 0.6 \t 0.39\n",
      "95 \t 0.52 \t 0.25 \t 0.58 \t 0.35\n",
      "96 \t 0.55 \t 0.3 \t 0.66 \t 0.41\n",
      "97 \t 0.59 \t 0.31 \t 0.68 \t 0.42\n",
      "98 \t 0.55 \t 0.32 \t 0.59 \t 0.42\n",
      "99 \t 0.57 \t 0.27 \t 0.7 \t 0.38\n",
      "59 0.76 87 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(inputs, outputs, random_state = i, test_size = 0.2)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = svm.SVC(gamma='auto', C=1.0, kernel='linear', probability=True)\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 1 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 2 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 3 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 4 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 5 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 6 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 7 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 8 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 9 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 10 \t 0.59 \t 0.37 \t 0.68 \t 0.48\n",
      "0 \t 11 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 12 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 13 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 14 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 15 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 16 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 17 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 18 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 19 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 20 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 21 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 22 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 23 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 24 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 25 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 26 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 27 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 28 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 29 \t 0.59 \t 0.37 \t 0.68 \t 0.48\n",
      "0 \t 30 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 31 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 32 \t 0.59 \t 0.37 \t 0.68 \t 0.48\n",
      "0 \t 33 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 34 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 35 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 36 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 37 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 38 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 39 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 40 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 41 \t 0.59 \t 0.37 \t 0.68 \t 0.48\n",
      "0 \t 42 \t 0.59 \t 0.37 \t 0.68 \t 0.48\n",
      "0 \t 43 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 44 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 45 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 46 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 47 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 48 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "0 \t 49 \t 0.59 \t 0.38 \t 0.68 \t 0.49\n",
      "10 0.68 0 0.49\n",
      "1 \t 0 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 1 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 2 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 3 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 4 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 5 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 6 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 7 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 8 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 9 \t 0.57 \t 0.32 \t 0.69 \t 0.44\n",
      "1 \t 10 \t 0.57 \t 0.32 \t 0.69 \t 0.44\n",
      "1 \t 11 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 12 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 13 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 14 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 15 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 16 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 17 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 18 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 19 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 20 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 21 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 22 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 23 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 24 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 25 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 26 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 27 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 28 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 29 \t 0.57 \t 0.32 \t 0.69 \t 0.44\n",
      "1 \t 30 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 31 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 32 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 33 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 34 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 35 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 36 \t 0.57 \t 0.32 \t 0.69 \t 0.44\n",
      "1 \t 37 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 38 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 39 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 40 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 41 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 42 \t 0.57 \t 0.32 \t 0.69 \t 0.44\n",
      "1 \t 43 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 44 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 45 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 46 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 47 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 48 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "1 \t 49 \t 0.58 \t 0.33 \t 0.69 \t 0.45\n",
      "9 0.69 0 0.45\n",
      "2 \t 0 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 1 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 2 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 3 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 4 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 5 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 6 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 7 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 8 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 9 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 10 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 11 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 12 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 13 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 14 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 15 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 16 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 17 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 18 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 19 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 20 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 21 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 22 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 23 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 24 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 25 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 26 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 27 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 28 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 29 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 30 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 31 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 32 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 33 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 34 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 35 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 36 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 37 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 38 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 39 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 40 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 41 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 42 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 43 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 44 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 45 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 46 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 47 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 48 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "2 \t 49 \t 0.56 \t 0.28 \t 0.64 \t 0.39\n",
      "0 0.64 0 0.39\n",
      "3 \t 0 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 1 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 2 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 3 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 4 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 5 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 6 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 7 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 8 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 9 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 10 \t 0.56 \t 0.32 \t 0.61 \t 0.42\n",
      "3 \t 11 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 12 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 13 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 14 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 15 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 16 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 17 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 18 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 19 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 20 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 21 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 22 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 23 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 24 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 25 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 26 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 27 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 28 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 29 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 30 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 31 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 32 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 33 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 34 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 35 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 36 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 37 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 38 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 39 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 40 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 41 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 42 \t 0.56 \t 0.32 \t 0.61 \t 0.42\n",
      "3 \t 43 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 44 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 45 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 46 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 47 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 48 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "3 \t 49 \t 0.56 \t 0.34 \t 0.61 \t 0.43\n",
      "0 0.61 0 0.43\n",
      "4 \t 0 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 1 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 2 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 3 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 4 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 5 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 6 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 7 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 8 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 9 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 10 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 11 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 12 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 13 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 14 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 15 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 16 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 17 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 18 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 19 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 20 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 21 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 22 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 23 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 24 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 25 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 26 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 27 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 28 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 29 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 30 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 31 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 32 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 33 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 34 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 35 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 \t 36 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 37 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 38 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 39 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 40 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 41 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 42 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "4 \t 43 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 44 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 45 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 46 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 47 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 48 \t 0.57 \t 0.34 \t 0.7 \t 0.46\n",
      "4 \t 49 \t 0.57 \t 0.33 \t 0.7 \t 0.44\n",
      "2 0.7 2 0.46\n",
      "5 \t 0 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 1 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 2 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 3 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 4 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 5 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 6 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 7 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 8 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 9 \t 0.59 \t 0.32 \t 0.66 \t 0.44\n",
      "5 \t 10 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 11 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 12 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 13 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 14 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 15 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 16 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 17 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 18 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 19 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 20 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 21 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 22 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 23 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 24 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 25 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 26 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 27 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 28 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 29 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 30 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 31 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 32 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 33 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 34 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 35 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 36 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 37 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 38 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 39 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 40 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 41 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 42 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 43 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 44 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 45 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 46 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 47 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 48 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "5 \t 49 \t 0.6 \t 0.34 \t 0.66 \t 0.45\n",
      "0 0.66 0 0.45\n",
      "6 \t 0 \t 0.52 \t 0.25 \t 0.53 \t 0.34\n",
      "6 \t 1 \t 0.52 \t 0.25 \t 0.53 \t 0.34\n",
      "6 \t 2 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 3 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 4 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 5 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 6 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 7 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 8 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 9 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 10 \t 0.52 \t 0.25 \t 0.53 \t 0.34\n",
      "6 \t 11 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 12 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 13 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 14 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 15 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 16 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 17 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 18 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 19 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 20 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 21 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 22 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 23 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 24 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 25 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 26 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 27 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 28 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 29 \t 0.52 \t 0.25 \t 0.53 \t 0.34\n",
      "6 \t 30 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 31 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 32 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 33 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 34 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 35 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 36 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 37 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 38 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 39 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 40 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 41 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 42 \t 0.52 \t 0.25 \t 0.53 \t 0.34\n",
      "6 \t 43 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 44 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 45 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 46 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 47 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 48 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "6 \t 49 \t 0.53 \t 0.26 \t 0.55 \t 0.36\n",
      "2 0.55 2 0.36\n",
      "7 \t 0 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 1 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 2 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 3 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 4 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 5 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 6 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 7 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 8 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 9 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 10 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 11 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 12 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 13 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 14 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 15 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 16 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 17 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 18 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 19 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 20 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 21 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 22 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 23 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 24 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 25 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 26 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 27 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 28 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 29 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 30 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 31 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 32 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 33 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 34 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 35 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 36 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 37 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 38 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 39 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 40 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 41 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 42 \t 0.58 \t 0.36 \t 0.68 \t 0.47\n",
      "7 \t 43 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 44 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n",
      "7 \t 45 \t 0.58 \t 0.38 \t 0.68 \t 0.49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(50):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(inputs, outputs, random_state = i, test_size = 0.1)\n",
    "\n",
    "    max_f1_j = 0\n",
    "    max_precision_j = 0\n",
    "    max_j_f1 = 0\n",
    "    max_j_precision = 0\n",
    "\n",
    "    for j in range(50):\n",
    "        # Treina o modelo usando o conjunto de dados de treino:\n",
    "        classificador = MLPClassifier(activation='relu', solver='adam', max_iter=10000, alpha=1e-10, random_state=j)\n",
    "        classificador.fit(treino, classe_treino)\n",
    "\n",
    "        # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "        previsao = classificador.predict_proba(teste)\n",
    "\n",
    "        # transforma as saídas classificadas de acordo com um limiar:\n",
    "        previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "        # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "        previsao_int = previsao_bool.astype(np.int)\n",
    "\n",
    "        f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "        accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "        precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "        recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "\n",
    "        if(max_f1_j < f1_score): \n",
    "            max_f1_j = f1_score\n",
    "            max_j_f1 = j\n",
    "\n",
    "        if(max_precision_j < precision): \n",
    "            max_precision_j = precision\n",
    "            max_j_precision = j\n",
    "\n",
    "        # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "        print(i, '\\t', j, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "\n",
    "    print(max_j_precision, round(max_precision_j, 2), max_j_f1, round(max_f1_j, 2))\n",
    "    \n",
    "    if(max_f1 < max_f1_j): \n",
    "        max_f1 = max_f1_j\n",
    "        max_i_f1 = i\n",
    "\n",
    "    if(max_precision < max_precision_j): \n",
    "        max_precision = max_precision_j\n",
    "        max_i_precision = i\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
