{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carrega o arquivo com as sentenças, features e classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_frame = pd.read_csv('dataset_sentencas_processadas.csv')\n",
    "\n",
    "# sentenca_original = sentenças obtidas do trabalho de Gabriela\n",
    "# sentenca_processada1 = remoção das anotações feitas por Gabriela\n",
    "# sentenca_processada2 = sem pontuações\n",
    "# sentenca_processada3_1 = sem acentos\n",
    "# sentenca_processada3_2 = sem stopwords\n",
    "# sentenca_processada3_3 = letras minúsculas\n",
    "# sentenca_processada3_4 = apenas as raizes das palavras (stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenca_original</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "      <th>sentenca_processada3_1</th>\n",
       "      <th>sentenca_processada3_2</th>\n",
       "      <th>sentenca_processada3_3</th>\n",
       "      <th>sentenca_processada3_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Folha, sempre [tão solícita]P6, só fez junta...</td>\n",
       "      <td>A Folha, sempre tão solícita, só fez juntar os...</td>\n",
       "      <td>1</td>\n",
       "      <td>A Folha sempre tão solícita só fez juntar os d...</td>\n",
       "      <td>A Folha sempre tao solicita so fez juntar os d...</td>\n",
       "      <td>A Folha sempre tao solicita fez juntar dois de...</td>\n",
       "      <td>a folha sempre tao solicita fez juntar dois de...</td>\n",
       "      <td>a folh sempr tao solicit fez junt doi desafet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentenca_original  \\\n",
       "0  A Folha, sempre [tão solícita]P6, só fez junta...   \n",
       "\n",
       "                                sentenca_processada1  classificacao  \\\n",
       "0  A Folha, sempre tão solícita, só fez juntar os...              1   \n",
       "\n",
       "                                sentenca_processada2  \\\n",
       "0  A Folha sempre tão solícita só fez juntar os d...   \n",
       "\n",
       "                              sentenca_processada3_1  \\\n",
       "0  A Folha sempre tao solicita so fez juntar os d...   \n",
       "\n",
       "                              sentenca_processada3_2  \\\n",
       "0  A Folha sempre tao solicita fez juntar dois de...   \n",
       "\n",
       "                              sentenca_processada3_3  \\\n",
       "0  a folha sempre tao solicita fez juntar dois de...   \n",
       "\n",
       "                              sentenca_processada3_4  \n",
       "0  a folh sempr tao solicit fez junt doi desafet ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2000\n",
      "0    2000\n",
      "Name: classificacao, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_frame['classificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF (Term Frequency–Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vetorizar = TfidfVectorizer(lowercase=False)\n",
    "\n",
    "tfidf = vetorizar.fit_transform(data_frame['sentenca_processada3_4'].values.astype('U'))\n",
    "\n",
    "vocabulario = vetorizar.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 5776)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Utiliza conjunto de treino/teste (80/20% e 90/10%) para cálculo Precisão, Acurácia, F1-Score e Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.6 \t 0.52 \t 0.63 \t 0.57\n",
      "1 \t 0.62 \t 0.54 \t 0.67 \t 0.6\n",
      "2 \t 0.61 \t 0.52 \t 0.65 \t 0.58\n",
      "3 \t 0.6 \t 0.54 \t 0.61 \t 0.57\n",
      "4 \t 0.57 \t 0.46 \t 0.63 \t 0.53\n",
      "5 \t 0.59 \t 0.45 \t 0.61 \t 0.52\n",
      "6 \t 0.6 \t 0.52 \t 0.61 \t 0.56\n",
      "7 \t 0.61 \t 0.54 \t 0.66 \t 0.59\n",
      "8 \t 0.62 \t 0.55 \t 0.69 \t 0.61\n",
      "9 \t 0.6 \t 0.52 \t 0.67 \t 0.58\n",
      "10 \t 0.61 \t 0.57 \t 0.61 \t 0.59\n",
      "11 \t 0.56 \t 0.48 \t 0.57 \t 0.52\n",
      "12 \t 0.6 \t 0.53 \t 0.61 \t 0.57\n",
      "13 \t 0.63 \t 0.55 \t 0.7 \t 0.62\n",
      "14 \t 0.58 \t 0.53 \t 0.58 \t 0.55\n",
      "15 \t 0.62 \t 0.53 \t 0.67 \t 0.59\n",
      "16 \t 0.61 \t 0.49 \t 0.69 \t 0.57\n",
      "17 \t 0.59 \t 0.49 \t 0.61 \t 0.54\n",
      "18 \t 0.6 \t 0.51 \t 0.65 \t 0.57\n",
      "19 \t 0.6 \t 0.52 \t 0.63 \t 0.57\n",
      "20 \t 0.58 \t 0.46 \t 0.6 \t 0.52\n",
      "21 \t 0.62 \t 0.56 \t 0.67 \t 0.61\n",
      "22 \t 0.62 \t 0.5 \t 0.6 \t 0.55\n",
      "23 \t 0.62 \t 0.6 \t 0.65 \t 0.62\n",
      "24 \t 0.6 \t 0.49 \t 0.64 \t 0.56\n",
      "25 \t 0.6 \t 0.49 \t 0.58 \t 0.54\n",
      "26 \t 0.62 \t 0.55 \t 0.68 \t 0.61\n",
      "27 \t 0.6 \t 0.53 \t 0.62 \t 0.57\n",
      "28 \t 0.6 \t 0.48 \t 0.67 \t 0.56\n",
      "29 \t 0.66 \t 0.56 \t 0.71 \t 0.63\n",
      "30 \t 0.57 \t 0.51 \t 0.59 \t 0.54\n",
      "31 \t 0.62 \t 0.53 \t 0.65 \t 0.58\n",
      "32 \t 0.57 \t 0.48 \t 0.53 \t 0.51\n",
      "33 \t 0.62 \t 0.57 \t 0.61 \t 0.59\n",
      "34 \t 0.63 \t 0.59 \t 0.66 \t 0.62\n",
      "35 \t 0.6 \t 0.5 \t 0.65 \t 0.56\n",
      "36 \t 0.55 \t 0.46 \t 0.55 \t 0.5\n",
      "37 \t 0.58 \t 0.51 \t 0.59 \t 0.55\n",
      "38 \t 0.62 \t 0.53 \t 0.67 \t 0.59\n",
      "39 \t 0.6 \t 0.51 \t 0.64 \t 0.57\n",
      "40 \t 0.6 \t 0.55 \t 0.59 \t 0.57\n",
      "41 \t 0.64 \t 0.56 \t 0.67 \t 0.61\n",
      "42 \t 0.6 \t 0.53 \t 0.63 \t 0.57\n",
      "43 \t 0.64 \t 0.56 \t 0.68 \t 0.62\n",
      "44 \t 0.58 \t 0.5 \t 0.59 \t 0.54\n",
      "45 \t 0.64 \t 0.59 \t 0.67 \t 0.63\n",
      "46 \t 0.61 \t 0.49 \t 0.64 \t 0.56\n",
      "47 \t 0.58 \t 0.46 \t 0.59 \t 0.52\n",
      "48 \t 0.64 \t 0.59 \t 0.7 \t 0.64\n",
      "49 \t 0.61 \t 0.48 \t 0.66 \t 0.55\n",
      "50 \t 0.61 \t 0.53 \t 0.65 \t 0.58\n",
      "51 \t 0.62 \t 0.56 \t 0.59 \t 0.58\n",
      "52 \t 0.63 \t 0.55 \t 0.68 \t 0.61\n",
      "53 \t 0.65 \t 0.57 \t 0.67 \t 0.62\n",
      "54 \t 0.63 \t 0.55 \t 0.62 \t 0.58\n",
      "55 \t 0.58 \t 0.45 \t 0.6 \t 0.52\n",
      "56 \t 0.61 \t 0.53 \t 0.65 \t 0.59\n",
      "57 \t 0.63 \t 0.52 \t 0.69 \t 0.59\n",
      "58 \t 0.64 \t 0.57 \t 0.66 \t 0.61\n",
      "59 \t 0.57 \t 0.53 \t 0.59 \t 0.56\n",
      "60 \t 0.58 \t 0.49 \t 0.57 \t 0.53\n",
      "61 \t 0.6 \t 0.48 \t 0.65 \t 0.55\n",
      "62 \t 0.57 \t 0.51 \t 0.65 \t 0.57\n",
      "63 \t 0.57 \t 0.47 \t 0.58 \t 0.52\n",
      "64 \t 0.58 \t 0.45 \t 0.67 \t 0.54\n",
      "65 \t 0.6 \t 0.56 \t 0.59 \t 0.57\n",
      "66 \t 0.6 \t 0.5 \t 0.6 \t 0.54\n",
      "67 \t 0.64 \t 0.52 \t 0.61 \t 0.56\n",
      "68 \t 0.58 \t 0.47 \t 0.59 \t 0.53\n",
      "69 \t 0.6 \t 0.52 \t 0.62 \t 0.56\n",
      "70 \t 0.6 \t 0.52 \t 0.65 \t 0.58\n",
      "71 \t 0.6 \t 0.57 \t 0.61 \t 0.58\n",
      "72 \t 0.64 \t 0.59 \t 0.68 \t 0.63\n",
      "73 \t 0.57 \t 0.52 \t 0.6 \t 0.56\n",
      "74 \t 0.6 \t 0.53 \t 0.66 \t 0.59\n",
      "75 \t 0.62 \t 0.56 \t 0.63 \t 0.6\n",
      "76 \t 0.58 \t 0.47 \t 0.58 \t 0.52\n",
      "77 \t 0.62 \t 0.52 \t 0.67 \t 0.58\n",
      "78 \t 0.62 \t 0.54 \t 0.65 \t 0.59\n",
      "79 \t 0.6 \t 0.51 \t 0.62 \t 0.56\n",
      "80 \t 0.64 \t 0.54 \t 0.65 \t 0.59\n",
      "81 \t 0.6 \t 0.53 \t 0.6 \t 0.56\n",
      "82 \t 0.58 \t 0.54 \t 0.63 \t 0.58\n",
      "83 \t 0.63 \t 0.57 \t 0.69 \t 0.62\n",
      "84 \t 0.6 \t 0.51 \t 0.58 \t 0.54\n",
      "85 \t 0.62 \t 0.57 \t 0.65 \t 0.61\n",
      "86 \t 0.6 \t 0.46 \t 0.61 \t 0.53\n",
      "87 \t 0.63 \t 0.56 \t 0.66 \t 0.6\n",
      "88 \t 0.58 \t 0.45 \t 0.6 \t 0.51\n",
      "89 \t 0.62 \t 0.52 \t 0.65 \t 0.58\n",
      "90 \t 0.6 \t 0.54 \t 0.57 \t 0.56\n",
      "91 \t 0.64 \t 0.51 \t 0.64 \t 0.57\n",
      "92 \t 0.6 \t 0.5 \t 0.61 \t 0.55\n",
      "93 \t 0.6 \t 0.53 \t 0.62 \t 0.57\n",
      "94 \t 0.6 \t 0.51 \t 0.59 \t 0.55\n",
      "95 \t 0.61 \t 0.54 \t 0.64 \t 0.59\n",
      "96 \t 0.63 \t 0.58 \t 0.68 \t 0.63\n",
      "97 \t 0.62 \t 0.54 \t 0.65 \t 0.59\n",
      "98 \t 0.62 \t 0.57 \t 0.67 \t 0.61\n",
      "99 \t 0.61 \t 0.49 \t 0.62 \t 0.55\n",
      "29 0.71 48 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(tfidf, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = tree.DecisionTreeClassifier()\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.72 \t 0.76 \t 0.71 \t 0.74\n",
      "1 \t 0.72 \t 0.77 \t 0.72 \t 0.74\n",
      "2 \t 0.64 \t 0.6 \t 0.66 \t 0.63\n",
      "3 \t 0.7 \t 0.76 \t 0.68 \t 0.72\n",
      "4 \t 0.68 \t 0.7 \t 0.7 \t 0.7\n",
      "5 \t 0.72 \t 0.73 \t 0.7 \t 0.71\n",
      "6 \t 0.67 \t 0.69 \t 0.66 \t 0.67\n",
      "7 \t 0.7 \t 0.71 \t 0.71 \t 0.71\n",
      "8 \t 0.68 \t 0.7 \t 0.71 \t 0.71\n",
      "9 \t 0.73 \t 0.75 \t 0.75 \t 0.75\n",
      "10 \t 0.71 \t 0.74 \t 0.69 \t 0.72\n",
      "11 \t 0.66 \t 0.68 \t 0.67 \t 0.67\n",
      "12 \t 0.69 \t 0.73 \t 0.67 \t 0.7\n",
      "13 \t 0.7 \t 0.7 \t 0.73 \t 0.71\n",
      "14 \t 0.66 \t 0.71 \t 0.63 \t 0.67\n",
      "15 \t 0.7 \t 0.71 \t 0.71 \t 0.71\n",
      "16 \t 0.68 \t 0.67 \t 0.71 \t 0.69\n",
      "17 \t 0.71 \t 0.72 \t 0.7 \t 0.71\n",
      "18 \t 0.65 \t 0.67 \t 0.66 \t 0.66\n",
      "19 \t 0.68 \t 0.72 \t 0.68 \t 0.7\n",
      "20 \t 0.69 \t 0.7 \t 0.68 \t 0.69\n",
      "21 \t 0.72 \t 0.75 \t 0.73 \t 0.74\n",
      "22 \t 0.71 \t 0.72 \t 0.68 \t 0.7\n",
      "23 \t 0.7 \t 0.75 \t 0.7 \t 0.72\n",
      "24 \t 0.68 \t 0.71 \t 0.67 \t 0.69\n",
      "25 \t 0.73 \t 0.78 \t 0.68 \t 0.73\n",
      "26 \t 0.69 \t 0.65 \t 0.74 \t 0.69\n",
      "27 \t 0.76 \t 0.8 \t 0.74 \t 0.77\n",
      "28 \t 0.71 \t 0.76 \t 0.72 \t 0.74\n",
      "29 \t 0.7 \t 0.72 \t 0.7 \t 0.71\n",
      "30 \t 0.72 \t 0.8 \t 0.69 \t 0.74\n",
      "31 \t 0.69 \t 0.69 \t 0.69 \t 0.69\n",
      "32 \t 0.67 \t 0.67 \t 0.63 \t 0.65\n",
      "33 \t 0.72 \t 0.78 \t 0.68 \t 0.73\n",
      "34 \t 0.7 \t 0.71 \t 0.71 \t 0.71\n",
      "35 \t 0.68 \t 0.69 \t 0.68 \t 0.69\n",
      "36 \t 0.69 \t 0.68 \t 0.69 \t 0.68\n",
      "37 \t 0.66 \t 0.67 \t 0.66 \t 0.67\n",
      "38 \t 0.66 \t 0.67 \t 0.67 \t 0.67\n",
      "39 \t 0.65 \t 0.66 \t 0.67 \t 0.66\n",
      "40 \t 0.74 \t 0.76 \t 0.72 \t 0.74\n",
      "41 \t 0.71 \t 0.73 \t 0.7 \t 0.72\n",
      "42 \t 0.67 \t 0.67 \t 0.69 \t 0.68\n",
      "43 \t 0.69 \t 0.68 \t 0.72 \t 0.7\n",
      "44 \t 0.69 \t 0.75 \t 0.67 \t 0.7\n",
      "45 \t 0.71 \t 0.75 \t 0.7 \t 0.73\n",
      "46 \t 0.72 \t 0.73 \t 0.72 \t 0.72\n",
      "47 \t 0.68 \t 0.7 \t 0.67 \t 0.68\n",
      "48 \t 0.71 \t 0.73 \t 0.73 \t 0.73\n",
      "49 \t 0.69 \t 0.67 \t 0.7 \t 0.69\n",
      "50 \t 0.68 \t 0.66 \t 0.7 \t 0.68\n",
      "51 \t 0.69 \t 0.74 \t 0.64 \t 0.69\n",
      "52 \t 0.7 \t 0.7 \t 0.72 \t 0.71\n",
      "53 \t 0.71 \t 0.76 \t 0.69 \t 0.72\n",
      "54 \t 0.7 \t 0.71 \t 0.68 \t 0.69\n",
      "55 \t 0.68 \t 0.73 \t 0.65 \t 0.69\n",
      "56 \t 0.7 \t 0.7 \t 0.71 \t 0.71\n",
      "57 \t 0.74 \t 0.74 \t 0.75 \t 0.74\n",
      "58 \t 0.69 \t 0.69 \t 0.69 \t 0.69\n",
      "59 \t 0.67 \t 0.71 \t 0.66 \t 0.69\n",
      "60 \t 0.7 \t 0.76 \t 0.67 \t 0.71\n",
      "61 \t 0.7 \t 0.71 \t 0.7 \t 0.71\n",
      "62 \t 0.69 \t 0.71 \t 0.72 \t 0.72\n",
      "63 \t 0.68 \t 0.71 \t 0.67 \t 0.69\n",
      "64 \t 0.7 \t 0.7 \t 0.74 \t 0.72\n",
      "65 \t 0.74 \t 0.76 \t 0.71 \t 0.74\n",
      "66 \t 0.68 \t 0.7 \t 0.65 \t 0.68\n",
      "67 \t 0.68 \t 0.72 \t 0.62 \t 0.67\n",
      "68 \t 0.68 \t 0.67 \t 0.68 \t 0.67\n",
      "69 \t 0.69 \t 0.75 \t 0.67 \t 0.71\n",
      "70 \t 0.71 \t 0.75 \t 0.71 \t 0.73\n",
      "71 \t 0.7 \t 0.73 \t 0.68 \t 0.7\n",
      "72 \t 0.7 \t 0.73 \t 0.71 \t 0.72\n",
      "73 \t 0.71 \t 0.75 \t 0.7 \t 0.72\n",
      "74 \t 0.69 \t 0.66 \t 0.74 \t 0.7\n",
      "75 \t 0.72 \t 0.76 \t 0.7 \t 0.73\n",
      "76 \t 0.65 \t 0.67 \t 0.62 \t 0.65\n",
      "77 \t 0.71 \t 0.74 \t 0.71 \t 0.72\n",
      "78 \t 0.68 \t 0.69 \t 0.68 \t 0.68\n",
      "79 \t 0.66 \t 0.64 \t 0.67 \t 0.65\n",
      "80 \t 0.69 \t 0.73 \t 0.66 \t 0.69\n",
      "81 \t 0.69 \t 0.73 \t 0.66 \t 0.69\n",
      "82 \t 0.68 \t 0.71 \t 0.69 \t 0.7\n",
      "83 \t 0.72 \t 0.74 \t 0.74 \t 0.74\n",
      "84 \t 0.68 \t 0.76 \t 0.63 \t 0.69\n",
      "85 \t 0.73 \t 0.77 \t 0.73 \t 0.75\n",
      "86 \t 0.7 \t 0.7 \t 0.68 \t 0.69\n",
      "87 \t 0.7 \t 0.73 \t 0.69 \t 0.71\n",
      "88 \t 0.7 \t 0.68 \t 0.7 \t 0.69\n",
      "89 \t 0.72 \t 0.76 \t 0.7 \t 0.73\n",
      "90 \t 0.7 \t 0.75 \t 0.65 \t 0.69\n",
      "91 \t 0.71 \t 0.72 \t 0.68 \t 0.7\n",
      "92 \t 0.68 \t 0.68 \t 0.68 \t 0.68\n",
      "93 \t 0.69 \t 0.73 \t 0.68 \t 0.7\n",
      "94 \t 0.7 \t 0.74 \t 0.67 \t 0.7\n",
      "95 \t 0.74 \t 0.79 \t 0.73 \t 0.76\n",
      "96 \t 0.68 \t 0.77 \t 0.68 \t 0.72\n",
      "97 \t 0.7 \t 0.71 \t 0.71 \t 0.71\n",
      "98 \t 0.7 \t 0.72 \t 0.71 \t 0.72\n",
      "99 \t 0.7 \t 0.7 \t 0.69 \t 0.69\n",
      "9 0.75 27 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(tfidf, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = LogisticRegression()\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.7 \t 0.72 \t 0.7 \t 0.71\n",
      "1 \t 0.73 \t 0.75 \t 0.73 \t 0.74\n",
      "2 \t 0.64 \t 0.62 \t 0.65 \t 0.64\n",
      "3 \t 0.67 \t 0.7 \t 0.66 \t 0.68\n",
      "4 \t 0.67 \t 0.69 \t 0.68 \t 0.69\n",
      "5 \t 0.71 \t 0.7 \t 0.7 \t 0.7\n",
      "6 \t 0.65 \t 0.7 \t 0.63 \t 0.66\n",
      "7 \t 0.7 \t 0.69 \t 0.72 \t 0.7\n",
      "8 \t 0.69 \t 0.68 \t 0.72 \t 0.7\n",
      "9 \t 0.71 \t 0.75 \t 0.73 \t 0.74\n",
      "10 \t 0.68 \t 0.68 \t 0.67 \t 0.68\n",
      "11 \t 0.68 \t 0.69 \t 0.68 \t 0.68\n",
      "12 \t 0.68 \t 0.7 \t 0.67 \t 0.68\n",
      "13 \t 0.68 \t 0.68 \t 0.72 \t 0.7\n",
      "14 \t 0.67 \t 0.73 \t 0.64 \t 0.68\n",
      "15 \t 0.68 \t 0.69 \t 0.68 \t 0.69\n",
      "16 \t 0.66 \t 0.66 \t 0.68 \t 0.67\n",
      "17 \t 0.7 \t 0.7 \t 0.7 \t 0.7\n",
      "18 \t 0.67 \t 0.67 \t 0.69 \t 0.68\n",
      "19 \t 0.67 \t 0.69 \t 0.68 \t 0.68\n",
      "20 \t 0.69 \t 0.69 \t 0.69 \t 0.69\n",
      "21 \t 0.72 \t 0.72 \t 0.73 \t 0.73\n",
      "22 \t 0.72 \t 0.74 \t 0.69 \t 0.71\n",
      "23 \t 0.7 \t 0.72 \t 0.7 \t 0.71\n",
      "24 \t 0.66 \t 0.67 \t 0.66 \t 0.67\n",
      "25 \t 0.7 \t 0.78 \t 0.65 \t 0.71\n",
      "26 \t 0.69 \t 0.65 \t 0.73 \t 0.69\n",
      "27 \t 0.72 \t 0.75 \t 0.71 \t 0.73\n",
      "28 \t 0.72 \t 0.77 \t 0.73 \t 0.75\n",
      "29 \t 0.7 \t 0.7 \t 0.7 \t 0.7\n",
      "30 \t 0.72 \t 0.78 \t 0.7 \t 0.74\n",
      "31 \t 0.68 \t 0.69 \t 0.68 \t 0.69\n",
      "32 \t 0.66 \t 0.65 \t 0.62 \t 0.64\n",
      "33 \t 0.74 \t 0.79 \t 0.69 \t 0.74\n",
      "34 \t 0.7 \t 0.71 \t 0.72 \t 0.71\n",
      "35 \t 0.68 \t 0.69 \t 0.68 \t 0.69\n",
      "36 \t 0.68 \t 0.66 \t 0.68 \t 0.67\n",
      "37 \t 0.66 \t 0.66 \t 0.65 \t 0.66\n",
      "38 \t 0.65 \t 0.67 \t 0.67 \t 0.67\n",
      "39 \t 0.65 \t 0.65 \t 0.68 \t 0.66\n",
      "40 \t 0.72 \t 0.72 \t 0.7 \t 0.71\n",
      "41 \t 0.72 \t 0.72 \t 0.71 \t 0.72\n",
      "42 \t 0.68 \t 0.69 \t 0.69 \t 0.69\n",
      "43 \t 0.69 \t 0.67 \t 0.72 \t 0.69\n",
      "44 \t 0.7 \t 0.74 \t 0.68 \t 0.71\n",
      "45 \t 0.7 \t 0.72 \t 0.7 \t 0.71\n",
      "46 \t 0.71 \t 0.7 \t 0.71 \t 0.71\n",
      "47 \t 0.67 \t 0.69 \t 0.65 \t 0.67\n",
      "48 \t 0.69 \t 0.72 \t 0.71 \t 0.71\n",
      "49 \t 0.69 \t 0.67 \t 0.7 \t 0.69\n",
      "50 \t 0.7 \t 0.71 \t 0.71 \t 0.71\n",
      "51 \t 0.7 \t 0.73 \t 0.66 \t 0.69\n",
      "52 \t 0.68 \t 0.68 \t 0.71 \t 0.69\n",
      "53 \t 0.72 \t 0.78 \t 0.7 \t 0.74\n",
      "54 \t 0.69 \t 0.71 \t 0.66 \t 0.69\n",
      "55 \t 0.69 \t 0.74 \t 0.67 \t 0.7\n",
      "56 \t 0.68 \t 0.67 \t 0.7 \t 0.68\n",
      "57 \t 0.73 \t 0.74 \t 0.74 \t 0.74\n",
      "58 \t 0.7 \t 0.69 \t 0.7 \t 0.69\n",
      "59 \t 0.66 \t 0.72 \t 0.65 \t 0.68\n",
      "60 \t 0.7 \t 0.78 \t 0.65 \t 0.71\n",
      "61 \t 0.69 \t 0.69 \t 0.7 \t 0.7\n",
      "62 \t 0.68 \t 0.7 \t 0.71 \t 0.71\n",
      "63 \t 0.7 \t 0.73 \t 0.69 \t 0.71\n",
      "64 \t 0.7 \t 0.69 \t 0.73 \t 0.71\n",
      "65 \t 0.73 \t 0.74 \t 0.71 \t 0.73\n",
      "66 \t 0.69 \t 0.7 \t 0.66 \t 0.68\n",
      "67 \t 0.68 \t 0.72 \t 0.62 \t 0.66\n",
      "68 \t 0.66 \t 0.63 \t 0.65 \t 0.64\n",
      "69 \t 0.7 \t 0.75 \t 0.67 \t 0.71\n",
      "70 \t 0.72 \t 0.75 \t 0.72 \t 0.74\n",
      "71 \t 0.7 \t 0.7 \t 0.69 \t 0.7\n",
      "72 \t 0.71 \t 0.72 \t 0.73 \t 0.73\n",
      "73 \t 0.7 \t 0.74 \t 0.7 \t 0.72\n",
      "74 \t 0.72 \t 0.68 \t 0.77 \t 0.72\n",
      "75 \t 0.72 \t 0.76 \t 0.7 \t 0.73\n",
      "76 \t 0.62 \t 0.65 \t 0.6 \t 0.63\n",
      "77 \t 0.7 \t 0.74 \t 0.71 \t 0.72\n",
      "78 \t 0.68 \t 0.7 \t 0.68 \t 0.69\n",
      "79 \t 0.68 \t 0.65 \t 0.69 \t 0.67\n",
      "80 \t 0.68 \t 0.72 \t 0.65 \t 0.68\n",
      "81 \t 0.71 \t 0.74 \t 0.68 \t 0.71\n",
      "82 \t 0.67 \t 0.7 \t 0.68 \t 0.69\n",
      "83 \t 0.72 \t 0.78 \t 0.73 \t 0.75\n",
      "84 \t 0.66 \t 0.75 \t 0.61 \t 0.67\n",
      "85 \t 0.73 \t 0.75 \t 0.74 \t 0.75\n",
      "86 \t 0.68 \t 0.69 \t 0.66 \t 0.67\n",
      "87 \t 0.69 \t 0.72 \t 0.68 \t 0.7\n",
      "88 \t 0.7 \t 0.66 \t 0.71 \t 0.68\n",
      "89 \t 0.72 \t 0.76 \t 0.71 \t 0.73\n",
      "90 \t 0.71 \t 0.77 \t 0.66 \t 0.71\n",
      "91 \t 0.72 \t 0.71 \t 0.69 \t 0.7\n",
      "92 \t 0.68 \t 0.7 \t 0.67 \t 0.68\n",
      "93 \t 0.66 \t 0.7 \t 0.66 \t 0.68\n",
      "94 \t 0.68 \t 0.71 \t 0.65 \t 0.68\n",
      "95 \t 0.72 \t 0.77 \t 0.71 \t 0.74\n",
      "96 \t 0.7 \t 0.77 \t 0.7 \t 0.73\n",
      "97 \t 0.72 \t 0.7 \t 0.73 \t 0.72\n",
      "98 \t 0.68 \t 0.7 \t 0.69 \t 0.7\n",
      "99 \t 0.7 \t 0.7 \t 0.69 \t 0.69\n",
      "74 0.77 83 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(tfidf, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = svm.SVC(gamma='auto', C=1.0, kernel='linear', probability=True)\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0 \t 0.65 \t 0.58 \t 0.68 \t 0.63\n",
      "0 \t 1 \t 0.65 \t 0.59 \t 0.68 \t 0.64\n",
      "0 \t 2 \t 0.66 \t 0.61 \t 0.69 \t 0.65\n",
      "0 \t 3 \t 0.65 \t 0.59 \t 0.68 \t 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(50):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(tfidf, data_frame['classificacao'], random_state = i, test_size = 0.2)\n",
    "\n",
    "    max_f1_j = 0\n",
    "    max_precision_j = 0\n",
    "    max_j_f1 = 0\n",
    "    max_j_precision = 0\n",
    "\n",
    "    for j in range(50):\n",
    "        # Treina o modelo usando o conjunto de dados de treino:\n",
    "        classificador = MLPClassifier(activation='relu', solver='adam', max_iter=10000, alpha=1e-10, random_state=j)\n",
    "        classificador.fit(treino, classe_treino)\n",
    "\n",
    "        # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "        previsao = classificador.predict_proba(teste)\n",
    "\n",
    "        # transforma as saídas classificadas de acordo com um limiar:\n",
    "        previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "        # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "        previsao_int = previsao_bool.astype(np.int)\n",
    "\n",
    "        f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "        accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "        precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "        recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "\n",
    "        if(max_f1_j < f1_score): \n",
    "            max_f1_j = f1_score\n",
    "            max_j_f1 = j\n",
    "\n",
    "        if(max_precision_j < precision): \n",
    "            max_precision_j = precision\n",
    "            max_j_precision = j\n",
    "\n",
    "        # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "        print(i, '\\t', j, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "\n",
    "    print(max_j_precision, round(max_precision_j, 2), max_j_f1, round(max_f1_j, 2))\n",
    "    \n",
    "    if(max_f1 < max_f1_j): \n",
    "        max_f1 = max_f1_j\n",
    "        max_i_f1 = i\n",
    "\n",
    "    if(max_precision < max_precision_j): \n",
    "        max_precision = max_precision_j\n",
    "        max_i_precision = i\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.66 \t 0.83 \t 0.63 \t 0.71\n",
      "1 \t 0.64 \t 0.81 \t 0.61 \t 0.7\n",
      "2 \t 0.62 \t 0.78 \t 0.6 \t 0.68\n",
      "3 \t 0.62 \t 0.8 \t 0.59 \t 0.68\n",
      "4 \t 0.62 \t 0.8 \t 0.6 \t 0.69\n",
      "5 \t 0.65 \t 0.81 \t 0.6 \t 0.69\n",
      "6 \t 0.61 \t 0.73 \t 0.58 \t 0.65\n",
      "7 \t 0.66 \t 0.81 \t 0.64 \t 0.72\n",
      "8 \t 0.68 \t 0.81 \t 0.67 \t 0.73\n",
      "9 \t 0.64 \t 0.83 \t 0.62 \t 0.71\n",
      "10 \t 0.64 \t 0.81 \t 0.6 \t 0.69\n",
      "11 \t 0.62 \t 0.75 \t 0.6 \t 0.67\n",
      "12 \t 0.64 \t 0.83 \t 0.6 \t 0.7\n",
      "13 \t 0.64 \t 0.78 \t 0.64 \t 0.7\n",
      "14 \t 0.58 \t 0.78 \t 0.55 \t 0.64\n",
      "15 \t 0.62 \t 0.76 \t 0.6 \t 0.67\n",
      "16 \t 0.66 \t 0.79 \t 0.65 \t 0.71\n",
      "17 \t 0.64 \t 0.8 \t 0.61 \t 0.69\n",
      "18 \t 0.6 \t 0.79 \t 0.59 \t 0.68\n",
      "19 \t 0.64 \t 0.81 \t 0.62 \t 0.7\n",
      "20 \t 0.62 \t 0.8 \t 0.59 \t 0.68\n",
      "21 \t 0.66 \t 0.81 \t 0.63 \t 0.71\n",
      "22 \t 0.64 \t 0.78 \t 0.59 \t 0.67\n",
      "23 \t 0.64 \t 0.83 \t 0.62 \t 0.71\n",
      "24 \t 0.62 \t 0.78 \t 0.6 \t 0.68\n",
      "25 \t 0.65 \t 0.82 \t 0.59 \t 0.69\n",
      "26 \t 0.66 \t 0.81 \t 0.64 \t 0.72\n",
      "27 \t 0.64 \t 0.81 \t 0.61 \t 0.7\n",
      "28 \t 0.66 \t 0.81 \t 0.64 \t 0.72\n",
      "29 \t 0.66 \t 0.79 \t 0.63 \t 0.7\n",
      "30 \t 0.66 \t 0.84 \t 0.62 \t 0.71\n",
      "31 \t 0.62 \t 0.78 \t 0.6 \t 0.68\n",
      "32 \t 0.6 \t 0.82 \t 0.54 \t 0.65\n",
      "33 \t 0.63 \t 0.82 \t 0.58 \t 0.68\n",
      "34 \t 0.64 \t 0.82 \t 0.61 \t 0.7\n",
      "35 \t 0.63 \t 0.8 \t 0.61 \t 0.69\n",
      "36 \t 0.62 \t 0.74 \t 0.59 \t 0.66\n",
      "37 \t 0.6 \t 0.76 \t 0.58 \t 0.66\n",
      "38 \t 0.63 \t 0.74 \t 0.62 \t 0.68\n",
      "39 \t 0.62 \t 0.8 \t 0.61 \t 0.69\n",
      "40 \t 0.67 \t 0.82 \t 0.62 \t 0.71\n",
      "41 \t 0.65 \t 0.81 \t 0.61 \t 0.7\n",
      "42 \t 0.63 \t 0.79 \t 0.61 \t 0.69\n",
      "43 \t 0.66 \t 0.81 \t 0.63 \t 0.71\n",
      "44 \t 0.59 \t 0.77 \t 0.56 \t 0.65\n",
      "45 \t 0.63 \t 0.8 \t 0.6 \t 0.69\n",
      "46 \t 0.66 \t 0.81 \t 0.63 \t 0.71\n",
      "47 \t 0.62 \t 0.75 \t 0.58 \t 0.65\n",
      "48 \t 0.64 \t 0.78 \t 0.63 \t 0.7\n",
      "49 \t 0.6 \t 0.72 \t 0.59 \t 0.65\n",
      "50 \t 0.66 \t 0.78 \t 0.64 \t 0.7\n",
      "51 \t 0.6 \t 0.79 \t 0.55 \t 0.65\n",
      "52 \t 0.65 \t 0.77 \t 0.64 \t 0.7\n",
      "53 \t 0.61 \t 0.85 \t 0.57 \t 0.68\n",
      "54 \t 0.63 \t 0.79 \t 0.58 \t 0.67\n",
      "55 \t 0.62 \t 0.83 \t 0.58 \t 0.68\n",
      "56 \t 0.66 \t 0.8 \t 0.64 \t 0.71\n",
      "57 \t 0.65 \t 0.76 \t 0.64 \t 0.69\n",
      "58 \t 0.63 \t 0.82 \t 0.59 \t 0.69\n",
      "59 \t 0.6 \t 0.82 \t 0.57 \t 0.67\n",
      "60 \t 0.62 \t 0.82 \t 0.57 \t 0.67\n",
      "61 \t 0.64 \t 0.78 \t 0.62 \t 0.69\n",
      "62 \t 0.62 \t 0.73 \t 0.64 \t 0.68\n",
      "63 \t 0.6 \t 0.78 \t 0.57 \t 0.66\n",
      "64 \t 0.67 \t 0.81 \t 0.66 \t 0.72\n",
      "65 \t 0.63 \t 0.8 \t 0.58 \t 0.68\n",
      "66 \t 0.6 \t 0.78 \t 0.56 \t 0.65\n",
      "67 \t 0.61 \t 0.82 \t 0.54 \t 0.65\n",
      "68 \t 0.62 \t 0.77 \t 0.58 \t 0.66\n",
      "69 \t 0.6 \t 0.81 \t 0.57 \t 0.67\n",
      "70 \t 0.64 \t 0.78 \t 0.62 \t 0.69\n",
      "71 \t 0.63 \t 0.8 \t 0.59 \t 0.68\n",
      "72 \t 0.66 \t 0.82 \t 0.64 \t 0.72\n",
      "73 \t 0.63 \t 0.77 \t 0.61 \t 0.68\n",
      "74 \t 0.64 \t 0.78 \t 0.64 \t 0.7\n",
      "75 \t 0.65 \t 0.83 \t 0.61 \t 0.7\n",
      "76 \t 0.6 \t 0.76 \t 0.57 \t 0.65\n",
      "77 \t 0.65 \t 0.8 \t 0.63 \t 0.7\n",
      "78 \t 0.67 \t 0.83 \t 0.63 \t 0.72\n",
      "79 \t 0.62 \t 0.76 \t 0.59 \t 0.66\n",
      "80 \t 0.66 \t 0.83 \t 0.61 \t 0.7\n",
      "81 \t 0.63 \t 0.81 \t 0.58 \t 0.68\n",
      "82 \t 0.62 \t 0.79 \t 0.61 \t 0.69\n",
      "83 \t 0.62 \t 0.79 \t 0.62 \t 0.69\n",
      "84 \t 0.59 \t 0.81 \t 0.54 \t 0.65\n",
      "85 \t 0.7 \t 0.86 \t 0.66 \t 0.75\n",
      "86 \t 0.63 \t 0.79 \t 0.59 \t 0.67\n",
      "87 \t 0.62 \t 0.81 \t 0.59 \t 0.68\n",
      "88 \t 0.62 \t 0.77 \t 0.59 \t 0.67\n",
      "89 \t 0.64 \t 0.79 \t 0.61 \t 0.69\n",
      "90 \t 0.58 \t 0.83 \t 0.53 \t 0.65\n",
      "91 \t 0.64 \t 0.79 \t 0.59 \t 0.67\n",
      "92 \t 0.61 \t 0.79 \t 0.58 \t 0.67\n",
      "93 \t 0.61 \t 0.77 \t 0.59 \t 0.67\n",
      "94 \t 0.6 \t 0.8 \t 0.56 \t 0.66\n",
      "95 \t 0.66 \t 0.82 \t 0.63 \t 0.71\n",
      "96 \t 0.66 \t 0.84 \t 0.63 \t 0.72\n",
      "97 \t 0.66 \t 0.79 \t 0.63 \t 0.7\n",
      "98 \t 0.62 \t 0.79 \t 0.6 \t 0.68\n",
      "99 \t 0.64 \t 0.79 \t 0.59 \t 0.68\n",
      "8 0.67 85 0.75\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "max_f1 = 0\n",
    "max_precision = 0\n",
    "max_i_f1 = 0\n",
    "max_i_precision = 0\n",
    "\n",
    "for i in range(100):\n",
    "    # Separa o corpus em conjunto de dados de treino e de teste.\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(tfidf, data_frame['classificacao'], random_state = i, test_size = 0.1)\n",
    "\n",
    "    # Treina o modelo usando o conjunto de dados de treino:\n",
    "    classificador = XGBClassifier()\n",
    "    classificador.fit(treino, classe_treino)\n",
    "\n",
    "    # realiza a classificação usando os dados de teste e o modelo treinado anteriormente:\n",
    "    previsao = classificador.predict_proba(teste)\n",
    "\n",
    "    # transforma as saídas classificadas de acordo com um limiar:\n",
    "    previsao_bool = previsao[:,1] >= 0.5\n",
    "\n",
    "    # transforma as saídas classificadas (booleanas) em valores inteiros:\n",
    "    previsao_int = previsao_bool.astype(np.int)\n",
    "    \n",
    "    f1_score = metrics.f1_score(classe_teste, previsao_int)\n",
    "    accuracy = metrics.accuracy_score(classe_teste, previsao_int)\n",
    "    precision = metrics.precision_score(classe_teste, previsao_int)\n",
    "    recall = metrics.recall_score(classe_teste, previsao_int)\n",
    "    \n",
    "    if(max_f1 < f1_score): \n",
    "        max_f1 = f1_score\n",
    "        max_i_f1 = i\n",
    "        \n",
    "    if(max_precision < precision): \n",
    "        max_precision = precision\n",
    "        max_i_precision = i\n",
    "\n",
    "    # Apresenta os resultados de avaliação do algoritmo de classificação\n",
    "    print(i, '\\t', round(accuracy,2), '\\t', round(recall,2), '\\t', round(precision,2), '\\t', round(f1_score,2))\n",
    "    \n",
    "print(max_i_precision, round(max_precision, 2), max_i_f1, round(max_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
