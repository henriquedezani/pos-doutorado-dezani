{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carrega o arquivo com as sentenças (Córpus da Gabriela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenca_original</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Traidor e ajudante...</td>\n",
       "      <td>Traidor e ajudante...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Um  maluco corrupto  se unindo a um  traíra .</td>\n",
       "      <td>Um  maluco corrupto  se unindo a um  traíra .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Isso não vai dar certo.</td>\n",
       "      <td>Isso não vai dar certo.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT e PMDB destruiram a economia do brasil, lev...</td>\n",
       "      <td>PT e PMDB destruiram a economia do brasil, lev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O Cunha foi escalado para vilão.</td>\n",
       "      <td>O Cunha foi escalado para vilão.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentenca_original  \\\n",
       "0                              Traidor e ajudante...   \n",
       "1      Um  maluco corrupto  se unindo a um  traíra .   \n",
       "2                            Isso não vai dar certo.   \n",
       "3  PT e PMDB destruiram a economia do brasil, lev...   \n",
       "4                   O Cunha foi escalado para vilão.   \n",
       "\n",
       "                                sentenca_processada1  classificacao  \n",
       "0                              Traidor e ajudante...              0  \n",
       "1      Um  maluco corrupto  se unindo a um  traíra .              0  \n",
       "2                            Isso não vai dar certo.              0  \n",
       "3  PT e PMDB destruiram a economia do brasil, lev...              0  \n",
       "4                   O Cunha foi escalado para vilão.              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    10417\n",
      " 1     2192\n",
      "-1     1992\n",
      "Name: classificacao, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['classificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Atualiza o DataFrame com apenas as classificações irônicas e não irônicas (2.000 para cada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ironicas = list()\n",
    "naoironicas = list()\n",
    "\n",
    "ironicas = df.query('classificacao == 1')\n",
    "naoironicas = df.query('classificacao == 0')\n",
    "\n",
    "dados = ironicas[0:2000]\n",
    "dados = dados.append(naoironicas[0:2000])\n",
    "\n",
    "df = dados\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2000\n",
      "0    2000\n",
      "Name: classificacao, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['classificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Realiza um pre-processamento no dataset para remoção de caracteres especiais, vírgulas, pontos etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sents = list()\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    sents.append(re.sub(r'[^\\w\\s]','',sentenca))\n",
    "    \n",
    "df['sentenca_processada2'] = sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Realiza a obtenção das Features (utiliza sentenca_processada 1 e 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Folha, sempre tão solícita, só fez juntar os...</td>\n",
       "      <td>A Folha sempre tão solícita só fez juntar os d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o mensalão não termina no petrolão...</td>\n",
       "      <td>o mensalão não termina no petrolão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Para a tristeza da extrema-direita e da extrem...</td>\n",
       "      <td>Para a tristeza da extremadireita e da extrema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enquanto Temer tenta se safar, Cunha dará anda...</td>\n",
       "      <td>Enquanto Temer tenta se safar Cunha dará andam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Que dupla...</td>\n",
       "      <td>Que dupla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentenca_processada1  \\\n",
       "0  A Folha, sempre tão solícita, só fez juntar os...   \n",
       "1              o mensalão não termina no petrolão...   \n",
       "2  Para a tristeza da extrema-direita e da extrem...   \n",
       "3  Enquanto Temer tenta se safar, Cunha dará anda...   \n",
       "4                                       Que dupla...   \n",
       "\n",
       "                                sentenca_processada2  \n",
       "0  A Folha sempre tão solícita só fez juntar os d...  \n",
       "1                 o mensalão não termina no petrolão  \n",
       "2  Para a tristeza da extremadireita e da extrema...  \n",
       "3  Enquanto Temer tenta se safar Cunha dará andam...  \n",
       "4                                          Que dupla  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sentenca_processada1', 'sentenca_processada2']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Entidade Nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n",
      "627\n"
     ]
    }
   ],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "\n",
    "entidades_nomeadas = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    text = Text(sentenca, hint_language_code='pt',)\n",
    "    if len(text.entities) > 0:\n",
    "        if df['classificacao'][count] == 1:\n",
    "            ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0:\n",
    "            naoironicas = naoironicas + 1       \n",
    "        entidades_nomeadas.append(1)\n",
    "    else:\n",
    "        entidades_nomeadas.append(0)\n",
    "        \n",
    "    count = count + 1\n",
    "        \n",
    "            \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['entidades_nomeadas'] = entidades_nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2684\n",
       "1    1316\n",
       "Name: entidades_nomeadas, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entidades_nomeadas'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Adjetivos com polaridade positiva (no domínio político)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import nlpnet\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "stemmer = nltk.RSLPStemmer()\n",
    "\n",
    "# Define o etiquetador morfosintático do NLPNet:\n",
    "tagger_nplnet = nlpnet.POSTagger(data_dir='../pos-pt/', language='pt')\n",
    "\n",
    "# Lista de adjetivos de polaridade positiva bem marcados (Trabalho de Gabriela):\n",
    "lista_adjetivos_positivos = ['belo', 'bom', 'bem', 'excelente', 'extraordinário', 'fantástico', 'feliz', 'glorioso', 'heróico', 'hilário', \n",
    " 'honesto', 'ilustre', 'incrível', 'legal', 'limpo', 'lindo', 'majestoso', 'maravilhoso', 'nobre', 'ótimo', 'santo', 'satisfeito', \n",
    " 'solícito']\n",
    "\n",
    "# recupera as raizes das palavras:\n",
    "_lista_adjetivos_positivos = [stemmer.stem(palavra) for palavra in lista_adjetivos_positivos]\n",
    "\n",
    "__lista_adjetivos_positivos = [unidecode.unidecode(palavra) for palavra in _lista_adjetivos_positivos]\n",
    "  \n",
    "def contem_adjetivo_positivo_politico(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    for item in lista:\n",
    "        for (token, tag) in item:\n",
    "            if tag == 'ADJ' and any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_adjetivos_positivos):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "adjetivos = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_adjetivo_positivo_politico(sentenca):\n",
    "        adjetivos.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        adjetivos.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['adjetivos'] = adjetivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3857\n",
       "1     143\n",
       "Name: adjetivos, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['adjetivos'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773\n",
      "1835\n"
     ]
    }
   ],
   "source": [
    "# Lista de disparadores (Trabalho de Gabriela):\n",
    "lista_disparadores = ['aceitar', 'acreditar', 'adorar', 'alíquota', 'alma', 'amá-la', 'anjos', 'boa sorte', 'boa viagem', 'boa noite',\n",
    "  'bocadas', 'bondade', 'campanha', 'canonizá-lo', 'canonização', 'coincidência', 'coisa', 'comprar', 'contribuintes', 'contrição', \n",
    "  'corrupção', 'corruptos', 'cortar gastos', 'crescimento', 'crise', 'culpa', 'demitir', 'democracia', 'desemprego', 'desenvolvimento', \n",
    "  'desgoverno', 'desgraça', 'destruído', 'desvalorização', 'detalhe', 'deuses', 'dinheirama', 'dinheiro', 'ditador', 'dó', 'eleitoreiras', \n",
    "  'embuste', 'estrago', 'ética', 'expertise', 'financiar', 'fome', 'funcionar', 'ganhar', 'gastar', 'gostar', 'gostaria', 'grato', 'honestidade', \n",
    "  'ignorância', 'impeachment', 'inflação', 'investimento', 'lambuzou', 'liderança', 'louvor', 'megaempreiteiro', 'mensalão', 'mentiras', 'mídia',\n",
    "  'milagre', 'miséria', 'moral', 'moralidade', 'necessidade', 'obrigado', 'oposição', 'país', 'parabéns', 'parceria', 'partido', 'pedaladas', 'pena',\n",
    "  'política', 'político', 'prisão', 'quadrilha', 'quebrou', 'reeileição', 'refúgio', 'rombo', 'salve', 'santo', 'saudade', 'sindicalismo',\n",
    "  'solidariedade', 'subordinados', 'sugestivo', 'sugestões', 'surpresa', 'tomara', 'tucanas', 'verde-amarelo', 'vermelhos', 'vida']\n",
    "\n",
    "# recupera as raizes das palavras:\n",
    "_lista_disparadores = [stemmer.stem(palavra) for palavra in lista_disparadores]\n",
    "\n",
    "__lista_disparadores = [unidecode.unidecode(palavra) for palavra in _lista_disparadores]\n",
    "  \n",
    "def has_trigger(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca)\n",
    "    for token in tokens:\n",
    "        if any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_disparadores):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "triggers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if has_trigger(sentenca):\n",
    "        triggers.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        triggers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['triggers'] = triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3608\n",
       "0     392\n",
       "Name: triggers, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['triggers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Intensificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "import nlpnet\n",
    "\n",
    "# Define o etiquetador morfosintático do NLPNet:\n",
    "tagger_nplnet = nlpnet.POSTagger(data_dir='../pos-pt/', language='pt')\n",
    "\n",
    "# Intensificadores\n",
    "def contem_intensificadores(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    ADV = False\n",
    "    for item in lista:\n",
    "         for (_, tag) in item:\n",
    "            if tag == 'ADV':   \n",
    "                ADV = True\n",
    "            elif tag == 'ADJ':\n",
    "                if(ADV == True):           \n",
    "                    return True\n",
    "            else:\n",
    "                ADV = False\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "intensifiers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_intensificadores(sentenca):\n",
    "        intensifiers.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        intensifiers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['intensifiers'] = intensifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3847\n",
       "1     153\n",
       "Name: intensifiers, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intensifiers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Modificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1736\n",
      "1814\n"
     ]
    }
   ],
   "source": [
    "lista_modificadores = ['absolutamente', 'afinal', 'agora', 'apesar', 'até', 'aumento', 'como sempre', 'demais', 'do brasil', 'em paz', 'em solidariedade',\n",
    " 'extremamente', 'ficar longe', 'imagine', 'incondicionalmente', 'lindamente', 'logo agora', 'mais', 'manutenção', 'mas', 'menos',\n",
    "  'não é verdade', 'obrigatoriamente', 'ou melhor', 'pelo menos', 'pensando bem', 'porque', 'quanta', 'quão', 'sempre tão', 'simplesmente', 'só', 'todos']\n",
    "\n",
    "_lista_modificadores = [stemmer.stem(palavra) for palavra in lista_modificadores]\n",
    "\n",
    "__lista_modificadores = [unidecode.unidecode(palavra) for palavra in _lista_modificadores]\n",
    "\n",
    "def contem_modificadores(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca)\n",
    "    for token in tokens:\n",
    "        if any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_modificadores):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "modifiers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_modificadores(sentenca):\n",
    "        modifiers.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        modifiers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['modifiers'] = modifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3550\n",
       "0     450\n",
       "Name: modifiers, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modifiers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Quotation Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "def contem_palavras_com_aspas(sentenca):\n",
    "    result = re.findall(r'[\\'\\\"][\\w!?\\s]+[\\'\\\"]*', sentenca)    \n",
    "    if len(result) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "quotation_marks = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if contem_palavras_com_aspas(sentenca):\n",
    "        quotation_marks.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        quotation_marks.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['quotation_marks'] = quotation_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3727\n",
       "1     273\n",
       "Name: quotation_marks, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quotation_marks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. Pontuação Repetida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "def has_repeated_punctuation(sentenca):\n",
    "    result = re.findall(r'[!?.]+', sentenca)\n",
    "    for group in result:\n",
    "        if len(group) >= 2:\n",
    "            return True        \n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "repeated_punctuation = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_repeated_punctuation(sentenca):\n",
    "        repeated_punctuation.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        repeated_punctuation.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['repeated_punctuation'] = repeated_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3309\n",
       "1     691\n",
       "Name: repeated_punctuation, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['repeated_punctuation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8. Letras Repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "def has_letters_repetition(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    for item in lista:\n",
    "         for (token, tag) in item:\n",
    "            if(tag == 'N'):\n",
    "                result = re.findall(r'(\\w)\\1+', token.lower())\n",
    "                for group in result:\n",
    "                    if len(group) >= 1:\n",
    "                        return True        \n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "letters_repetition = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_letters_repetition(sentenca):\n",
    "        letters_repetition.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        letters_repetition.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['letters_repetition'] = letters_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3477\n",
       "1     523\n",
       "Name: letters_repetition, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letters_repetition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9. Palavras Repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def has_word_repetition(sentenca):\n",
    "    \n",
    "    _tokens = nltk.word_tokenize(sentenca.lower())\n",
    "    \n",
    "    _raizes = [stemmer.stem(palavra) for palavra in _tokens]\n",
    "\n",
    "    _sem_acentos = [unidecode.unidecode(palavra) for palavra in _raizes]\n",
    "\n",
    "    \n",
    "    if(max([len(list(group)) for key, group in groupby(_sem_acentos)])) > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "word_repetition = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_word_repetition(sentenca):\n",
    "        word_repetition.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        word_repetition.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['word_repetition'] = word_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3717\n",
       "1     283\n",
       "Name: word_repetition, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_repetition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10. Rethorical Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESENVOLVER!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.11. LIWC (Executar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "\n",
    "# stemmer = nltk.RSLPStemmer()\n",
    "lines = list()\n",
    "\n",
    "posemo = list()\n",
    "negemo = list()\n",
    "\n",
    "with open('liwc2.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    lines = [re.split(r'\\t+', line.rstrip('\\t')) for line in lines]\n",
    "    \n",
    "for line in lines:\n",
    "    if '126' in line:\n",
    "        posemo.append(unidecode.unidecode(line[0]))\n",
    "    if '127' in line:\n",
    "        negemo.append(unidecode.unidecode(line[0]))\n",
    "    \n",
    "# lines[68]\n",
    "# posemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rato', 'de', 'de', 'roma']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "tokens = nltk.word_tokenize(\"o rato roeu de a roupa do rei de roma\")\n",
    "# tokens\n",
    "\n",
    "tokens2 = nltk.word_tokenize(\"rato de de roma\")\n",
    "# tokens2\n",
    "\n",
    "intersection(tokens, tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721\n",
      "1612\n"
     ]
    }
   ],
   "source": [
    "###### LIWC ######\n",
    "import nltk \n",
    "\n",
    "def get_polaridade_sentenca(sentenca):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(sentenca.lower())\n",
    "    \n",
    "    positivo = 0\n",
    "    negativo = 0\n",
    "    \n",
    "    positivo = positivo + len(intersection(tokens, posemo))\n",
    "    negativo = negativo + len(intersection(tokens, negemo))\n",
    "    \n",
    "#     for token in tokens:\n",
    "#         if token in posemo:\n",
    "#             positivo = positivo + 1\n",
    "#         elif token in negemo:\n",
    "#             negativo = negativo + 1\n",
    "            \n",
    "\n",
    "    if (positivo >= negativo):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "liwc = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if get_polaridade_sentenca(sentenca) == 1:\n",
    "        liwc.append(1)\n",
    "        if df['classificacao'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['classificacao'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        liwc.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "# df['liwc'] = liwc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liwc'] = liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3333\n",
       "0     667\n",
       "Name: liwc, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['liwc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentenca_original</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "      <th>liwc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>A Folha, sempre [tão solícita]P6, só fez junta...</td>\n",
       "      <td>A Folha, sempre tão solícita, só fez juntar os...</td>\n",
       "      <td>1</td>\n",
       "      <td>A Folha sempre tão solícita só fez juntar os d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>o mensalão não termina no petrolão...</td>\n",
       "      <td>o mensalão não termina no petrolão...</td>\n",
       "      <td>1</td>\n",
       "      <td>o mensalão não termina no petrolão</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Para a tristeza da extrema-direita e da extrem...</td>\n",
       "      <td>Para a tristeza da extrema-direita e da extrem...</td>\n",
       "      <td>1</td>\n",
       "      <td>Para a tristeza da extremadireita e da extrema...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Enquanto Temer tenta se safar, Cunha dará anda...</td>\n",
       "      <td>Enquanto Temer tenta se safar, Cunha dará anda...</td>\n",
       "      <td>1</td>\n",
       "      <td>Enquanto Temer tenta se safar Cunha dará andam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Que dupla...</td>\n",
       "      <td>Que dupla...</td>\n",
       "      <td>1</td>\n",
       "      <td>Que dupla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>o que será que [Aécinho]P5 Zona Sul fez na noi...</td>\n",
       "      <td>o que será que Aécinho Zona Sul fez na noite a...</td>\n",
       "      <td>1</td>\n",
       "      <td>o que será que Aécinho Zona Sul fez na noite a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Façam suas apostas, porque o jogo nunca esteve...</td>\n",
       "      <td>Façam suas apostas, porque o jogo nunca esteve...</td>\n",
       "      <td>1</td>\n",
       "      <td>Façam suas apostas porque o jogo nunca esteve ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>O  cruz credo  e a  coisa feia !!!</td>\n",
       "      <td>O  cruz credo  e a  coisa feia !!!</td>\n",
       "      <td>1</td>\n",
       "      <td>O  cruz credo  e a  coisa feia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56</td>\n",
       "      <td>Vamos nos benzer.</td>\n",
       "      <td>Vamos nos benzer.</td>\n",
       "      <td>1</td>\n",
       "      <td>Vamos nos benzer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61</td>\n",
       "      <td>Mimi e Cocó.</td>\n",
       "      <td>Mimi e Cocó.</td>\n",
       "      <td>1</td>\n",
       "      <td>Mimi e Cocó</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74</td>\n",
       "      <td>Melhor deixar tudo com está é?</td>\n",
       "      <td>Melhor deixar tudo com está é?</td>\n",
       "      <td>1</td>\n",
       "      <td>Melhor deixar tudo com está é</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76</td>\n",
       "      <td>Enquanto o pessoal não cria vergonha na cara e...</td>\n",
       "      <td>Enquanto o pessoal não cria vergonha na cara e...</td>\n",
       "      <td>1</td>\n",
       "      <td>Enquanto o pessoal não cria vergonha na cara e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>95</td>\n",
       "      <td>Golpe plano B?</td>\n",
       "      <td>Golpe plano B?</td>\n",
       "      <td>1</td>\n",
       "      <td>Golpe plano B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>104</td>\n",
       "      <td>São muito nobres, afinal, a chapa usou $$ de c...</td>\n",
       "      <td>São muito nobres, afinal, a chapa usou $$ de c...</td>\n",
       "      <td>1</td>\n",
       "      <td>São muito nobres afinal a chapa usou  de corru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>112</td>\n",
       "      <td>Porque o governo não tem?</td>\n",
       "      <td>Porque o governo não tem?</td>\n",
       "      <td>1</td>\n",
       "      <td>Porque o governo não tem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115</td>\n",
       "      <td>É assim que se governa o Brasil.</td>\n",
       "      <td>É assim que se governa o Brasil.</td>\n",
       "      <td>1</td>\n",
       "      <td>É assim que se governa o Brasil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>117</td>\n",
       "      <td>Sim ela parece funcionar muito bem...</td>\n",
       "      <td>Sim ela parece funcionar muito bem...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim ela parece funcionar muito bem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>118</td>\n",
       "      <td>Quase ninguém passa muita fome ou necessidade ...</td>\n",
       "      <td>Quase ninguém passa muita fome ou necessidade ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Quase ninguém passa muita fome ou necessidade lá</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>133</td>\n",
       "      <td>Tirar a Dilma e colocar o Cunha ou  Temer  no ...</td>\n",
       "      <td>Tirar a Dilma e colocar o Cunha ou  Temer  no ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tirar a Dilma e colocar o Cunha ou  Temer  no ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>134</td>\n",
       "      <td>claro, deve ser da sua turma e ai podem brecar...</td>\n",
       "      <td>claro, deve ser da sua turma e ai podem brecar...</td>\n",
       "      <td>1</td>\n",
       "      <td>claro deve ser da sua turma e ai podem brecar ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>174</td>\n",
       "      <td>Haja vaselina ou o dedo era mágico</td>\n",
       "      <td>Haja vaselina ou o dedo era mágico</td>\n",
       "      <td>1</td>\n",
       "      <td>Haja vaselina ou o dedo era mágico</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>194</td>\n",
       "      <td>Com um [\"conselheiro\"]P1 desse, o que se pode ...</td>\n",
       "      <td>Com um [\"conselheiro\"]P1 desse, o que se pode ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Com um conselheiroP1 desse o que se pode esper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>199</td>\n",
       "      <td>Desgraça pouca é bobagem.</td>\n",
       "      <td>Desgraça pouca é bobagem.</td>\n",
       "      <td>1</td>\n",
       "      <td>Desgraça pouca é bobagem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>214</td>\n",
       "      <td>Impichimã de  dirma  é golpismo.</td>\n",
       "      <td>Impichimã de  dirma  é golpismo.</td>\n",
       "      <td>1</td>\n",
       "      <td>Impichimã de  dirma  é golpismo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>215</td>\n",
       "      <td>Loolla  continuar na presidença é [continuismo...</td>\n",
       "      <td>Loolla  continuar na presidença é continuismo.</td>\n",
       "      <td>1</td>\n",
       "      <td>Loolla  continuar na presidença é continuismo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>228</td>\n",
       "      <td>Disputa para ver quem é mais Falso, como eles ...</td>\n",
       "      <td>Disputa para ver quem é mais Falso, como eles ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Disputa para ver quem é mais Falso como eles r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>233</td>\n",
       "      <td>Os dois se merecem!</td>\n",
       "      <td>Os dois se merecem!</td>\n",
       "      <td>1</td>\n",
       "      <td>Os dois se merecem</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>234</td>\n",
       "      <td>Se o Lula manda!!!</td>\n",
       "      <td>Se o Lula manda!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>Se o Lula manda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>235</td>\n",
       "      <td>Deixe entender!!!</td>\n",
       "      <td>Deixe entender!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>Deixe entender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>236</td>\n",
       "      <td>A culpa desse estado do Brasil não é só  dela ...</td>\n",
       "      <td>A culpa desse estado do Brasil não é só  dela ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A culpa desse estado do Brasil não é só  dela</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>473</td>\n",
       "      <td>Agora vai!!!!</td>\n",
       "      <td>Agora vai!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>Agora vai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>476</td>\n",
       "      <td>Esqueceram de chamar a Dilma.</td>\n",
       "      <td>Esqueceram de chamar a Dilma.</td>\n",
       "      <td>1</td>\n",
       "      <td>Esqueceram de chamar a Dilma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>478</td>\n",
       "      <td>A  coitada  está perdida, até jornalista alhei...</td>\n",
       "      <td>A  coitada  está perdida, até jornalista alhei...</td>\n",
       "      <td>1</td>\n",
       "      <td>A  coitada  está perdida até jornalista alheio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>497</td>\n",
       "      <td>Companheiro, quem pariu Matheus que embale!</td>\n",
       "      <td>Companheiro, quem pariu Matheus que embale!</td>\n",
       "      <td>1</td>\n",
       "      <td>Companheiro quem pariu Matheus que embale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>505</td>\n",
       "      <td>Não poderia faltar o comunista f.martins.</td>\n",
       "      <td>Não poderia faltar o comunista f.martins.</td>\n",
       "      <td>1</td>\n",
       "      <td>Não poderia faltar o comunista fmartins</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>507</td>\n",
       "      <td>Ah! só para lembrar: ela quebrou uma [lojinha]...</td>\n",
       "      <td>Ah! só para lembrar: ela quebrou uma lojinha d...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ah só para lembrar ela quebrou uma lojinha de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>508</td>\n",
       "      <td>Faltou convidar os dois filhos do  Luulla .</td>\n",
       "      <td>Faltou convidar os dois filhos do  Luulla .</td>\n",
       "      <td>1</td>\n",
       "      <td>Faltou convidar os dois filhos do  Luulla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>509</td>\n",
       "      <td>Com a expertise de ambos na condução de seus n...</td>\n",
       "      <td>Com a expertise de ambos na condução de seus n...</td>\n",
       "      <td>1</td>\n",
       "      <td>Com a expertise de ambos na condução de seus n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>518</td>\n",
       "      <td>Abrs. Manric</td>\n",
       "      <td>Abrs. Manric</td>\n",
       "      <td>1</td>\n",
       "      <td>Abrs Manric</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>523</td>\n",
       "      <td>Só se for na papuda.</td>\n",
       "      <td>Só se for na papuda.</td>\n",
       "      <td>1</td>\n",
       "      <td>Só se for na papuda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>527</td>\n",
       "      <td>Dilma já não é mais presidente?</td>\n",
       "      <td>Dilma já não é mais presidente?</td>\n",
       "      <td>1</td>\n",
       "      <td>Dilma já não é mais presidente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>537</td>\n",
       "      <td>Cinco?</td>\n",
       "      <td>Cinco?</td>\n",
       "      <td>1</td>\n",
       "      <td>Cinco</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>541</td>\n",
       "      <td>Sugestão primeira: Investir mais na Carta Capi...</td>\n",
       "      <td>Sugestão primeira: Investir mais na Carta Capi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sugestão primeira Investir mais na Carta Capit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>543</td>\n",
       "      <td>Reunião dos 3 patetas, um afundou o Brasil, no...</td>\n",
       "      <td>Reunião dos 3 patetas, um afundou o Brasil, no...</td>\n",
       "      <td>1</td>\n",
       "      <td>Reunião dos 3 patetas um afundou o Brasil no t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>544</td>\n",
       "      <td>Pobre [Banania]P3.</td>\n",
       "      <td>Pobre Banania.</td>\n",
       "      <td>1</td>\n",
       "      <td>Pobre Banania</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>555</td>\n",
       "      <td>Beluzzo, Mino Carta, Frankin Martins, só falto...</td>\n",
       "      <td>Beluzzo, Mino Carta, Frankin Martins, só falto...</td>\n",
       "      <td>1</td>\n",
       "      <td>Beluzzo Mino Carta Frankin Martins só faltou P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>563</td>\n",
       "      <td>Parque dos Dinossauros 6...</td>\n",
       "      <td>Parque dos Dinossauros 6...</td>\n",
       "      <td>1</td>\n",
       "      <td>Parque dos Dinossauros 6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>564</td>\n",
       "      <td>Agora vai!</td>\n",
       "      <td>Agora vai!</td>\n",
       "      <td>1</td>\n",
       "      <td>Agora vai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>570</td>\n",
       "      <td>Há esqueci a fortuna de seu filho e os desvios...</td>\n",
       "      <td>Há esqueci a fortuna de seu filho e os desvios...</td>\n",
       "      <td>1</td>\n",
       "      <td>Há esqueci a fortuna de seu filho e os desvios...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>571</td>\n",
       "      <td>É só devolver o dinheiro desviado das estatais...</td>\n",
       "      <td>É só devolver o dinheiro desviado das estatais...</td>\n",
       "      <td>1</td>\n",
       "      <td>É só devolver o dinheiro desviado das estatais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>573</td>\n",
       "      <td>Esqueceram de convidar o mais importante e ilu...</td>\n",
       "      <td>Esqueceram de convidar o mais importante e ilu...</td>\n",
       "      <td>1</td>\n",
       "      <td>Esqueceram de convidar o mais importante e ilu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>574</td>\n",
       "      <td>Seus mal agradecidos!</td>\n",
       "      <td>Seus mal agradecidos!</td>\n",
       "      <td>1</td>\n",
       "      <td>Seus mal agradecidos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>575</td>\n",
       "      <td>O deputado  Eduardoh Cunhah  seguramente já pe...</td>\n",
       "      <td>O deputado  Eduardoh Cunhah  seguramente já pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>O deputado  Eduardoh Cunhah  seguramente já pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>576</td>\n",
       "      <td>Ainda penso que daria um bom embaixador do Bra...</td>\n",
       "      <td>Ainda penso que daria um bom embaixador do Bra...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ainda penso que daria um bom embaixador do Bra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>589</td>\n",
       "      <td>Eduardo Cunha é o Cara!!?</td>\n",
       "      <td>Eduardo Cunha é o Cara!!?</td>\n",
       "      <td>1</td>\n",
       "      <td>Eduardo Cunha é o Cara</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>599</td>\n",
       "      <td>Somos um pais de [coitadinhos]P5.</td>\n",
       "      <td>Somos um pais de coitadinhos.</td>\n",
       "      <td>1</td>\n",
       "      <td>Somos um pais de coitadinhos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>607</td>\n",
       "      <td>É capaz de chegar para a própria mulher dele, ...</td>\n",
       "      <td>É capaz de chegar para a própria mulher dele, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>É capaz de chegar para a própria mulher dele t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>608</td>\n",
       "      <td>Governo, Procuradoria, Homens e Mulheres de Be...</td>\n",
       "      <td>Governo, Procuradoria, Homens e Mulheres de Be...</td>\n",
       "      <td>1</td>\n",
       "      <td>Governo Procuradoria Homens e Mulheres de Bem ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>617</td>\n",
       "      <td>Jura que  ele  eh inocente?</td>\n",
       "      <td>Jura que  ele  eh inocente?</td>\n",
       "      <td>1</td>\n",
       "      <td>Jura que  ele  eh inocente</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>620</td>\n",
       "      <td>Ou  coitado  é um santo injustiçado.</td>\n",
       "      <td>Ou  coitado  é um santo injustiçado.</td>\n",
       "      <td>1</td>\n",
       "      <td>Ou  coitado  é um santo injustiçado</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                  sentenca_original  \\\n",
       "0       7  A Folha, sempre [tão solícita]P6, só fez junta...   \n",
       "1      17              o mensalão não termina no petrolão...   \n",
       "2      22  Para a tristeza da extrema-direita e da extrem...   \n",
       "3      23  Enquanto Temer tenta se safar, Cunha dará anda...   \n",
       "4      36                                       Que dupla...   \n",
       "5      37  o que será que [Aécinho]P5 Zona Sul fez na noi...   \n",
       "6      49  Façam suas apostas, porque o jogo nunca esteve...   \n",
       "7      55                 O  cruz credo  e a  coisa feia !!!   \n",
       "8      56                                  Vamos nos benzer.   \n",
       "9      61                                       Mimi e Cocó.   \n",
       "10     74                     Melhor deixar tudo com está é?   \n",
       "11     76  Enquanto o pessoal não cria vergonha na cara e...   \n",
       "12     95                                     Golpe plano B?   \n",
       "13    104  São muito nobres, afinal, a chapa usou $$ de c...   \n",
       "14    112                          Porque o governo não tem?   \n",
       "15    115                   É assim que se governa o Brasil.   \n",
       "16    117              Sim ela parece funcionar muito bem...   \n",
       "17    118  Quase ninguém passa muita fome ou necessidade ...   \n",
       "18    133  Tirar a Dilma e colocar o Cunha ou  Temer  no ...   \n",
       "19    134  claro, deve ser da sua turma e ai podem brecar...   \n",
       "20    174                 Haja vaselina ou o dedo era mágico   \n",
       "21    194  Com um [\"conselheiro\"]P1 desse, o que se pode ...   \n",
       "22    199                          Desgraça pouca é bobagem.   \n",
       "23    214                   Impichimã de  dirma  é golpismo.   \n",
       "24    215  Loolla  continuar na presidença é [continuismo...   \n",
       "25    228  Disputa para ver quem é mais Falso, como eles ...   \n",
       "26    233                                Os dois se merecem!   \n",
       "27    234                                 Se o Lula manda!!!   \n",
       "28    235                                  Deixe entender!!!   \n",
       "29    236  A culpa desse estado do Brasil não é só  dela ...   \n",
       "..    ...                                                ...   \n",
       "70    473                                      Agora vai!!!!   \n",
       "71    476                      Esqueceram de chamar a Dilma.   \n",
       "72    478  A  coitada  está perdida, até jornalista alhei...   \n",
       "73    497        Companheiro, quem pariu Matheus que embale!   \n",
       "74    505          Não poderia faltar o comunista f.martins.   \n",
       "75    507  Ah! só para lembrar: ela quebrou uma [lojinha]...   \n",
       "76    508        Faltou convidar os dois filhos do  Luulla .   \n",
       "77    509  Com a expertise de ambos na condução de seus n...   \n",
       "78    518                                       Abrs. Manric   \n",
       "79    523                               Só se for na papuda.   \n",
       "80    527                    Dilma já não é mais presidente?   \n",
       "81    537                                             Cinco?   \n",
       "82    541  Sugestão primeira: Investir mais na Carta Capi...   \n",
       "83    543  Reunião dos 3 patetas, um afundou o Brasil, no...   \n",
       "84    544                                 Pobre [Banania]P3.   \n",
       "85    555  Beluzzo, Mino Carta, Frankin Martins, só falto...   \n",
       "86    563                        Parque dos Dinossauros 6...   \n",
       "87    564                                         Agora vai!   \n",
       "88    570  Há esqueci a fortuna de seu filho e os desvios...   \n",
       "89    571  É só devolver o dinheiro desviado das estatais...   \n",
       "90    573  Esqueceram de convidar o mais importante e ilu...   \n",
       "91    574                              Seus mal agradecidos!   \n",
       "92    575  O deputado  Eduardoh Cunhah  seguramente já pe...   \n",
       "93    576  Ainda penso que daria um bom embaixador do Bra...   \n",
       "94    589                          Eduardo Cunha é o Cara!!?   \n",
       "95    599                  Somos um pais de [coitadinhos]P5.   \n",
       "96    607  É capaz de chegar para a própria mulher dele, ...   \n",
       "97    608  Governo, Procuradoria, Homens e Mulheres de Be...   \n",
       "98    617                        Jura que  ele  eh inocente?   \n",
       "99    620               Ou  coitado  é um santo injustiçado.   \n",
       "\n",
       "                                 sentenca_processada1  classificacao  \\\n",
       "0   A Folha, sempre tão solícita, só fez juntar os...              1   \n",
       "1               o mensalão não termina no petrolão...              1   \n",
       "2   Para a tristeza da extrema-direita e da extrem...              1   \n",
       "3   Enquanto Temer tenta se safar, Cunha dará anda...              1   \n",
       "4                                        Que dupla...              1   \n",
       "5   o que será que Aécinho Zona Sul fez na noite a...              1   \n",
       "6   Façam suas apostas, porque o jogo nunca esteve...              1   \n",
       "7                  O  cruz credo  e a  coisa feia !!!              1   \n",
       "8                                   Vamos nos benzer.              1   \n",
       "9                                        Mimi e Cocó.              1   \n",
       "10                     Melhor deixar tudo com está é?              1   \n",
       "11  Enquanto o pessoal não cria vergonha na cara e...              1   \n",
       "12                                     Golpe plano B?              1   \n",
       "13  São muito nobres, afinal, a chapa usou $$ de c...              1   \n",
       "14                          Porque o governo não tem?              1   \n",
       "15                   É assim que se governa o Brasil.              1   \n",
       "16              Sim ela parece funcionar muito bem...              1   \n",
       "17  Quase ninguém passa muita fome ou necessidade ...              1   \n",
       "18  Tirar a Dilma e colocar o Cunha ou  Temer  no ...              1   \n",
       "19  claro, deve ser da sua turma e ai podem brecar...              1   \n",
       "20                 Haja vaselina ou o dedo era mágico              1   \n",
       "21  Com um [\"conselheiro\"]P1 desse, o que se pode ...              1   \n",
       "22                          Desgraça pouca é bobagem.              1   \n",
       "23                   Impichimã de  dirma  é golpismo.              1   \n",
       "24     Loolla  continuar na presidença é continuismo.              1   \n",
       "25  Disputa para ver quem é mais Falso, como eles ...              1   \n",
       "26                                Os dois se merecem!              1   \n",
       "27                                 Se o Lula manda!!!              1   \n",
       "28                                  Deixe entender!!!              1   \n",
       "29  A culpa desse estado do Brasil não é só  dela ...              1   \n",
       "..                                                ...            ...   \n",
       "70                                      Agora vai!!!!              1   \n",
       "71                      Esqueceram de chamar a Dilma.              1   \n",
       "72  A  coitada  está perdida, até jornalista alhei...              1   \n",
       "73        Companheiro, quem pariu Matheus que embale!              1   \n",
       "74          Não poderia faltar o comunista f.martins.              1   \n",
       "75  Ah! só para lembrar: ela quebrou uma lojinha d...              1   \n",
       "76        Faltou convidar os dois filhos do  Luulla .              1   \n",
       "77  Com a expertise de ambos na condução de seus n...              1   \n",
       "78                                       Abrs. Manric              1   \n",
       "79                               Só se for na papuda.              1   \n",
       "80                    Dilma já não é mais presidente?              1   \n",
       "81                                             Cinco?              1   \n",
       "82  Sugestão primeira: Investir mais na Carta Capi...              1   \n",
       "83  Reunião dos 3 patetas, um afundou o Brasil, no...              1   \n",
       "84                                     Pobre Banania.              1   \n",
       "85  Beluzzo, Mino Carta, Frankin Martins, só falto...              1   \n",
       "86                        Parque dos Dinossauros 6...              1   \n",
       "87                                         Agora vai!              1   \n",
       "88  Há esqueci a fortuna de seu filho e os desvios...              1   \n",
       "89  É só devolver o dinheiro desviado das estatais...              1   \n",
       "90  Esqueceram de convidar o mais importante e ilu...              1   \n",
       "91                              Seus mal agradecidos!              1   \n",
       "92  O deputado  Eduardoh Cunhah  seguramente já pe...              1   \n",
       "93  Ainda penso que daria um bom embaixador do Bra...              1   \n",
       "94                          Eduardo Cunha é o Cara!!?              1   \n",
       "95                      Somos um pais de coitadinhos.              1   \n",
       "96  É capaz de chegar para a própria mulher dele, ...              1   \n",
       "97  Governo, Procuradoria, Homens e Mulheres de Be...              1   \n",
       "98                        Jura que  ele  eh inocente?              1   \n",
       "99               Ou  coitado  é um santo injustiçado.              1   \n",
       "\n",
       "                                 sentenca_processada2  liwc  \n",
       "0   A Folha sempre tão solícita só fez juntar os d...     1  \n",
       "1                  o mensalão não termina no petrolão     1  \n",
       "2   Para a tristeza da extremadireita e da extrema...     0  \n",
       "3   Enquanto Temer tenta se safar Cunha dará andam...     0  \n",
       "4                                           Que dupla     1  \n",
       "5   o que será que Aécinho Zona Sul fez na noite a...     0  \n",
       "6   Façam suas apostas porque o jogo nunca esteve ...     1  \n",
       "7                     O  cruz credo  e a  coisa feia      0  \n",
       "8                                    Vamos nos benzer     1  \n",
       "9                                         Mimi e Cocó     1  \n",
       "10                      Melhor deixar tudo com está é     1  \n",
       "11  Enquanto o pessoal não cria vergonha na cara e...     1  \n",
       "12                                      Golpe plano B     0  \n",
       "13  São muito nobres afinal a chapa usou  de corru...     1  \n",
       "14                           Porque o governo não tem     1  \n",
       "15                    É assim que se governa o Brasil     1  \n",
       "16                 Sim ela parece funcionar muito bem     1  \n",
       "17   Quase ninguém passa muita fome ou necessidade lá     0  \n",
       "18  Tirar a Dilma e colocar o Cunha ou  Temer  no ...     0  \n",
       "19  claro deve ser da sua turma e ai podem brecar ...     1  \n",
       "20                 Haja vaselina ou o dedo era mágico     1  \n",
       "21  Com um conselheiroP1 desse o que se pode esper...     1  \n",
       "22                           Desgraça pouca é bobagem     1  \n",
       "23                    Impichimã de  dirma  é golpismo     1  \n",
       "24      Loolla  continuar na presidença é continuismo     1  \n",
       "25  Disputa para ver quem é mais Falso como eles r...     0  \n",
       "26                                 Os dois se merecem     1  \n",
       "27                                    Se o Lula manda     1  \n",
       "28                                     Deixe entender     1  \n",
       "29    A culpa desse estado do Brasil não é só  dela       0  \n",
       "..                                                ...   ...  \n",
       "70                                          Agora vai     1  \n",
       "71                       Esqueceram de chamar a Dilma     1  \n",
       "72  A  coitada  está perdida até jornalista alheio...     0  \n",
       "73          Companheiro quem pariu Matheus que embale     1  \n",
       "74            Não poderia faltar o comunista fmartins     1  \n",
       "75  Ah só para lembrar ela quebrou uma lojinha de ...     1  \n",
       "76         Faltou convidar os dois filhos do  Luulla      1  \n",
       "77  Com a expertise de ambos na condução de seus n...     1  \n",
       "78                                        Abrs Manric     1  \n",
       "79                                Só se for na papuda     1  \n",
       "80                     Dilma já não é mais presidente     1  \n",
       "81                                              Cinco     1  \n",
       "82  Sugestão primeira Investir mais na Carta Capit...     1  \n",
       "83  Reunião dos 3 patetas um afundou o Brasil no t...     1  \n",
       "84                                      Pobre Banania     1  \n",
       "85  Beluzzo Mino Carta Frankin Martins só faltou P...     1  \n",
       "86                           Parque dos Dinossauros 6     1  \n",
       "87                                          Agora vai     1  \n",
       "88  Há esqueci a fortuna de seu filho e os desvios...     1  \n",
       "89  É só devolver o dinheiro desviado das estatais...     1  \n",
       "90  Esqueceram de convidar o mais importante e ilu...     1  \n",
       "91                               Seus mal agradecidos     1  \n",
       "92  O deputado  Eduardoh Cunhah  seguramente já pe...     1  \n",
       "93  Ainda penso que daria um bom embaixador do Bra...     1  \n",
       "94                             Eduardo Cunha é o Cara     1  \n",
       "95                       Somos um pais de coitadinhos     1  \n",
       "96  É capaz de chegar para a própria mulher dele t...     1  \n",
       "97  Governo Procuradoria Homens e Mulheres de Bem ...     1  \n",
       "98                         Jura que  ele  eh inocente     1  \n",
       "99                Ou  coitado  é um santo injustiçado     1  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALVA DATAFRAME EM CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataframe completo (sentenças + classificação + features)\n",
    "# df.to_csv('dataset_full.csv', index=False)\n",
    "\n",
    "# remove as colunas das sentenças, permanecendo apenas a classificação e features:\n",
    "df1 = df.drop(columns=[\"index\", \"sentenca_original\", \"sentenca_processada1\", \"sentenca_processada2\"])\n",
    "\n",
    "# Salva o dataframe features (classificação + features)\n",
    "df1.to_csv('dataset_features_liwc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificacao</th>\n",
       "      <th>liwc</th>\n",
       "      <th>entidades_nomeadas</th>\n",
       "      <th>adjetivos</th>\n",
       "      <th>triggers</th>\n",
       "      <th>intensifiers</th>\n",
       "      <th>modifiers</th>\n",
       "      <th>quotation_marks</th>\n",
       "      <th>repeated_punctuation</th>\n",
       "      <th>letters_repetition</th>\n",
       "      <th>word_repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classificacao  liwc  entidades_nomeadas  adjetivos  triggers  intensifiers  \\\n",
       "0              1     1                   0          1         1             1   \n",
       "1              1     1                   0          0         1             0   \n",
       "2              1     0                   0          0         1             0   \n",
       "3              1     0                   1          0         1             0   \n",
       "4              1     1                   0          0         1             0   \n",
       "\n",
       "   modifiers  quotation_marks  repeated_punctuation  letters_repetition  \\\n",
       "0          1                0                     0                   0   \n",
       "1          1                0                     1                   0   \n",
       "2          1                0                     0                   1   \n",
       "3          1                1                     1                   0   \n",
       "4          0                0                     1                   0   \n",
       "\n",
       "   word_repetition  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = df1.iloc[:,1:10].values\n",
    "outputs = df1['classificacao']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELEÇÃO DAS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(inputs, outputs)\n",
    "classificador = tree.DecisionTreeClassifier()\n",
    "classificador.fit(inputs, outputs)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(classificador.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "classificador = LogisticRegression()\n",
    "# classificador.fit(treino, classe_treino)\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(classificador, 1)\n",
    "rfe = rfe.fit(inputs, outputs)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "classificador = svm.SVC(gamma='auto', C=1.0, kernel='linear', probability=False)\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(classificador, 1)\n",
    "rfe = rfe.fit(inputs, outputs)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(inputs, outputs)\n",
    "classificador = MLPClassifier(activation='relu', solver='adam', max_iter=10000, alpha=1e-10, hidden_layer_sizes=(18,2))\n",
    "classificador.fit(inputs, outputs)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(classificador.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # http://minerandodados.com.br/index.php/2018/05/21/feature-selection-bala-de-prata/\n",
    "# from sklearn import feature_selection\n",
    "# fs = feature_selection.SelectPercentile(feature_selection.f_classif, percentile=100)\n",
    "# # model = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k=9)\n",
    "# X_treino_fs = fs.fit_transform(inputs, outputs)\n",
    "\n",
    "# # results = model.fit(df[columns], df['qsec'])\n",
    "\n",
    "# print(fs.scores_)\n",
    "# print(fs.pvalues_)\n",
    "\n",
    "# # x = pd.DataFrame(X_treino_fs)\n",
    "# # x\n",
    "\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
