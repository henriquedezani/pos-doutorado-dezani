{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carrega o arquivo com as sentenças (Córpus da Gabriela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tamanho200_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_polaridade_positiva</th>\n",
       "      <th>pont_repetida</th>\n",
       "      <th>entidade_nomeada</th>\n",
       "      <th>disparadores</th>\n",
       "      <th>expressoes</th>\n",
       "      <th>letras_repetidas</th>\n",
       "      <th>palavras_repetidas</th>\n",
       "      <th>aspas</th>\n",
       "      <th>intensificadores</th>\n",
       "      <th>modificadores</th>\n",
       "      <th>liwc</th>\n",
       "      <th>rotulo</th>\n",
       "      <th>sentenca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir, é...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Que coisa mais corrupta, dentro de um novo pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dilma elogiando o Congresso porque votaram?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adj_polaridade_positiva  pont_repetida  entidade_nomeada  disparadores  \\\n",
       "0                      0.0            0.0               1.0           1.0   \n",
       "1                      0.0            0.0               0.0           1.0   \n",
       "2                      0.0            0.0               0.0           1.0   \n",
       "3                      0.0            0.0               1.0           1.0   \n",
       "4                      0.0            0.0               1.0           1.0   \n",
       "\n",
       "   expressoes  letras_repetidas  palavras_repetidas  aspas  intensificadores  \\\n",
       "0         0.0               0.0                 0.0    0.0               0.0   \n",
       "1         0.0               0.0                 0.0    0.0               0.0   \n",
       "2         0.0               0.0                 0.0    0.0               1.0   \n",
       "3         0.0               0.0                 0.0    0.0               0.0   \n",
       "4         0.0               0.0                 0.0    0.0               0.0   \n",
       "\n",
       "   modificadores  liwc  rotulo  \\\n",
       "0            0.0   0.5     1.0   \n",
       "1            0.0   0.5     1.0   \n",
       "2            1.0   1.0     1.0   \n",
       "3            1.0   1.0     1.0   \n",
       "4            0.0   0.0     1.0   \n",
       "\n",
       "                                            sentenca  \n",
       "0                Parece estar no Reino da Dinamarca.  \n",
       "1  Esta conversa pra jornalista sabonete ouvir, é...  \n",
       "2  Que coisa mais corrupta, dentro de um novo pac...  \n",
       "3        Dilma elogiando o Congresso porque votaram?  \n",
       "4   pedindo pazes com Temer tipo jardim da infância?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"pont_repetida\",\"entidade_nomeada\", \"disparadores\", \"expressoes\", \"adj_polaridade_positiva\", \"letras_repetidas\", \"aspas\", \"palavras_repetidas\", \"liwc\", \"intensificadores\", \"modificadores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotulo</th>\n",
       "      <th>sentenca</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir, é...</td>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir, é...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Que coisa mais corrupta, dentro de um novo pac...</td>\n",
       "      <td>Que coisa mais corrupta, dentro de um novo pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Dilma elogiando o Congresso porque votaram?</td>\n",
       "      <td>Dilma elogiando o Congresso porque votaram?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância?</td>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rotulo                                           sentenca  \\\n",
       "0     1.0                Parece estar no Reino da Dinamarca.   \n",
       "1     1.0  Esta conversa pra jornalista sabonete ouvir, é...   \n",
       "2     1.0  Que coisa mais corrupta, dentro de um novo pac...   \n",
       "3     1.0        Dilma elogiando o Congresso porque votaram?   \n",
       "4     1.0   pedindo pazes com Temer tipo jardim da infância?   \n",
       "\n",
       "                                sentenca_processada1  \n",
       "0                Parece estar no Reino da Dinamarca.  \n",
       "1  Esta conversa pra jornalista sabonete ouvir, é...  \n",
       "2  Que coisa mais corrupta, dentro de um novo pac...  \n",
       "3        Dilma elogiando o Congresso porque votaram?  \n",
       "4   pedindo pazes com Temer tipo jardim da infância?  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    200\n",
      "1.0    200\n",
      "Name: rotulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['rotulo'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Atualiza o DataFrame com apenas as classificações irônicas e não irônicas (2.000 para cada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencas_processadas1 = list()\n",
    "\n",
    "for sentenca in df['sentenca']:\n",
    "    sentencas_processadas1.append(sentenca)\n",
    "    \n",
    "df['sentenca_processada1'] = sentencas_processadas1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Realiza um pre-processamento no dataset para remoção de caracteres especiais, vírgulas, pontos etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sents = list()\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    sents.append(re.sub(r'[^\\w\\s]','',sentenca))\n",
    "    \n",
    "df['sentenca_processada2'] = sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Realiza a obtenção das Features (utiliza sentenca_processada 1 e 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "      <td>Parece estar no Reino da Dinamarca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir, é...</td>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir é ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Que coisa mais corrupta, dentro de um novo pac...</td>\n",
       "      <td>Que coisa mais corrupta dentro de um novo paco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dilma elogiando o Congresso porque votaram?</td>\n",
       "      <td>Dilma elogiando o Congresso porque votaram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância?</td>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentenca_processada1  \\\n",
       "0                Parece estar no Reino da Dinamarca.   \n",
       "1  Esta conversa pra jornalista sabonete ouvir, é...   \n",
       "2  Que coisa mais corrupta, dentro de um novo pac...   \n",
       "3        Dilma elogiando o Congresso porque votaram?   \n",
       "4   pedindo pazes com Temer tipo jardim da infância?   \n",
       "\n",
       "                                sentenca_processada2  \n",
       "0                 Parece estar no Reino da Dinamarca  \n",
       "1  Esta conversa pra jornalista sabonete ouvir é ...  \n",
       "2  Que coisa mais corrupta dentro de um novo paco...  \n",
       "3         Dilma elogiando o Congresso porque votaram  \n",
       "4    pedindo pazes com Temer tipo jardim da infância  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sentenca_processada1', 'sentenca_processada2']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Entidade Nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "\n",
    "entidades_nomeadas = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    text = Text(sentenca, hint_language_code='pt',)\n",
    "    if len(text.entities) > 0:\n",
    "        if df['rotulo'][count] == 1:\n",
    "            ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0:\n",
    "            naoironicas = naoironicas + 1       \n",
    "        entidades_nomeadas.append(1)\n",
    "    else:\n",
    "        entidades_nomeadas.append(0)\n",
    "        \n",
    "    count = count + 1\n",
    "        \n",
    "            \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['entidades_nomeadas'] = entidades_nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    269\n",
       "1    131\n",
       "Name: entidades_nomeadas, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entidades_nomeadas'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Adjetivos com polaridade positiva (no domínio político)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import nlpnet\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "stemmer = nltk.RSLPStemmer()\n",
    "\n",
    "# Define o etiquetador morfosintático do NLPNet:\n",
    "tagger_nplnet = nlpnet.POSTagger(data_dir='../pos-pt/', language='pt')\n",
    "\n",
    "# Lista de adjetivos de polaridade positiva bem marcados (Trabalho de Gabriela):\n",
    "lista_adjetivos_positivos = ['belo', 'bom', 'bem', 'excelente', 'extraordinário', 'fantástico', 'feliz', 'glorioso', 'heróico', 'hilário', \n",
    " 'honesto', 'ilustre', 'incrível', 'legal', 'limpo', 'lindo', 'majestoso', 'maravilhoso', 'nobre', 'ótimo', 'santo', 'satisfeito', \n",
    " 'solícito']\n",
    "\n",
    "# recupera as raizes das palavras:\n",
    "_lista_adjetivos_positivos = [stemmer.stem(palavra) for palavra in lista_adjetivos_positivos]\n",
    "\n",
    "__lista_adjetivos_positivos = [unidecode.unidecode(palavra) for palavra in _lista_adjetivos_positivos]\n",
    "  \n",
    "def contem_adjetivo_positivo_politico(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    for item in lista:\n",
    "        for (token, tag) in item:\n",
    "            if tag == 'ADJ' and any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_adjetivos_positivos):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "adjetivos = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_adjetivo_positivo_politico(sentenca):\n",
    "        adjetivos.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        adjetivos.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['adjetivos'] = adjetivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    377\n",
       "1     23\n",
       "Name: adjetivos, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['adjetivos'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "# Lista de disparadores (Trabalho de Gabriela):\n",
    "lista_disparadores = ['aceitar', 'acreditar', 'adorar', 'alíquota', 'alma', 'amá-la', 'anjos', 'boa sorte', 'boa viagem', 'boa noite',\n",
    "  'bocadas', 'bondade', 'campanha', 'canonizá-lo', 'canonização', 'coincidência', 'coisa', 'comprar', 'contribuintes', 'contrição', \n",
    "  'corrupção', 'corruptos', 'cortar gastos', 'crescimento', 'crise', 'culpa', 'demitir', 'democracia', 'desemprego', 'desenvolvimento', \n",
    "  'desgoverno', 'desgraça', 'destruído', 'desvalorização', 'detalhe', 'deuses', 'dinheirama', 'dinheiro', 'ditador', 'dó', 'eleitoreiras', \n",
    "  'embuste', 'estrago', 'ética', 'expertise', 'financiar', 'fome', 'funcionar', 'ganhar', 'gastar', 'gostar', 'gostaria', 'grato', 'honestidade', \n",
    "  'ignorância', 'impeachment', 'inflação', 'investimento', 'lambuzou', 'liderança', 'louvor', 'megaempreiteiro', 'mensalão', 'mentiras', 'mídia',\n",
    "  'milagre', 'miséria', 'moral', 'moralidade', 'necessidade', 'obrigado', 'oposição', 'país', 'parabéns', 'parceria', 'partido', 'pedaladas', 'pena',\n",
    "  'política', 'político', 'prisão', 'quadrilha', 'quebrou', 'reeileição', 'refúgio', 'rombo', 'salve', 'santo', 'saudade', 'sindicalismo',\n",
    "  'solidariedade', 'subordinados', 'sugestivo', 'sugestões', 'surpresa', 'tomara', 'tucanas', 'verde-amarelo', 'vermelhos', 'vida']\n",
    "\n",
    "# recupera as raizes das palavras:\n",
    "_lista_disparadores = [stemmer.stem(palavra) for palavra in lista_disparadores]\n",
    "\n",
    "__lista_disparadores = [unidecode.unidecode(palavra) for palavra in _lista_disparadores]\n",
    "  \n",
    "def has_trigger(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca)\n",
    "    for token in tokens:\n",
    "        if any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_disparadores):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "triggers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if has_trigger(sentenca):\n",
    "        triggers.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        triggers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['triggers'] = triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    369\n",
       "0     31\n",
       "Name: triggers, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['triggers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Intensificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import nlpnet\n",
    "\n",
    "# Define o etiquetador morfosintático do NLPNet:\n",
    "tagger_nplnet = nlpnet.POSTagger(data_dir='../pos-pt/', language='pt')\n",
    "\n",
    "# Intensificadores\n",
    "def contem_intensificadores(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    ADV = False\n",
    "    for item in lista:\n",
    "         for (_, tag) in item:\n",
    "            if tag == 'ADV':   \n",
    "                ADV = True\n",
    "            elif tag == 'ADJ':\n",
    "                if(ADV == True):           \n",
    "                    return True\n",
    "            else:\n",
    "                ADV = False\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "intensifiers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_intensificadores(sentenca):\n",
    "        intensifiers.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        intensifiers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['intensifiers'] = intensifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    380\n",
       "1     20\n",
       "Name: intensifiers, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intensifiers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Modificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "lista_modificadores = ['absolutamente', 'afinal', 'agora', 'apesar', 'até', 'aumento', 'como sempre', 'demais', 'do brasil', 'em paz', 'em solidariedade',\n",
    " 'extremamente', 'ficar longe', 'imagine', 'incondicionalmente', 'lindamente', 'logo agora', 'mais', 'manutenção', 'mas', 'menos',\n",
    "  'não é verdade', 'obrigatoriamente', 'ou melhor', 'pelo menos', 'pensando bem', 'porque', 'quanta', 'quão', 'sempre tão', 'simplesmente', 'só', 'todos']\n",
    "\n",
    "_lista_modificadores = [stemmer.stem(palavra) for palavra in lista_modificadores]\n",
    "\n",
    "__lista_modificadores = [unidecode.unidecode(palavra) for palavra in _lista_modificadores]\n",
    "\n",
    "def contem_modificadores(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca)\n",
    "    for token in tokens:\n",
    "        if any(unidecode.unidecode(stemmer.stem(token.lower())) in s for s in __lista_modificadores):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "modifiers = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada2']:\n",
    "    if contem_modificadores(sentenca):\n",
    "        modifiers.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        modifiers.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['modifiers'] = modifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    365\n",
       "0     35\n",
       "Name: modifiers, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modifiers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Quotation Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def contem_palavras_com_aspas(sentenca):\n",
    "    result = re.findall(r'[\\'\\\"][\\w!?\\s]+[\\'\\\"]*', sentenca)    \n",
    "    if len(result) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "quotation_marks = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if contem_palavras_com_aspas(sentenca):\n",
    "        quotation_marks.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        quotation_marks.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['quotation_marks'] = quotation_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1     43\n",
       "Name: quotation_marks, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quotation_marks'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. Pontuação Repetida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "def has_repeated_punctuation(sentenca):\n",
    "    result = re.findall(r'[!?.]+', sentenca)\n",
    "    for group in result:\n",
    "        if len(group) >= 2:\n",
    "            return True        \n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "repeated_punctuation = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_repeated_punctuation(sentenca):\n",
    "        repeated_punctuation.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        repeated_punctuation.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['repeated_punctuation'] = repeated_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    330\n",
       "1     70\n",
       "Name: repeated_punctuation, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['repeated_punctuation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8. Letras Repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "def has_letters_repetition(sentenca):\n",
    "    lista = tagger_nplnet.tag(sentenca)\n",
    "    for item in lista:\n",
    "         for (token, tag) in item:\n",
    "            if(tag == 'N'):\n",
    "                result = re.findall(r'(\\w)\\1+', token.lower())\n",
    "                for group in result:\n",
    "                    if len(group) >= 1:\n",
    "                        return True        \n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "letters_repetition = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_letters_repetition(sentenca):\n",
    "        letters_repetition.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        letters_repetition.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['letters_repetition'] = letters_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    338\n",
       "1     62\n",
       "Name: letters_repetition, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letters_repetition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9. Palavras Repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def has_word_repetition(sentenca):\n",
    "    \n",
    "    _tokens = nltk.word_tokenize(sentenca.lower())\n",
    "    \n",
    "    _raizes = [stemmer.stem(palavra) for palavra in _tokens]\n",
    "\n",
    "    _sem_acentos = [unidecode.unidecode(palavra) for palavra in _raizes]\n",
    "\n",
    "    \n",
    "    if(max([len(list(group)) for key, group in groupby(_sem_acentos)])) > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "word_repetition = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if has_word_repetition(sentenca):\n",
    "        word_repetition.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        word_repetition.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['word_repetition'] = word_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    368\n",
       "1     32\n",
       "Name: word_repetition, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_repetition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10. Rethorical Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESENVOLVER!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11. LIWC (Executar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c9823bc07a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentenca\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentenca_processada1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mget_polaridade_sentenca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentenca\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mliwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rotulo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mironicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mironicas\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-c9823bc07a36>\u001b[0m in \u001b[0;36mget_polaridade_sentenca\u001b[0;34m(sentenca)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mget_polaridade_palavra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positivo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mpositivo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositivo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mget_polaridade_palavra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'negativo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mnegativo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegativo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-c9823bc07a36>\u001b[0m in \u001b[0;36mget_polaridade_palavra\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_polaridade_palavra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mliwc_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'126'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m'positivo'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/stem/rslp.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# verb reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mprev_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprev_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;31m# vowel removal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/stem/rslp.py\u001b[0m in \u001b[0;36mapply_rule\u001b[0;34m(self, word, rule_index)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrule_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0msuffix_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msuffix_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;31m# if suffix matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msuffix_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if we have minimum size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### LIWC ######\n",
    "import csv\n",
    "liwc_words = []\n",
    "\n",
    "with open('liwc2.txt','r') as f:\n",
    "    next(f) # skip headings\n",
    "    reader=csv.reader(f,delimiter='\\t')\n",
    "    for line in reader:\n",
    "        liwc_words.append(line)\n",
    "\n",
    "def get_polaridade_palavra(word):\n",
    "    for line in liwc_words:\n",
    "        if stemmer.stem(word) in line:\n",
    "            if '126' in line:\n",
    "                return 'positivo'\n",
    "            elif '127' in line:\n",
    "                return 'negativo'\n",
    "            else:\n",
    "                return 'undefined'\n",
    "\n",
    "    return 'not_found'\n",
    "\n",
    "def get_polaridade_sentenca(sentenca):\n",
    "    tokens = nltk.word_tokenize(sentenca.lower())\n",
    "    positivo = 0\n",
    "    negativo = 0\n",
    "    for token in tokens:\n",
    "        if get_polaridade_palavra(token) == 'positivo':\n",
    "            positivo = positivo + 1\n",
    "        elif get_polaridade_palavra(token) == 'negativo':\n",
    "            negativo = negativo + 1\n",
    "            \n",
    "\n",
    "    if (positivo > negativo):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "naoironicas = 0\n",
    "ironicas = 0\n",
    "\n",
    "liwc = list()\n",
    "\n",
    "count = 0\n",
    "for sentenca in df['sentenca_processada1']:\n",
    "    if get_polaridade_sentenca(sentenca) == 1:\n",
    "        liwc.append(1)\n",
    "        if df['rotulo'][count] == 1: ironicas = ironicas + 1\n",
    "        if df['rotulo'][count] == 0: naoironicas = naoironicas + 1\n",
    "    else:\n",
    "        liwc.append(0)\n",
    "    count = count + 1\n",
    "    \n",
    "print(ironicas)\n",
    "print(naoironicas)\n",
    "\n",
    "df['liwc'] = liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liwc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALVA DATAFRAME EM CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataframe completo (sentenças + classificação + features)\n",
    "df.to_csv('dataset_full_400.csv', index=False)\n",
    "\n",
    "# # remove as colunas das sentenças, permanecendo apenas a classificação e features:\n",
    "# df1 = df.drop(columns=[\"index\", \"sentenca_original\", \"sentenca_processada1\", \"sentenca_processada2\"])\n",
    "\n",
    "# # Salva o dataframe features (classificação + features)\n",
    "# df1.to_csv('dataset_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotulo</th>\n",
       "      <th>sentenca</th>\n",
       "      <th>sentenca_processada1</th>\n",
       "      <th>sentenca_processada2</th>\n",
       "      <th>entidades_nomeadas</th>\n",
       "      <th>adjetivos</th>\n",
       "      <th>triggers</th>\n",
       "      <th>intensifiers</th>\n",
       "      <th>modifiers</th>\n",
       "      <th>quotation_marks</th>\n",
       "      <th>repeated_punctuation</th>\n",
       "      <th>letters_repetition</th>\n",
       "      <th>word_repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "      <td>Parece estar no Reino da Dinamarca.</td>\n",
       "      <td>Parece estar no Reino da Dinamarca</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir, é...</td>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir, é...</td>\n",
       "      <td>Esta conversa pra jornalista sabonete ouvir é ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Que coisa mais corrupta, dentro de um novo pac...</td>\n",
       "      <td>Que coisa mais corrupta, dentro de um novo pac...</td>\n",
       "      <td>Que coisa mais corrupta dentro de um novo paco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Dilma elogiando o Congresso porque votaram?</td>\n",
       "      <td>Dilma elogiando o Congresso porque votaram?</td>\n",
       "      <td>Dilma elogiando o Congresso porque votaram</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância?</td>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância?</td>\n",
       "      <td>pedindo pazes com Temer tipo jardim da infância</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rotulo                                           sentenca  \\\n",
       "0     1.0                Parece estar no Reino da Dinamarca.   \n",
       "1     1.0  Esta conversa pra jornalista sabonete ouvir, é...   \n",
       "2     1.0  Que coisa mais corrupta, dentro de um novo pac...   \n",
       "3     1.0        Dilma elogiando o Congresso porque votaram?   \n",
       "4     1.0   pedindo pazes com Temer tipo jardim da infância?   \n",
       "\n",
       "                                sentenca_processada1  \\\n",
       "0                Parece estar no Reino da Dinamarca.   \n",
       "1  Esta conversa pra jornalista sabonete ouvir, é...   \n",
       "2  Que coisa mais corrupta, dentro de um novo pac...   \n",
       "3        Dilma elogiando o Congresso porque votaram?   \n",
       "4   pedindo pazes com Temer tipo jardim da infância?   \n",
       "\n",
       "                                sentenca_processada2  entidades_nomeadas  \\\n",
       "0                 Parece estar no Reino da Dinamarca                   1   \n",
       "1  Esta conversa pra jornalista sabonete ouvir é ...                   0   \n",
       "2  Que coisa mais corrupta dentro de um novo paco...                   0   \n",
       "3         Dilma elogiando o Congresso porque votaram                   1   \n",
       "4    pedindo pazes com Temer tipo jardim da infância                   1   \n",
       "\n",
       "   adjetivos  triggers  intensifiers  modifiers  quotation_marks  \\\n",
       "0          0         1             0          1                0   \n",
       "1          0         1             0          1                0   \n",
       "2          0         1             1          1                0   \n",
       "3          0         1             0          1                0   \n",
       "4          0         1             0          1                0   \n",
       "\n",
       "   repeated_punctuation  letters_repetition  word_repetition  \n",
       "0                     0                   0                0  \n",
       "1                     0                   0                0  \n",
       "2                     0                   0                0  \n",
       "3                     0                   0                0  \n",
       "4                     0                   0                0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classificacao</th>\n",
       "      <th>entidades_nomeadas</th>\n",
       "      <th>adjetivos</th>\n",
       "      <th>triggers</th>\n",
       "      <th>intensifiers</th>\n",
       "      <th>modifiers</th>\n",
       "      <th>quotation_marks</th>\n",
       "      <th>repeated_punctuation</th>\n",
       "      <th>letters_repetition</th>\n",
       "      <th>word_repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classificacao  entidades_nomeadas  adjetivos  triggers  intensifiers  \\\n",
       "0              1                   0          1         1             1   \n",
       "1              1                   0          0         1             0   \n",
       "2              1                   0          0         1             0   \n",
       "3              1                   1          0         1             0   \n",
       "4              1                   0          0         1             0   \n",
       "\n",
       "   modifiers  quotation_marks  repeated_punctuation  letters_repetition  \\\n",
       "0          1                0                     0                   0   \n",
       "1          1                0                     1                   0   \n",
       "2          1                0                     0                   1   \n",
       "3          1                1                     1                   0   \n",
       "4          0                0                     1                   0   \n",
       "\n",
       "   word_repetition  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = df1.iloc[:,1:10].values\n",
    "outputs = df1['classificacao']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELEÇÃO DAS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n",
      "[0.05798318 0.09833265 0.04484432 0.06661862 0.07870014 0.07961864\n",
      " 0.36655478 0.09197765 0.11537002]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(inputs, outputs)\n",
    "classificador = tree.DecisionTreeClassifier()\n",
    "classificador.fit(inputs, outputs)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(classificador.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n",
      "[False False False False False False  True False False]\n",
      "[7 2 8 6 4 3 1 5 9]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "classificador = LogisticRegression()\n",
    "# classificador.fit(treino, classe_treino)\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(classificador, 1)\n",
    "rfe = rfe.fit(inputs, outputs)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n",
      "[False False False False False False  True False False]\n",
      "[9 2 5 7 3 4 1 8 6]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "classificador = svm.SVC(gamma='auto', C=1.0, kernel='linear', probability=False)\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(classificador, 1)\n",
    "rfe = rfe.fit(inputs, outputs)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [entidades_nomeadas, adjetivos, triggers, intensifiers, modifiers, quotation_marks, repeated_punctuation, letters_repetition, word_repetition]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5e3ba0bdf6d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# display the relative importance of each attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = pd.read_csv('dataset_features.csv')\n",
    "\n",
    "inputs = dataset.iloc[:,1:10].values\n",
    "outputs = dataset['classificacao']\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "# model = ExtraTreesClassifier()\n",
    "# model.fit(inputs, outputs)\n",
    "classificador = MLPClassifier(activation='relu', solver='adam', max_iter=10000, alpha=1e-10, hidden_layer_sizes=(18,2))\n",
    "classificador.fit(inputs, outputs)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print(dataset.iloc[:,1:10].head(0))\n",
    "print(classificador.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # http://minerandodados.com.br/index.php/2018/05/21/feature-selection-bala-de-prata/\n",
    "# from sklearn import feature_selection\n",
    "# fs = feature_selection.SelectPercentile(feature_selection.f_classif, percentile=100)\n",
    "# # model = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k=9)\n",
    "# X_treino_fs = fs.fit_transform(inputs, outputs)\n",
    "\n",
    "# # results = model.fit(df[columns], df['qsec'])\n",
    "\n",
    "# print(fs.scores_)\n",
    "# print(fs.pvalues_)\n",
    "\n",
    "# # x = pd.DataFrame(X_treino_fs)\n",
    "# # x\n",
    "\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
